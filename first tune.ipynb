{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_11155/1946800243.py:1: DtypeWarning: Columns (4,13,14,16,47) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  train_data = pd.read_csv(\"/home/sysadm/F1nalyze/train.csv\")\n",
      "/tmp/ipykernel_11155/1946800243.py:2: DtypeWarning: Columns (13,16,36) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  validation_data = pd.read_csv(\"/home/sysadm/F1nalyze/validation.csv\")\n",
      "/tmp/ipykernel_11155/1946800243.py:3: DtypeWarning: Columns (13,16) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  test_data = pd.read_csv(\"/home/sysadm/F1nalyze/test.csv\")\n"
     ]
    }
   ],
   "source": [
    "train_data = pd.read_csv(\"/home/sysadm/F1nalyze/train.csv\")\n",
    "validation_data = pd.read_csv(\"/home/sysadm/F1nalyze/validation.csv\")\n",
    "test_data = pd.read_csv(\"/home/sysadm/F1nalyze/test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fixing Train Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>resultId</th>\n",
       "      <th>racerId</th>\n",
       "      <th>driverId</th>\n",
       "      <th>constructorId</th>\n",
       "      <th>number</th>\n",
       "      <th>grid</th>\n",
       "      <th>position_x</th>\n",
       "      <th>positionText_x</th>\n",
       "      <th>positionOrder</th>\n",
       "      <th>points</th>\n",
       "      <th>...</th>\n",
       "      <th>points_y</th>\n",
       "      <th>position</th>\n",
       "      <th>positionText_y</th>\n",
       "      <th>wins</th>\n",
       "      <th>constructorRef</th>\n",
       "      <th>company</th>\n",
       "      <th>nationality_y</th>\n",
       "      <th>url</th>\n",
       "      <th>status</th>\n",
       "      <th>result_driver_standing</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20025</td>\n",
       "      <td>833</td>\n",
       "      <td>642</td>\n",
       "      <td>51</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>9.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.33</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>alfa</td>\n",
       "      <td>Alfa Romeo</td>\n",
       "      <td>Swiss</td>\n",
       "      <td>http://en.wikipedia.org/wiki/Alfa_Romeo_in_For...</td>\n",
       "      <td>Finished</td>\n",
       "      <td>922731975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20025</td>\n",
       "      <td>833</td>\n",
       "      <td>642</td>\n",
       "      <td>51</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>9.0</td>\n",
       "      <td>...</td>\n",
       "      <td>6.33</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>alfa</td>\n",
       "      <td>Alfa Romeo</td>\n",
       "      <td>Swiss</td>\n",
       "      <td>http://en.wikipedia.org/wiki/Alfa_Romeo_in_For...</td>\n",
       "      <td>Finished</td>\n",
       "      <td>923172525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20025</td>\n",
       "      <td>833</td>\n",
       "      <td>642</td>\n",
       "      <td>51</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>9.0</td>\n",
       "      <td>...</td>\n",
       "      <td>6.33</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>alfa</td>\n",
       "      <td>Alfa Romeo</td>\n",
       "      <td>Swiss</td>\n",
       "      <td>http://en.wikipedia.org/wiki/Alfa_Romeo_in_For...</td>\n",
       "      <td>Finished</td>\n",
       "      <td>923833350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20025</td>\n",
       "      <td>833</td>\n",
       "      <td>642</td>\n",
       "      <td>51</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>9.0</td>\n",
       "      <td>...</td>\n",
       "      <td>10.33</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>alfa</td>\n",
       "      <td>Alfa Romeo</td>\n",
       "      <td>Swiss</td>\n",
       "      <td>http://en.wikipedia.org/wiki/Alfa_Romeo_in_For...</td>\n",
       "      <td>Finished</td>\n",
       "      <td>925195050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20025</td>\n",
       "      <td>833</td>\n",
       "      <td>642</td>\n",
       "      <td>51</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>9.0</td>\n",
       "      <td>...</td>\n",
       "      <td>10.33</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>alfa</td>\n",
       "      <td>Alfa Romeo</td>\n",
       "      <td>Swiss</td>\n",
       "      <td>http://en.wikipedia.org/wiki/Alfa_Romeo_in_For...</td>\n",
       "      <td>Finished</td>\n",
       "      <td>926576775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2830096</th>\n",
       "      <td>22109</td>\n",
       "      <td>899</td>\n",
       "      <td>17</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>18.0</td>\n",
       "      <td>...</td>\n",
       "      <td>61.50</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>red_bull</td>\n",
       "      <td>Red Bull</td>\n",
       "      <td>Austrian</td>\n",
       "      <td>http://en.wikipedia.org/wiki/Red_Bull_Racing</td>\n",
       "      <td>Finished</td>\n",
       "      <td>401167805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2830097</th>\n",
       "      <td>22109</td>\n",
       "      <td>899</td>\n",
       "      <td>17</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>18.0</td>\n",
       "      <td>...</td>\n",
       "      <td>69.50</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>red_bull</td>\n",
       "      <td>Red Bull</td>\n",
       "      <td>Austrian</td>\n",
       "      <td>http://en.wikipedia.org/wiki/Red_Bull_Racing</td>\n",
       "      <td>Finished</td>\n",
       "      <td>660484266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2830098</th>\n",
       "      <td>22109</td>\n",
       "      <td>899</td>\n",
       "      <td>17</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>18.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.00</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>red_bull</td>\n",
       "      <td>Red Bull</td>\n",
       "      <td>Austrian</td>\n",
       "      <td>http://en.wikipedia.org/wiki/Red_Bull_Racing</td>\n",
       "      <td>Finished</td>\n",
       "      <td>1409316096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2830099</th>\n",
       "      <td>22109</td>\n",
       "      <td>899</td>\n",
       "      <td>17</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>18.0</td>\n",
       "      <td>...</td>\n",
       "      <td>6.00</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>red_bull</td>\n",
       "      <td>Red Bull</td>\n",
       "      <td>Austrian</td>\n",
       "      <td>http://en.wikipedia.org/wiki/Red_Bull_Racing</td>\n",
       "      <td>Finished</td>\n",
       "      <td>1409846712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2830100</th>\n",
       "      <td>22109</td>\n",
       "      <td>899</td>\n",
       "      <td>17</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>18.0</td>\n",
       "      <td>...</td>\n",
       "      <td>24.00</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>red_bull</td>\n",
       "      <td>Red Bull</td>\n",
       "      <td>Austrian</td>\n",
       "      <td>http://en.wikipedia.org/wiki/Red_Bull_Racing</td>\n",
       "      <td>Finished</td>\n",
       "      <td>1410377328</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2830101 rows × 55 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         resultId  racerId  driverId  constructorId number  grid position_x  \\\n",
       "0           20025      833       642             51      2     1          1   \n",
       "1           20025      833       642             51      2     1          1   \n",
       "2           20025      833       642             51      2     1          1   \n",
       "3           20025      833       642             51      2     1          1   \n",
       "4           20025      833       642             51      2     1          1   \n",
       "...           ...      ...       ...            ...    ...   ...        ...   \n",
       "2830096     22109      899        17              9      2     4          2   \n",
       "2830097     22109      899        17              9      2     4          2   \n",
       "2830098     22109      899        17              9      2     4          2   \n",
       "2830099     22109      899        17              9      2     4          2   \n",
       "2830100     22109      899        17              9      2     4          2   \n",
       "\n",
       "        positionText_x  positionOrder  points  ...  points_y position  \\\n",
       "0                    1              1     9.0  ...      3.33        3   \n",
       "1                    1              1     9.0  ...      6.33        3   \n",
       "2                    1              1     9.0  ...      6.33        4   \n",
       "3                    1              1     9.0  ...     10.33        3   \n",
       "4                    1              1     9.0  ...     10.33        4   \n",
       "...                ...            ...     ...  ...       ...      ...   \n",
       "2830096              2              2    18.0  ...     61.50        4   \n",
       "2830097              2              2    18.0  ...     69.50        4   \n",
       "2830098              2              2    18.0  ...      4.00        8   \n",
       "2830099              2              2    18.0  ...      6.00       10   \n",
       "2830100              2              2    18.0  ...     24.00        8   \n",
       "\n",
       "        positionText_y wins constructorRef     company nationality_y  \\\n",
       "0                    3    0           alfa  Alfa Romeo         Swiss   \n",
       "1                    3    0           alfa  Alfa Romeo         Swiss   \n",
       "2                    4    0           alfa  Alfa Romeo         Swiss   \n",
       "3                    3    0           alfa  Alfa Romeo         Swiss   \n",
       "4                    4    0           alfa  Alfa Romeo         Swiss   \n",
       "...                ...  ...            ...         ...           ...   \n",
       "2830096              4    2       red_bull    Red Bull      Austrian   \n",
       "2830097              4    2       red_bull    Red Bull      Austrian   \n",
       "2830098              8    0       red_bull    Red Bull      Austrian   \n",
       "2830099             10    0       red_bull    Red Bull      Austrian   \n",
       "2830100              8    0       red_bull    Red Bull      Austrian   \n",
       "\n",
       "                                                       url    status  \\\n",
       "0        http://en.wikipedia.org/wiki/Alfa_Romeo_in_For...  Finished   \n",
       "1        http://en.wikipedia.org/wiki/Alfa_Romeo_in_For...  Finished   \n",
       "2        http://en.wikipedia.org/wiki/Alfa_Romeo_in_For...  Finished   \n",
       "3        http://en.wikipedia.org/wiki/Alfa_Romeo_in_For...  Finished   \n",
       "4        http://en.wikipedia.org/wiki/Alfa_Romeo_in_For...  Finished   \n",
       "...                                                    ...       ...   \n",
       "2830096       http://en.wikipedia.org/wiki/Red_Bull_Racing  Finished   \n",
       "2830097       http://en.wikipedia.org/wiki/Red_Bull_Racing  Finished   \n",
       "2830098       http://en.wikipedia.org/wiki/Red_Bull_Racing  Finished   \n",
       "2830099       http://en.wikipedia.org/wiki/Red_Bull_Racing  Finished   \n",
       "2830100       http://en.wikipedia.org/wiki/Red_Bull_Racing  Finished   \n",
       "\n",
       "         result_driver_standing  \n",
       "0                     922731975  \n",
       "1                     923172525  \n",
       "2                     923833350  \n",
       "3                     925195050  \n",
       "4                     926576775  \n",
       "...                         ...  \n",
       "2830096               401167805  \n",
       "2830097               660484266  \n",
       "2830098              1409316096  \n",
       "2830099              1409846712  \n",
       "2830100              1410377328  \n",
       "\n",
       "[2830101 rows x 55 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resultId                        0\n",
      "racerId                         0\n",
      "driverId                        0\n",
      "constructorId                   0\n",
      "number                        160\n",
      "grid                            0\n",
      "position_x                1125357\n",
      "positionText_x                  0\n",
      "positionOrder                   0\n",
      "points                          0\n",
      "laps                            0\n",
      "time_x                    1871686\n",
      "timetaken_in_millisec     1871741\n",
      "fastestLap                2112010\n",
      "rank                      2105375\n",
      "fastestLapTime            2112010\n",
      "max_speed                 2112010\n",
      "statusId                        0\n",
      "year                            0\n",
      "round                           0\n",
      "circuitId                       0\n",
      "grand_prix                      0\n",
      "date                            0\n",
      "time_y                    2150026\n",
      "url_x                           0\n",
      "fp1_date                  2830101\n",
      "fp1_time                  2830101\n",
      "fp2_date                  2830101\n",
      "fp2_time                  2830101\n",
      "fp3_date                  2830101\n",
      "fp3_time                  2830101\n",
      "quali_date                2830101\n",
      "quali_time                2830101\n",
      "sprint_date               2830101\n",
      "sprint_time               2830101\n",
      "driverRef                       0\n",
      "driver_num                2354922\n",
      "driver_code               1731200\n",
      "forename                        0\n",
      "surname                         0\n",
      "dob                             0\n",
      "nationality                     0\n",
      "url_y                           0\n",
      "driverStandingsId               0\n",
      "raceId_y                        0\n",
      "points_y                        0\n",
      "position                        0\n",
      "positionText_y                  0\n",
      "wins                            0\n",
      "constructorRef                  0\n",
      "company                         0\n",
      "nationality_y                   0\n",
      "url                             0\n",
      "status                          0\n",
      "result_driver_standing          0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "train_data.replace('\\\\N', np.nan, inplace=True)\n",
    "\n",
    "na_counts = train_data.isna().sum()\n",
    "\n",
    "print(na_counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.drop(columns = [\"resultId\",\"position_x\",\"time_x\",\"timetaken_in_millisec\",\"date\",\"time_y\",\"url_x\",\"fp1_date\",\n",
    "                           \"fp1_time\",\"fp2_date\",\"fp2_time\",\"fp3_date\",\"fp3_time\",\"quali_date\",\"quali_time\",\"sprint_date\",\"sprint_time\",\"driver_num\",\"driver_code\",\"forename\",\n",
    "                           \"surname\",\"dob\",\"url_y\",\"driverStandingsId\",\"raceId_y\",\"positionText_y\",\"constructorRef\",\"url\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.dropna(inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>racerId</th>\n",
       "      <th>driverId</th>\n",
       "      <th>constructorId</th>\n",
       "      <th>number</th>\n",
       "      <th>grid</th>\n",
       "      <th>positionText_x</th>\n",
       "      <th>positionOrder</th>\n",
       "      <th>points</th>\n",
       "      <th>laps</th>\n",
       "      <th>fastestLap</th>\n",
       "      <th>...</th>\n",
       "      <th>grand_prix</th>\n",
       "      <th>driverRef</th>\n",
       "      <th>nationality</th>\n",
       "      <th>points_y</th>\n",
       "      <th>position</th>\n",
       "      <th>wins</th>\n",
       "      <th>company</th>\n",
       "      <th>nationality_y</th>\n",
       "      <th>status</th>\n",
       "      <th>result_driver_standing</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2082849</th>\n",
       "      <td>90</td>\n",
       "      <td>30</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10.0</td>\n",
       "      <td>58</td>\n",
       "      <td>29</td>\n",
       "      <td>...</td>\n",
       "      <td>Australian Grand Prix</td>\n",
       "      <td>michael_schumacher</td>\n",
       "      <td>German</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>Ferrari</td>\n",
       "      <td>Italian</td>\n",
       "      <td>Finished</td>\n",
       "      <td>19404120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2082850</th>\n",
       "      <td>90</td>\n",
       "      <td>30</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10.0</td>\n",
       "      <td>58</td>\n",
       "      <td>29</td>\n",
       "      <td>...</td>\n",
       "      <td>Australian Grand Prix</td>\n",
       "      <td>michael_schumacher</td>\n",
       "      <td>German</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>Ferrari</td>\n",
       "      <td>Italian</td>\n",
       "      <td>Finished</td>\n",
       "      <td>19431390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2082851</th>\n",
       "      <td>90</td>\n",
       "      <td>30</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10.0</td>\n",
       "      <td>58</td>\n",
       "      <td>29</td>\n",
       "      <td>...</td>\n",
       "      <td>Australian Grand Prix</td>\n",
       "      <td>michael_schumacher</td>\n",
       "      <td>German</td>\n",
       "      <td>11.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>Ferrari</td>\n",
       "      <td>Italian</td>\n",
       "      <td>Finished</td>\n",
       "      <td>19463205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2082852</th>\n",
       "      <td>90</td>\n",
       "      <td>30</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10.0</td>\n",
       "      <td>58</td>\n",
       "      <td>29</td>\n",
       "      <td>...</td>\n",
       "      <td>Australian Grand Prix</td>\n",
       "      <td>michael_schumacher</td>\n",
       "      <td>German</td>\n",
       "      <td>21.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Ferrari</td>\n",
       "      <td>Italian</td>\n",
       "      <td>Finished</td>\n",
       "      <td>19496535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2082853</th>\n",
       "      <td>90</td>\n",
       "      <td>30</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10.0</td>\n",
       "      <td>58</td>\n",
       "      <td>29</td>\n",
       "      <td>...</td>\n",
       "      <td>Australian Grand Prix</td>\n",
       "      <td>michael_schumacher</td>\n",
       "      <td>German</td>\n",
       "      <td>31.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>Ferrari</td>\n",
       "      <td>Italian</td>\n",
       "      <td>Finished</td>\n",
       "      <td>19529865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2830096</th>\n",
       "      <td>899</td>\n",
       "      <td>17</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>18.0</td>\n",
       "      <td>71</td>\n",
       "      <td>51</td>\n",
       "      <td>...</td>\n",
       "      <td>Brazilian Grand Prix</td>\n",
       "      <td>webber</td>\n",
       "      <td>Australian</td>\n",
       "      <td>61.5</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>Red Bull</td>\n",
       "      <td>Austrian</td>\n",
       "      <td>Finished</td>\n",
       "      <td>401167805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2830097</th>\n",
       "      <td>899</td>\n",
       "      <td>17</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>18.0</td>\n",
       "      <td>71</td>\n",
       "      <td>51</td>\n",
       "      <td>...</td>\n",
       "      <td>Brazilian Grand Prix</td>\n",
       "      <td>webber</td>\n",
       "      <td>Australian</td>\n",
       "      <td>69.5</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>Red Bull</td>\n",
       "      <td>Austrian</td>\n",
       "      <td>Finished</td>\n",
       "      <td>660484266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2830098</th>\n",
       "      <td>899</td>\n",
       "      <td>17</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>18.0</td>\n",
       "      <td>71</td>\n",
       "      <td>51</td>\n",
       "      <td>...</td>\n",
       "      <td>Brazilian Grand Prix</td>\n",
       "      <td>webber</td>\n",
       "      <td>Australian</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>Red Bull</td>\n",
       "      <td>Austrian</td>\n",
       "      <td>Finished</td>\n",
       "      <td>1409316096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2830099</th>\n",
       "      <td>899</td>\n",
       "      <td>17</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>18.0</td>\n",
       "      <td>71</td>\n",
       "      <td>51</td>\n",
       "      <td>...</td>\n",
       "      <td>Brazilian Grand Prix</td>\n",
       "      <td>webber</td>\n",
       "      <td>Australian</td>\n",
       "      <td>6.0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>Red Bull</td>\n",
       "      <td>Austrian</td>\n",
       "      <td>Finished</td>\n",
       "      <td>1409846712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2830100</th>\n",
       "      <td>899</td>\n",
       "      <td>17</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>18.0</td>\n",
       "      <td>71</td>\n",
       "      <td>51</td>\n",
       "      <td>...</td>\n",
       "      <td>Brazilian Grand Prix</td>\n",
       "      <td>webber</td>\n",
       "      <td>Australian</td>\n",
       "      <td>24.0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>Red Bull</td>\n",
       "      <td>Austrian</td>\n",
       "      <td>Finished</td>\n",
       "      <td>1410377328</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>718091 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         racerId  driverId  constructorId number  grid positionText_x  \\\n",
       "2082849       90        30              6      1     1              1   \n",
       "2082850       90        30              6      1     1              1   \n",
       "2082851       90        30              6      1     1              1   \n",
       "2082852       90        30              6      1     1              1   \n",
       "2082853       90        30              6      1     1              1   \n",
       "...          ...       ...            ...    ...   ...            ...   \n",
       "2830096      899        17              9      2     4              2   \n",
       "2830097      899        17              9      2     4              2   \n",
       "2830098      899        17              9      2     4              2   \n",
       "2830099      899        17              9      2     4              2   \n",
       "2830100      899        17              9      2     4              2   \n",
       "\n",
       "         positionOrder  points  laps fastestLap  ...             grand_prix  \\\n",
       "2082849              1    10.0    58         29  ...  Australian Grand Prix   \n",
       "2082850              1    10.0    58         29  ...  Australian Grand Prix   \n",
       "2082851              1    10.0    58         29  ...  Australian Grand Prix   \n",
       "2082852              1    10.0    58         29  ...  Australian Grand Prix   \n",
       "2082853              1    10.0    58         29  ...  Australian Grand Prix   \n",
       "...                ...     ...   ...        ...  ...                    ...   \n",
       "2830096              2    18.0    71         51  ...   Brazilian Grand Prix   \n",
       "2830097              2    18.0    71         51  ...   Brazilian Grand Prix   \n",
       "2830098              2    18.0    71         51  ...   Brazilian Grand Prix   \n",
       "2830099              2    18.0    71         51  ...   Brazilian Grand Prix   \n",
       "2830100              2    18.0    71         51  ...   Brazilian Grand Prix   \n",
       "\n",
       "                  driverRef nationality  points_y  position  wins   company  \\\n",
       "2082849  michael_schumacher      German       8.0         2     0   Ferrari   \n",
       "2082850  michael_schumacher      German      11.0         2     0   Ferrari   \n",
       "2082851  michael_schumacher      German      11.0         4     0   Ferrari   \n",
       "2082852  michael_schumacher      German      21.0         2     1   Ferrari   \n",
       "2082853  michael_schumacher      German      31.0         2     2   Ferrari   \n",
       "...                     ...         ...       ...       ...   ...       ...   \n",
       "2830096              webber  Australian      61.5         4     2  Red Bull   \n",
       "2830097              webber  Australian      69.5         4     2  Red Bull   \n",
       "2830098              webber  Australian       4.0         8     0  Red Bull   \n",
       "2830099              webber  Australian       6.0        10     0  Red Bull   \n",
       "2830100              webber  Australian      24.0         8     0  Red Bull   \n",
       "\n",
       "        nationality_y    status result_driver_standing  \n",
       "2082849       Italian  Finished               19404120  \n",
       "2082850       Italian  Finished               19431390  \n",
       "2082851       Italian  Finished               19463205  \n",
       "2082852       Italian  Finished               19496535  \n",
       "2082853       Italian  Finished               19529865  \n",
       "...               ...       ...                    ...  \n",
       "2830096      Austrian  Finished              401167805  \n",
       "2830097      Austrian  Finished              660484266  \n",
       "2830098      Austrian  Finished             1409316096  \n",
       "2830099      Austrian  Finished             1409846712  \n",
       "2830100      Austrian  Finished             1410377328  \n",
       "\n",
       "[718091 rows x 27 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_to_seconds(time_str):\n",
    "    minutes, seconds = time_str.split(':')\n",
    "    total_seconds = int(minutes) * 60 + float(seconds)\n",
    "    return total_seconds\n",
    "\n",
    "train_data[\"fastestLapTime\"] = train_data[\"fastestLapTime\"].apply(time_to_seconds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data[\"number\"] = train_data[\"number\"].astype(int)\n",
    "train_data[\"fastestLap\"] = train_data[\"fastestLap\"].astype(int)\n",
    "train_data[\"rank\"] = train_data[\"rank\"].astype(int)\n",
    "train_data[\"max_speed\"] = train_data[\"max_speed\"].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = LabelEncoder()\n",
    "train_data[\"positionText_x\"] = encoder.fit_transform(train_data[\"positionText_x\"])\n",
    "train_data[\"grand_prix\"] = encoder.fit_transform(train_data[\"grand_prix\"])\n",
    "train_data[\"driverRef\"] = encoder.fit_transform(train_data[\"driverRef\"])\n",
    "train_data[\"nationality\"] = encoder.fit_transform(train_data[\"nationality\"])\n",
    "train_data[\"company\"] = encoder.fit_transform(train_data[\"company\"])\n",
    "train_data[\"nationality_y\"] = encoder.fit_transform(train_data[\"nationality_y\"])\n",
    "train_data[\"status\"] = encoder.fit_transform(train_data[\"status\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "racerId                     int64\n",
       "driverId                    int64\n",
       "constructorId               int64\n",
       "number                      int64\n",
       "grid                        int64\n",
       "positionText_x              int64\n",
       "positionOrder               int64\n",
       "points                    float64\n",
       "laps                        int64\n",
       "fastestLap                  int64\n",
       "rank                        int64\n",
       "fastestLapTime            float64\n",
       "max_speed                 float64\n",
       "statusId                    int64\n",
       "year                        int64\n",
       "round                       int64\n",
       "circuitId                   int64\n",
       "grand_prix                  int64\n",
       "driverRef                   int64\n",
       "nationality                 int64\n",
       "points_y                  float64\n",
       "position                    int64\n",
       "wins                        int64\n",
       "company                     int64\n",
       "nationality_y               int64\n",
       "status                      int64\n",
       "result_driver_standing      int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>racerId</th>\n",
       "      <th>driverId</th>\n",
       "      <th>constructorId</th>\n",
       "      <th>number</th>\n",
       "      <th>grid</th>\n",
       "      <th>positionText_x</th>\n",
       "      <th>positionOrder</th>\n",
       "      <th>points</th>\n",
       "      <th>laps</th>\n",
       "      <th>fastestLap</th>\n",
       "      <th>...</th>\n",
       "      <th>grand_prix</th>\n",
       "      <th>driverRef</th>\n",
       "      <th>nationality</th>\n",
       "      <th>points_y</th>\n",
       "      <th>position</th>\n",
       "      <th>wins</th>\n",
       "      <th>company</th>\n",
       "      <th>nationality_y</th>\n",
       "      <th>status</th>\n",
       "      <th>result_driver_standing</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2082849</th>\n",
       "      <td>90</td>\n",
       "      <td>30</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>10.0</td>\n",
       "      <td>58</td>\n",
       "      <td>29</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>40</td>\n",
       "      <td>11</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>33</td>\n",
       "      <td>19404120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2082850</th>\n",
       "      <td>90</td>\n",
       "      <td>30</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>10.0</td>\n",
       "      <td>58</td>\n",
       "      <td>29</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>40</td>\n",
       "      <td>11</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>33</td>\n",
       "      <td>19431390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2082851</th>\n",
       "      <td>90</td>\n",
       "      <td>30</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>10.0</td>\n",
       "      <td>58</td>\n",
       "      <td>29</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>40</td>\n",
       "      <td>11</td>\n",
       "      <td>11.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>33</td>\n",
       "      <td>19463205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2082852</th>\n",
       "      <td>90</td>\n",
       "      <td>30</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>10.0</td>\n",
       "      <td>58</td>\n",
       "      <td>29</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>40</td>\n",
       "      <td>11</td>\n",
       "      <td>21.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>33</td>\n",
       "      <td>19496535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2082853</th>\n",
       "      <td>90</td>\n",
       "      <td>30</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>10.0</td>\n",
       "      <td>58</td>\n",
       "      <td>29</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>40</td>\n",
       "      <td>11</td>\n",
       "      <td>31.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>33</td>\n",
       "      <td>19529865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2830096</th>\n",
       "      <td>899</td>\n",
       "      <td>17</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>18.0</td>\n",
       "      <td>71</td>\n",
       "      <td>51</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>65</td>\n",
       "      <td>1</td>\n",
       "      <td>61.5</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>33</td>\n",
       "      <td>401167805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2830097</th>\n",
       "      <td>899</td>\n",
       "      <td>17</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>18.0</td>\n",
       "      <td>71</td>\n",
       "      <td>51</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>65</td>\n",
       "      <td>1</td>\n",
       "      <td>69.5</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>33</td>\n",
       "      <td>660484266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2830098</th>\n",
       "      <td>899</td>\n",
       "      <td>17</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>18.0</td>\n",
       "      <td>71</td>\n",
       "      <td>51</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>65</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>33</td>\n",
       "      <td>1409316096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2830099</th>\n",
       "      <td>899</td>\n",
       "      <td>17</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>18.0</td>\n",
       "      <td>71</td>\n",
       "      <td>51</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>65</td>\n",
       "      <td>1</td>\n",
       "      <td>6.0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>33</td>\n",
       "      <td>1409846712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2830100</th>\n",
       "      <td>899</td>\n",
       "      <td>17</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>18.0</td>\n",
       "      <td>71</td>\n",
       "      <td>51</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>65</td>\n",
       "      <td>1</td>\n",
       "      <td>24.0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>33</td>\n",
       "      <td>1410377328</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>718091 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         racerId  driverId  constructorId  number  grid  positionText_x  \\\n",
       "2082849       90        30              6       1     1               0   \n",
       "2082850       90        30              6       1     1               0   \n",
       "2082851       90        30              6       1     1               0   \n",
       "2082852       90        30              6       1     1               0   \n",
       "2082853       90        30              6       1     1               0   \n",
       "...          ...       ...            ...     ...   ...             ...   \n",
       "2830096      899        17              9       2     4              11   \n",
       "2830097      899        17              9       2     4              11   \n",
       "2830098      899        17              9       2     4              11   \n",
       "2830099      899        17              9       2     4              11   \n",
       "2830100      899        17              9       2     4              11   \n",
       "\n",
       "         positionOrder  points  laps  fastestLap  ...  grand_prix  driverRef  \\\n",
       "2082849              1    10.0    58          29  ...           1         40   \n",
       "2082850              1    10.0    58          29  ...           1         40   \n",
       "2082851              1    10.0    58          29  ...           1         40   \n",
       "2082852              1    10.0    58          29  ...           1         40   \n",
       "2082853              1    10.0    58          29  ...           1         40   \n",
       "...                ...     ...   ...         ...  ...         ...        ...   \n",
       "2830096              2    18.0    71          51  ...           4         65   \n",
       "2830097              2    18.0    71          51  ...           4         65   \n",
       "2830098              2    18.0    71          51  ...           4         65   \n",
       "2830099              2    18.0    71          51  ...           4         65   \n",
       "2830100              2    18.0    71          51  ...           4         65   \n",
       "\n",
       "         nationality  points_y  position  wins  company  nationality_y  \\\n",
       "2082849           11       8.0         2     0        4              7   \n",
       "2082850           11      11.0         2     0        4              7   \n",
       "2082851           11      11.0         4     0        4              7   \n",
       "2082852           11      21.0         2     1        4              7   \n",
       "2082853           11      31.0         2     2        4              7   \n",
       "...              ...       ...       ...   ...      ...            ...   \n",
       "2830096            1      61.5         4     2       17              0   \n",
       "2830097            1      69.5         4     2       17              0   \n",
       "2830098            1       4.0         8     0       17              0   \n",
       "2830099            1       6.0        10     0       17              0   \n",
       "2830100            1      24.0         8     0       17              0   \n",
       "\n",
       "         status  result_driver_standing  \n",
       "2082849      33                19404120  \n",
       "2082850      33                19431390  \n",
       "2082851      33                19463205  \n",
       "2082852      33                19496535  \n",
       "2082853      33                19529865  \n",
       "...         ...                     ...  \n",
       "2830096      33               401167805  \n",
       "2830097      33               660484266  \n",
       "2830098      33              1409316096  \n",
       "2830099      33              1409846712  \n",
       "2830100      33              1410377328  \n",
       "\n",
       "[718091 rows x 27 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fixing Validation Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resultId                       0\n",
      "racerId                        0\n",
      "driverId                       0\n",
      "constructorId                  0\n",
      "number                         0\n",
      "grid                           0\n",
      "position_x                 62123\n",
      "positionText_x                 0\n",
      "positionOrder                  0\n",
      "points                         0\n",
      "laps                           0\n",
      "time_x                    155366\n",
      "timetaken_in_millisec     155366\n",
      "fastestLap                 16390\n",
      "rank                           0\n",
      "fastestLapTime             16390\n",
      "max_speed                  16390\n",
      "statusId                       0\n",
      "year                           0\n",
      "round                          0\n",
      "circuitId                      0\n",
      "grand_prix                     0\n",
      "date                           0\n",
      "time_y                         0\n",
      "url_x                          0\n",
      "fp1_date                  353762\n",
      "fp1_time                  353762\n",
      "fp2_date                  353762\n",
      "fp2_time                  353762\n",
      "fp3_date                  353762\n",
      "fp3_time                  353762\n",
      "quali_date                353762\n",
      "quali_time                353762\n",
      "sprint_date               353762\n",
      "sprint_time               353762\n",
      "driverRef                      0\n",
      "driver_num                   379\n",
      "driver_code                    0\n",
      "forename                       0\n",
      "surname                        0\n",
      "dob                            0\n",
      "nationality                    0\n",
      "url_y                          0\n",
      "driverStandingsId              0\n",
      "raceId_y                       0\n",
      "points_y                       0\n",
      "position                       0\n",
      "positionText_y                 0\n",
      "wins                           0\n",
      "constructorRef                 0\n",
      "company                        0\n",
      "nationality_y                  0\n",
      "url                            0\n",
      "status                         0\n",
      "result_driver_standing         0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "validation_data.replace('\\\\N', np.nan, inplace=True)\n",
    "na_counts = validation_data.isna().sum()\n",
    "print(na_counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_data.drop(columns = [\"resultId\",\"position_x\",\"time_x\",\"timetaken_in_millisec\",\"date\",\"time_y\",\"url_x\",\"fp1_date\",\n",
    "                           \"fp1_time\",\"fp2_date\",\"fp2_time\",\"fp3_date\",\"fp3_time\",\"quali_date\",\"quali_time\",\"sprint_date\",\"sprint_time\",\"driver_num\",\"driver_code\",\"forename\",\n",
    "                           \"surname\",\"dob\",\"url_y\",\"driverStandingsId\",\"raceId_y\",\"positionText_y\",\"constructorRef\",\"url\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_data.dropna(inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>racerId</th>\n",
       "      <th>driverId</th>\n",
       "      <th>constructorId</th>\n",
       "      <th>number</th>\n",
       "      <th>grid</th>\n",
       "      <th>positionText_x</th>\n",
       "      <th>positionOrder</th>\n",
       "      <th>points</th>\n",
       "      <th>laps</th>\n",
       "      <th>fastestLap</th>\n",
       "      <th>...</th>\n",
       "      <th>grand_prix</th>\n",
       "      <th>driverRef</th>\n",
       "      <th>nationality</th>\n",
       "      <th>points_y</th>\n",
       "      <th>position</th>\n",
       "      <th>wins</th>\n",
       "      <th>company</th>\n",
       "      <th>nationality_y</th>\n",
       "      <th>status</th>\n",
       "      <th>result_driver_standing</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>899</td>\n",
       "      <td>17</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>18.0</td>\n",
       "      <td>71</td>\n",
       "      <td>51</td>\n",
       "      <td>...</td>\n",
       "      <td>Brazilian Grand Prix</td>\n",
       "      <td>webber</td>\n",
       "      <td>Australian</td>\n",
       "      <td>28.0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>Red Bull</td>\n",
       "      <td>Austrian</td>\n",
       "      <td>Finished</td>\n",
       "      <td>1410907944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>899</td>\n",
       "      <td>17</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>18.0</td>\n",
       "      <td>71</td>\n",
       "      <td>51</td>\n",
       "      <td>...</td>\n",
       "      <td>Brazilian Grand Prix</td>\n",
       "      <td>webber</td>\n",
       "      <td>Australian</td>\n",
       "      <td>53.0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>Red Bull</td>\n",
       "      <td>Austrian</td>\n",
       "      <td>Finished</td>\n",
       "      <td>1411438560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>899</td>\n",
       "      <td>17</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>18.0</td>\n",
       "      <td>71</td>\n",
       "      <td>51</td>\n",
       "      <td>...</td>\n",
       "      <td>Brazilian Grand Prix</td>\n",
       "      <td>webber</td>\n",
       "      <td>Australian</td>\n",
       "      <td>78.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Red Bull</td>\n",
       "      <td>Austrian</td>\n",
       "      <td>Finished</td>\n",
       "      <td>1412499792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>899</td>\n",
       "      <td>17</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>18.0</td>\n",
       "      <td>71</td>\n",
       "      <td>51</td>\n",
       "      <td>...</td>\n",
       "      <td>Brazilian Grand Prix</td>\n",
       "      <td>webber</td>\n",
       "      <td>Australian</td>\n",
       "      <td>93.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Red Bull</td>\n",
       "      <td>Austrian</td>\n",
       "      <td>Finished</td>\n",
       "      <td>1413030408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>899</td>\n",
       "      <td>17</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>18.0</td>\n",
       "      <td>71</td>\n",
       "      <td>51</td>\n",
       "      <td>...</td>\n",
       "      <td>Brazilian Grand Prix</td>\n",
       "      <td>webber</td>\n",
       "      <td>Australian</td>\n",
       "      <td>103.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>Red Bull</td>\n",
       "      <td>Austrian</td>\n",
       "      <td>Finished</td>\n",
       "      <td>1413561024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>353757</th>\n",
       "      <td>997</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>13</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>4.0</td>\n",
       "      <td>70</td>\n",
       "      <td>69</td>\n",
       "      <td>...</td>\n",
       "      <td>Austrian Grand Prix</td>\n",
       "      <td>alonso</td>\n",
       "      <td>Spanish</td>\n",
       "      <td>123.0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>McLaren</td>\n",
       "      <td>British</td>\n",
       "      <td>+1 Lap</td>\n",
       "      <td>1705168800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>353758</th>\n",
       "      <td>997</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>13</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>4.0</td>\n",
       "      <td>70</td>\n",
       "      <td>69</td>\n",
       "      <td>...</td>\n",
       "      <td>Austrian Grand Prix</td>\n",
       "      <td>alonso</td>\n",
       "      <td>Spanish</td>\n",
       "      <td>133.0</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>McLaren</td>\n",
       "      <td>British</td>\n",
       "      <td>+1 Lap</td>\n",
       "      <td>1705815423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>353759</th>\n",
       "      <td>997</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>13</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>4.0</td>\n",
       "      <td>70</td>\n",
       "      <td>69</td>\n",
       "      <td>...</td>\n",
       "      <td>Austrian Grand Prix</td>\n",
       "      <td>alonso</td>\n",
       "      <td>Spanish</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>McLaren</td>\n",
       "      <td>British</td>\n",
       "      <td>+1 Lap</td>\n",
       "      <td>297542376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>353760</th>\n",
       "      <td>997</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>13</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>4.0</td>\n",
       "      <td>70</td>\n",
       "      <td>69</td>\n",
       "      <td>...</td>\n",
       "      <td>Austrian Grand Prix</td>\n",
       "      <td>alonso</td>\n",
       "      <td>Spanish</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>McLaren</td>\n",
       "      <td>British</td>\n",
       "      <td>+1 Lap</td>\n",
       "      <td>297877662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>353761</th>\n",
       "      <td>997</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>13</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>4.0</td>\n",
       "      <td>70</td>\n",
       "      <td>69</td>\n",
       "      <td>...</td>\n",
       "      <td>Austrian Grand Prix</td>\n",
       "      <td>alonso</td>\n",
       "      <td>Spanish</td>\n",
       "      <td>11.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>McLaren</td>\n",
       "      <td>British</td>\n",
       "      <td>+1 Lap</td>\n",
       "      <td>298284795</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>337372 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        racerId  driverId  constructorId  number  grid positionText_x  \\\n",
       "0           899        17              9       2     4              2   \n",
       "1           899        17              9       2     4              2   \n",
       "2           899        17              9       2     4              2   \n",
       "3           899        17              9       2     4              2   \n",
       "4           899        17              9       2     4              2   \n",
       "...         ...       ...            ...     ...   ...            ...   \n",
       "353757      997         4              1      14    13              8   \n",
       "353758      997         4              1      14    13              8   \n",
       "353759      997         4              1      14    13              8   \n",
       "353760      997         4              1      14    13              8   \n",
       "353761      997         4              1      14    13              8   \n",
       "\n",
       "        positionOrder  points  laps fastestLap  ...            grand_prix  \\\n",
       "0                   2    18.0    71         51  ...  Brazilian Grand Prix   \n",
       "1                   2    18.0    71         51  ...  Brazilian Grand Prix   \n",
       "2                   2    18.0    71         51  ...  Brazilian Grand Prix   \n",
       "3                   2    18.0    71         51  ...  Brazilian Grand Prix   \n",
       "4                   2    18.0    71         51  ...  Brazilian Grand Prix   \n",
       "...               ...     ...   ...        ...  ...                   ...   \n",
       "353757              8     4.0    70         69  ...   Austrian Grand Prix   \n",
       "353758              8     4.0    70         69  ...   Austrian Grand Prix   \n",
       "353759              8     4.0    70         69  ...   Austrian Grand Prix   \n",
       "353760              8     4.0    70         69  ...   Austrian Grand Prix   \n",
       "353761              8     4.0    70         69  ...   Austrian Grand Prix   \n",
       "\n",
       "       driverRef nationality  points_y  position  wins   company  \\\n",
       "0         webber  Australian      28.0         8     0  Red Bull   \n",
       "1         webber  Australian      53.0         4     1  Red Bull   \n",
       "2         webber  Australian      78.0         1     2  Red Bull   \n",
       "3         webber  Australian      93.0         1     2  Red Bull   \n",
       "4         webber  Australian     103.0         3     2  Red Bull   \n",
       "...          ...         ...       ...       ...   ...       ...   \n",
       "353757    alonso     Spanish     123.0         1     6   McLaren   \n",
       "353758    alonso     Spanish     133.0         1     7   McLaren   \n",
       "353759    alonso     Spanish       6.0         3     0   McLaren   \n",
       "353760    alonso     Spanish       8.0         5     0   McLaren   \n",
       "353761    alonso     Spanish      11.0         5     0   McLaren   \n",
       "\n",
       "       nationality_y    status result_driver_standing  \n",
       "0           Austrian  Finished             1410907944  \n",
       "1           Austrian  Finished             1411438560  \n",
       "2           Austrian  Finished             1412499792  \n",
       "3           Austrian  Finished             1413030408  \n",
       "4           Austrian  Finished             1413561024  \n",
       "...              ...       ...                    ...  \n",
       "353757       British    +1 Lap             1705168800  \n",
       "353758       British    +1 Lap             1705815423  \n",
       "353759       British    +1 Lap              297542376  \n",
       "353760       British    +1 Lap              297877662  \n",
       "353761       British    +1 Lap              298284795  \n",
       "\n",
       "[337372 rows x 27 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_data[\"fastestLapTime\"] = validation_data[\"fastestLapTime\"].apply(time_to_seconds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_data[\"number\"] = validation_data[\"number\"].astype(int)\n",
    "validation_data[\"fastestLap\"] = validation_data[\"fastestLap\"].astype(int)\n",
    "validation_data[\"rank\"] = validation_data[\"rank\"].astype(int)\n",
    "validation_data[\"max_speed\"] = validation_data[\"max_speed\"].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = LabelEncoder()\n",
    "validation_data[\"positionText_x\"] = encoder.fit_transform(validation_data[\"positionText_x\"])\n",
    "validation_data[\"grand_prix\"] = encoder.fit_transform(validation_data[\"grand_prix\"])\n",
    "validation_data[\"driverRef\"] = encoder.fit_transform(validation_data[\"driverRef\"])\n",
    "validation_data[\"nationality\"] = encoder.fit_transform(validation_data[\"nationality\"])\n",
    "validation_data[\"company\"] = encoder.fit_transform(validation_data[\"company\"])\n",
    "validation_data[\"nationality_y\"] = encoder.fit_transform(validation_data[\"nationality_y\"])\n",
    "validation_data[\"status\"] = encoder.fit_transform(validation_data[\"status\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "racerId                     int64\n",
       "driverId                    int64\n",
       "constructorId               int64\n",
       "number                      int64\n",
       "grid                        int64\n",
       "positionText_x              int64\n",
       "positionOrder               int64\n",
       "points                    float64\n",
       "laps                        int64\n",
       "fastestLap                  int64\n",
       "rank                        int64\n",
       "fastestLapTime            float64\n",
       "max_speed                 float64\n",
       "statusId                    int64\n",
       "year                        int64\n",
       "round                       int64\n",
       "circuitId                   int64\n",
       "grand_prix                  int64\n",
       "driverRef                   int64\n",
       "nationality                 int64\n",
       "points_y                  float64\n",
       "position                    int64\n",
       "wins                        int64\n",
       "company                     int64\n",
       "nationality_y               int64\n",
       "status                      int64\n",
       "result_driver_standing      int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>racerId</th>\n",
       "      <th>driverId</th>\n",
       "      <th>constructorId</th>\n",
       "      <th>number</th>\n",
       "      <th>grid</th>\n",
       "      <th>positionText_x</th>\n",
       "      <th>positionOrder</th>\n",
       "      <th>points</th>\n",
       "      <th>laps</th>\n",
       "      <th>fastestLap</th>\n",
       "      <th>...</th>\n",
       "      <th>grand_prix</th>\n",
       "      <th>driverRef</th>\n",
       "      <th>nationality</th>\n",
       "      <th>points_y</th>\n",
       "      <th>position</th>\n",
       "      <th>wins</th>\n",
       "      <th>company</th>\n",
       "      <th>nationality_y</th>\n",
       "      <th>status</th>\n",
       "      <th>result_driver_standing</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>899</td>\n",
       "      <td>17</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>18.0</td>\n",
       "      <td>71</td>\n",
       "      <td>51</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>42</td>\n",
       "      <td>1</td>\n",
       "      <td>28.0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>1410907944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>899</td>\n",
       "      <td>17</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>18.0</td>\n",
       "      <td>71</td>\n",
       "      <td>51</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>42</td>\n",
       "      <td>1</td>\n",
       "      <td>53.0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>1411438560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>899</td>\n",
       "      <td>17</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>18.0</td>\n",
       "      <td>71</td>\n",
       "      <td>51</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>42</td>\n",
       "      <td>1</td>\n",
       "      <td>78.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>1412499792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>899</td>\n",
       "      <td>17</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>18.0</td>\n",
       "      <td>71</td>\n",
       "      <td>51</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>42</td>\n",
       "      <td>1</td>\n",
       "      <td>93.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>1413030408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>899</td>\n",
       "      <td>17</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>18.0</td>\n",
       "      <td>71</td>\n",
       "      <td>51</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>42</td>\n",
       "      <td>1</td>\n",
       "      <td>103.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>1413561024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>353757</th>\n",
       "      <td>997</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>13</td>\n",
       "      <td>20</td>\n",
       "      <td>8</td>\n",
       "      <td>4.0</td>\n",
       "      <td>70</td>\n",
       "      <td>69</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>123.0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1705168800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>353758</th>\n",
       "      <td>997</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>13</td>\n",
       "      <td>20</td>\n",
       "      <td>8</td>\n",
       "      <td>4.0</td>\n",
       "      <td>70</td>\n",
       "      <td>69</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>133.0</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1705815423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>353759</th>\n",
       "      <td>997</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>13</td>\n",
       "      <td>20</td>\n",
       "      <td>8</td>\n",
       "      <td>4.0</td>\n",
       "      <td>70</td>\n",
       "      <td>69</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>297542376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>353760</th>\n",
       "      <td>997</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>13</td>\n",
       "      <td>20</td>\n",
       "      <td>8</td>\n",
       "      <td>4.0</td>\n",
       "      <td>70</td>\n",
       "      <td>69</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>297877662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>353761</th>\n",
       "      <td>997</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>13</td>\n",
       "      <td>20</td>\n",
       "      <td>8</td>\n",
       "      <td>4.0</td>\n",
       "      <td>70</td>\n",
       "      <td>69</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>11.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>298284795</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>337372 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        racerId  driverId  constructorId  number  grid  positionText_x  \\\n",
       "0           899        17              9       2     4              11   \n",
       "1           899        17              9       2     4              11   \n",
       "2           899        17              9       2     4              11   \n",
       "3           899        17              9       2     4              11   \n",
       "4           899        17              9       2     4              11   \n",
       "...         ...       ...            ...     ...   ...             ...   \n",
       "353757      997         4              1      14    13              20   \n",
       "353758      997         4              1      14    13              20   \n",
       "353759      997         4              1      14    13              20   \n",
       "353760      997         4              1      14    13              20   \n",
       "353761      997         4              1      14    13              20   \n",
       "\n",
       "        positionOrder  points  laps  fastestLap  ...  grand_prix  driverRef  \\\n",
       "0                   2    18.0    71          51  ...           6         42   \n",
       "1                   2    18.0    71          51  ...           6         42   \n",
       "2                   2    18.0    71          51  ...           6         42   \n",
       "3                   2    18.0    71          51  ...           6         42   \n",
       "4                   2    18.0    71          51  ...           6         42   \n",
       "...               ...     ...   ...         ...  ...         ...        ...   \n",
       "353757              8     4.0    70          69  ...           2          0   \n",
       "353758              8     4.0    70          69  ...           2          0   \n",
       "353759              8     4.0    70          69  ...           2          0   \n",
       "353760              8     4.0    70          69  ...           2          0   \n",
       "353761              8     4.0    70          69  ...           2          0   \n",
       "\n",
       "        nationality  points_y  position  wins  company  nationality_y  status  \\\n",
       "0                 1      28.0         8     0        9              1      20   \n",
       "1                 1      53.0         4     1        9              1      20   \n",
       "2                 1      78.0         1     2        9              1      20   \n",
       "3                 1      93.0         1     2        9              1      20   \n",
       "4                 1     103.0         3     2        9              1      20   \n",
       "...             ...       ...       ...   ...      ...            ...     ...   \n",
       "353757           18     123.0         1     6        7              2       0   \n",
       "353758           18     133.0         1     7        7              2       0   \n",
       "353759           18       6.0         3     0        7              2       0   \n",
       "353760           18       8.0         5     0        7              2       0   \n",
       "353761           18      11.0         5     0        7              2       0   \n",
       "\n",
       "        result_driver_standing  \n",
       "0                   1410907944  \n",
       "1                   1411438560  \n",
       "2                   1412499792  \n",
       "3                   1413030408  \n",
       "4                   1413561024  \n",
       "...                        ...  \n",
       "353757              1705168800  \n",
       "353758              1705815423  \n",
       "353759               297542376  \n",
       "353760               297877662  \n",
       "353761               298284795  \n",
       "\n",
       "[337372 rows x 27 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fixing Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resultId                       0\n",
      "racerId                        0\n",
      "driverId                       0\n",
      "constructorId                  0\n",
      "number                         0\n",
      "grid                           0\n",
      "position_x                 45237\n",
      "positionText_x                 0\n",
      "positionOrder                  0\n",
      "points                         0\n",
      "laps                           0\n",
      "time_x                    145425\n",
      "timetaken_in_millisec     145425\n",
      "fastestLap                 12225\n",
      "rank                           0\n",
      "fastestLapTime             12225\n",
      "max_speed                  12225\n",
      "statusId                       0\n",
      "year                           0\n",
      "round                          0\n",
      "circuitId                      0\n",
      "grand_prix                     0\n",
      "date                           0\n",
      "time_y                         0\n",
      "url_x                          0\n",
      "fp1_date                  177237\n",
      "fp1_time                  249976\n",
      "fp2_date                  177237\n",
      "fp2_time                  249976\n",
      "fp3_date                  204987\n",
      "fp3_time                  267989\n",
      "quali_date                177237\n",
      "quali_time                249976\n",
      "sprint_date               325178\n",
      "sprint_time               334915\n",
      "driverRef                      0\n",
      "driver_num                     0\n",
      "driver_code                    0\n",
      "forename                       0\n",
      "surname                        0\n",
      "dob                            0\n",
      "nationality                    0\n",
      "url_y                          0\n",
      "driverStandingsId              0\n",
      "raceId_y                       0\n",
      "points_y                       0\n",
      "wins                           0\n",
      "constructorRef                 0\n",
      "company                        0\n",
      "nationality_y                  0\n",
      "url                            0\n",
      "status                         0\n",
      "result_driver_standing         0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "test_data.replace('\\\\N', np.nan, inplace=True)\n",
    "na_counts = test_data.isna().sum()\n",
    "\n",
    "print(na_counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data.drop(columns = [\"resultId\",\"position_x\",\"time_x\",\"timetaken_in_millisec\",\"date\",\"time_y\",\"url_x\",\"fp1_date\",\n",
    "                           \"fp1_time\",\"fp2_date\",\"fp2_time\",\"fp3_date\",\"fp3_time\",\"quali_date\",\"quali_time\",\"sprint_date\",\"sprint_time\",\"driver_num\",\"driver_code\",\"forename\",\n",
    "                           \"surname\",\"dob\",\"url_y\",\"driverStandingsId\",\"raceId_y\",\"constructorRef\",\"url\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data['fastestLapTime'] = test_data['fastestLapTime'].apply(lambda x: time_to_seconds(x) if pd.notna(x) else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data[\"number\"] = test_data[\"number\"].astype(int)\n",
    "test_data['fastestLap'] = test_data['fastestLap'].apply(lambda x: int(x) if pd.notna(x) else x)\n",
    "test_data[\"rank\"] = test_data[\"rank\"].astype(int)\n",
    "test_data[\"max_speed\"] = test_data[\"max_speed\"].apply(lambda x: float(x) if pd.notna(x) else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = LabelEncoder()\n",
    "test_data[\"positionText_x\"] = encoder.fit_transform(test_data[\"positionText_x\"])\n",
    "test_data[\"grand_prix\"] = encoder.fit_transform(test_data[\"grand_prix\"])\n",
    "test_data[\"driverRef\"] = encoder.fit_transform(test_data[\"driverRef\"])\n",
    "test_data[\"nationality\"] = encoder.fit_transform(test_data[\"nationality\"])\n",
    "test_data[\"company\"] = encoder.fit_transform(test_data[\"company\"])\n",
    "test_data[\"nationality_y\"] = encoder.fit_transform(test_data[\"nationality_y\"])\n",
    "test_data[\"status\"] = encoder.fit_transform(test_data[\"status\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_columns = [\"fastestLap\",\"fastestLapTime\",\"max_speed\"]\n",
    "test_data[numerical_columns] = test_data[numerical_columns].apply(lambda col: col.fillna(col.mean()), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "racerId                   0\n",
      "driverId                  0\n",
      "constructorId             0\n",
      "number                    0\n",
      "grid                      0\n",
      "positionText_x            0\n",
      "positionOrder             0\n",
      "points                    0\n",
      "laps                      0\n",
      "fastestLap                0\n",
      "rank                      0\n",
      "fastestLapTime            0\n",
      "max_speed                 0\n",
      "statusId                  0\n",
      "year                      0\n",
      "round                     0\n",
      "circuitId                 0\n",
      "grand_prix                0\n",
      "driverRef                 0\n",
      "nationality               0\n",
      "points_y                  0\n",
      "wins                      0\n",
      "company                   0\n",
      "nationality_y             0\n",
      "status                    0\n",
      "result_driver_standing    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "na_counts = test_data.isna().sum()\n",
    "\n",
    "print(na_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "racerId                     int64\n",
       "driverId                    int64\n",
       "constructorId               int64\n",
       "number                      int64\n",
       "grid                        int64\n",
       "positionText_x              int64\n",
       "positionOrder               int64\n",
       "points                    float64\n",
       "laps                        int64\n",
       "fastestLap                float64\n",
       "rank                        int64\n",
       "fastestLapTime            float64\n",
       "max_speed                 float64\n",
       "statusId                    int64\n",
       "year                        int64\n",
       "round                       int64\n",
       "circuitId                   int64\n",
       "grand_prix                  int64\n",
       "driverRef                   int64\n",
       "nationality                 int64\n",
       "points_y                  float64\n",
       "wins                        int64\n",
       "company                     int64\n",
       "nationality_y               int64\n",
       "status                      int64\n",
       "result_driver_standing      int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>racerId</th>\n",
       "      <th>driverId</th>\n",
       "      <th>constructorId</th>\n",
       "      <th>number</th>\n",
       "      <th>grid</th>\n",
       "      <th>positionText_x</th>\n",
       "      <th>positionOrder</th>\n",
       "      <th>points</th>\n",
       "      <th>laps</th>\n",
       "      <th>fastestLap</th>\n",
       "      <th>...</th>\n",
       "      <th>circuitId</th>\n",
       "      <th>grand_prix</th>\n",
       "      <th>driverRef</th>\n",
       "      <th>nationality</th>\n",
       "      <th>points_y</th>\n",
       "      <th>wins</th>\n",
       "      <th>company</th>\n",
       "      <th>nationality_y</th>\n",
       "      <th>status</th>\n",
       "      <th>result_driver_standing</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>997</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>13</td>\n",
       "      <td>18</td>\n",
       "      <td>8</td>\n",
       "      <td>4.0</td>\n",
       "      <td>70</td>\n",
       "      <td>69.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>70</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>19</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>298739826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>997</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>13</td>\n",
       "      <td>18</td>\n",
       "      <td>8</td>\n",
       "      <td>4.0</td>\n",
       "      <td>70</td>\n",
       "      <td>69.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>70</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>19</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>299218806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>997</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>13</td>\n",
       "      <td>18</td>\n",
       "      <td>8</td>\n",
       "      <td>4.0</td>\n",
       "      <td>70</td>\n",
       "      <td>69.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>70</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>19</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>299697786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>997</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>13</td>\n",
       "      <td>18</td>\n",
       "      <td>8</td>\n",
       "      <td>4.0</td>\n",
       "      <td>70</td>\n",
       "      <td>69.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>70</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>19</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>300176766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>997</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>13</td>\n",
       "      <td>18</td>\n",
       "      <td>8</td>\n",
       "      <td>4.0</td>\n",
       "      <td>70</td>\n",
       "      <td>69.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>70</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>19</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>300655746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>352923</th>\n",
       "      <td>1110</td>\n",
       "      <td>857</td>\n",
       "      <td>1</td>\n",
       "      <td>81</td>\n",
       "      <td>5</td>\n",
       "      <td>21</td>\n",
       "      <td>20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>46.738294</td>\n",
       "      <td>...</td>\n",
       "      <td>13</td>\n",
       "      <td>6</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>1880337225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>352924</th>\n",
       "      <td>1110</td>\n",
       "      <td>857</td>\n",
       "      <td>1</td>\n",
       "      <td>81</td>\n",
       "      <td>5</td>\n",
       "      <td>21</td>\n",
       "      <td>20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>46.738294</td>\n",
       "      <td>...</td>\n",
       "      <td>13</td>\n",
       "      <td>6</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>1881380625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>352925</th>\n",
       "      <td>1110</td>\n",
       "      <td>857</td>\n",
       "      <td>1</td>\n",
       "      <td>81</td>\n",
       "      <td>5</td>\n",
       "      <td>21</td>\n",
       "      <td>20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>46.738294</td>\n",
       "      <td>...</td>\n",
       "      <td>13</td>\n",
       "      <td>6</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>1881902325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>352926</th>\n",
       "      <td>1110</td>\n",
       "      <td>857</td>\n",
       "      <td>1</td>\n",
       "      <td>81</td>\n",
       "      <td>5</td>\n",
       "      <td>21</td>\n",
       "      <td>20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>46.738294</td>\n",
       "      <td>...</td>\n",
       "      <td>13</td>\n",
       "      <td>6</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>1882424025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>352927</th>\n",
       "      <td>1110</td>\n",
       "      <td>857</td>\n",
       "      <td>1</td>\n",
       "      <td>81</td>\n",
       "      <td>5</td>\n",
       "      <td>21</td>\n",
       "      <td>20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>46.738294</td>\n",
       "      <td>...</td>\n",
       "      <td>13</td>\n",
       "      <td>6</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>1882971810</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>352928 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        racerId  driverId  constructorId  number  grid  positionText_x  \\\n",
       "0           997         4              1      14    13              18   \n",
       "1           997         4              1      14    13              18   \n",
       "2           997         4              1      14    13              18   \n",
       "3           997         4              1      14    13              18   \n",
       "4           997         4              1      14    13              18   \n",
       "...         ...       ...            ...     ...   ...             ...   \n",
       "352923     1110       857              1      81     5              21   \n",
       "352924     1110       857              1      81     5              21   \n",
       "352925     1110       857              1      81     5              21   \n",
       "352926     1110       857              1      81     5              21   \n",
       "352927     1110       857              1      81     5              21   \n",
       "\n",
       "        positionOrder  points  laps  fastestLap  ...  circuitId  grand_prix  \\\n",
       "0                   8     4.0    70   69.000000  ...         70           3   \n",
       "1                   8     4.0    70   69.000000  ...         70           3   \n",
       "2                   8     4.0    70   69.000000  ...         70           3   \n",
       "3                   8     4.0    70   69.000000  ...         70           3   \n",
       "4                   8     4.0    70   69.000000  ...         70           3   \n",
       "...               ...     ...   ...         ...  ...        ...         ...   \n",
       "352923             20     0.0     0   46.738294  ...         13           6   \n",
       "352924             20     0.0     0   46.738294  ...         13           6   \n",
       "352925             20     0.0     0   46.738294  ...         13           6   \n",
       "352926             20     0.0     0   46.738294  ...         13           6   \n",
       "352927             20     0.0     0   46.738294  ...         13           6   \n",
       "\n",
       "        driverRef  nationality  points_y  wins  company  nationality_y  \\\n",
       "0               2           19      16.0     0        7              2   \n",
       "1               2           19      21.0     0        7              2   \n",
       "2               2           19      21.0     0        7              2   \n",
       "3               2           19      25.0     0        7              2   \n",
       "4               2           19      25.0     0        7              2   \n",
       "...           ...          ...       ...   ...      ...            ...   \n",
       "352923         23            1       5.0     0        7              2   \n",
       "352924         23            1       5.0     0        7              2   \n",
       "352925         23            1      17.0     0        7              2   \n",
       "352926         23            1      27.0     0        7              2   \n",
       "352927         23            1      34.0     0        7              2   \n",
       "\n",
       "        status  result_driver_standing  \n",
       "0            0               298739826  \n",
       "1            0               299218806  \n",
       "2            0               299697786  \n",
       "3            0               300176766  \n",
       "4            0               300655746  \n",
       "...        ...                     ...  \n",
       "352923       9              1880337225  \n",
       "352924       9              1881380625  \n",
       "352925       9              1881902325  \n",
       "352926       9              1882424025  \n",
       "352927       9              1882971810  \n",
       "\n",
       "[352928 rows x 26 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train_data.pop(\"position\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_val = validation_data.pop(\"position\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaler_standard = StandardScaler()\n",
    "# x_train = scaler_standard.fit_transform(train_data)\n",
    "# x_val = scaler_standard.fit_transform(validation_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = train_data\n",
    "x_val = validation_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_train = pd.DataFrame(x_train, columns=['number', 'grid', 'positionText_x','positionOrder','points','laps','fastestLap','rank','fastestLapTime','max_speed','statusId','year','round','circuitId','grand_prix','driverRef','nationality','points_y','wins','company','nationality_y','status', 'result_driver_standing'])\n",
    "# x_val = pd.DataFrame(x_val, columns=['number', 'grid', 'positionText_x','positionOrder','points','laps','fastestLap','rank','fastestLapTime','max_speed','statusId','year','round','circuitId','grand_prix','driverRef','nationality','points_y','wins','company','nationality_y','status', 'result_driver_standing'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>racerId</th>\n",
       "      <th>driverId</th>\n",
       "      <th>constructorId</th>\n",
       "      <th>number</th>\n",
       "      <th>grid</th>\n",
       "      <th>positionText_x</th>\n",
       "      <th>positionOrder</th>\n",
       "      <th>points</th>\n",
       "      <th>laps</th>\n",
       "      <th>fastestLap</th>\n",
       "      <th>...</th>\n",
       "      <th>circuitId</th>\n",
       "      <th>grand_prix</th>\n",
       "      <th>driverRef</th>\n",
       "      <th>nationality</th>\n",
       "      <th>points_y</th>\n",
       "      <th>wins</th>\n",
       "      <th>company</th>\n",
       "      <th>nationality_y</th>\n",
       "      <th>status</th>\n",
       "      <th>result_driver_standing</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2082849</th>\n",
       "      <td>90</td>\n",
       "      <td>30</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>10.0</td>\n",
       "      <td>58</td>\n",
       "      <td>29</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>40</td>\n",
       "      <td>11</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>33</td>\n",
       "      <td>19404120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2082850</th>\n",
       "      <td>90</td>\n",
       "      <td>30</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>10.0</td>\n",
       "      <td>58</td>\n",
       "      <td>29</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>40</td>\n",
       "      <td>11</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>33</td>\n",
       "      <td>19431390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2082851</th>\n",
       "      <td>90</td>\n",
       "      <td>30</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>10.0</td>\n",
       "      <td>58</td>\n",
       "      <td>29</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>40</td>\n",
       "      <td>11</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>33</td>\n",
       "      <td>19463205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2082852</th>\n",
       "      <td>90</td>\n",
       "      <td>30</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>10.0</td>\n",
       "      <td>58</td>\n",
       "      <td>29</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>40</td>\n",
       "      <td>11</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>33</td>\n",
       "      <td>19496535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2082853</th>\n",
       "      <td>90</td>\n",
       "      <td>30</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>10.0</td>\n",
       "      <td>58</td>\n",
       "      <td>29</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>40</td>\n",
       "      <td>11</td>\n",
       "      <td>31.0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>33</td>\n",
       "      <td>19529865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2830096</th>\n",
       "      <td>899</td>\n",
       "      <td>17</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>18.0</td>\n",
       "      <td>71</td>\n",
       "      <td>51</td>\n",
       "      <td>...</td>\n",
       "      <td>18</td>\n",
       "      <td>4</td>\n",
       "      <td>65</td>\n",
       "      <td>1</td>\n",
       "      <td>61.5</td>\n",
       "      <td>2</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>33</td>\n",
       "      <td>401167805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2830097</th>\n",
       "      <td>899</td>\n",
       "      <td>17</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>18.0</td>\n",
       "      <td>71</td>\n",
       "      <td>51</td>\n",
       "      <td>...</td>\n",
       "      <td>18</td>\n",
       "      <td>4</td>\n",
       "      <td>65</td>\n",
       "      <td>1</td>\n",
       "      <td>69.5</td>\n",
       "      <td>2</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>33</td>\n",
       "      <td>660484266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2830098</th>\n",
       "      <td>899</td>\n",
       "      <td>17</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>18.0</td>\n",
       "      <td>71</td>\n",
       "      <td>51</td>\n",
       "      <td>...</td>\n",
       "      <td>18</td>\n",
       "      <td>4</td>\n",
       "      <td>65</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>33</td>\n",
       "      <td>1409316096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2830099</th>\n",
       "      <td>899</td>\n",
       "      <td>17</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>18.0</td>\n",
       "      <td>71</td>\n",
       "      <td>51</td>\n",
       "      <td>...</td>\n",
       "      <td>18</td>\n",
       "      <td>4</td>\n",
       "      <td>65</td>\n",
       "      <td>1</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>33</td>\n",
       "      <td>1409846712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2830100</th>\n",
       "      <td>899</td>\n",
       "      <td>17</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>18.0</td>\n",
       "      <td>71</td>\n",
       "      <td>51</td>\n",
       "      <td>...</td>\n",
       "      <td>18</td>\n",
       "      <td>4</td>\n",
       "      <td>65</td>\n",
       "      <td>1</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>33</td>\n",
       "      <td>1410377328</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>718091 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         racerId  driverId  constructorId  number  grid  positionText_x  \\\n",
       "2082849       90        30              6       1     1               0   \n",
       "2082850       90        30              6       1     1               0   \n",
       "2082851       90        30              6       1     1               0   \n",
       "2082852       90        30              6       1     1               0   \n",
       "2082853       90        30              6       1     1               0   \n",
       "...          ...       ...            ...     ...   ...             ...   \n",
       "2830096      899        17              9       2     4              11   \n",
       "2830097      899        17              9       2     4              11   \n",
       "2830098      899        17              9       2     4              11   \n",
       "2830099      899        17              9       2     4              11   \n",
       "2830100      899        17              9       2     4              11   \n",
       "\n",
       "         positionOrder  points  laps  fastestLap  ...  circuitId  grand_prix  \\\n",
       "2082849              1    10.0    58          29  ...          1           1   \n",
       "2082850              1    10.0    58          29  ...          1           1   \n",
       "2082851              1    10.0    58          29  ...          1           1   \n",
       "2082852              1    10.0    58          29  ...          1           1   \n",
       "2082853              1    10.0    58          29  ...          1           1   \n",
       "...                ...     ...   ...         ...  ...        ...         ...   \n",
       "2830096              2    18.0    71          51  ...         18           4   \n",
       "2830097              2    18.0    71          51  ...         18           4   \n",
       "2830098              2    18.0    71          51  ...         18           4   \n",
       "2830099              2    18.0    71          51  ...         18           4   \n",
       "2830100              2    18.0    71          51  ...         18           4   \n",
       "\n",
       "         driverRef  nationality  points_y  wins  company  nationality_y  \\\n",
       "2082849         40           11       8.0     0        4              7   \n",
       "2082850         40           11      11.0     0        4              7   \n",
       "2082851         40           11      11.0     0        4              7   \n",
       "2082852         40           11      21.0     1        4              7   \n",
       "2082853         40           11      31.0     2        4              7   \n",
       "...            ...          ...       ...   ...      ...            ...   \n",
       "2830096         65            1      61.5     2       17              0   \n",
       "2830097         65            1      69.5     2       17              0   \n",
       "2830098         65            1       4.0     0       17              0   \n",
       "2830099         65            1       6.0     0       17              0   \n",
       "2830100         65            1      24.0     0       17              0   \n",
       "\n",
       "         status  result_driver_standing  \n",
       "2082849      33                19404120  \n",
       "2082850      33                19431390  \n",
       "2082851      33                19463205  \n",
       "2082852      33                19496535  \n",
       "2082853      33                19529865  \n",
       "...         ...                     ...  \n",
       "2830096      33               401167805  \n",
       "2830097      33               660484266  \n",
       "2830098      33              1409316096  \n",
       "2830099      33              1409846712  \n",
       "2830100      33              1410377328  \n",
       "\n",
       "[718091 rows x 26 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.ensemble import RandomForestRegressor\n",
    "# rf = RandomForestRegressor(n_estimators=100)\n",
    "# rf.fit(x_train,y_train)\n",
    "# y_train_pred = rf.predict(x_train)\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "tree_regressor = DecisionTreeRegressor(max_depth=5)\n",
    "tree_regressor.fit(x_train,y_train)\n",
    "y_train_pred = tree_regressor.predict(x_train)\n",
    "y_val_pred = tree_regressor.predict(x_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error (MSE) on training data: 8.565202507790636\n",
      "Mean Squared Error (MSE) on training data: 8.467656630428241\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "mse = mean_squared_error(y_train, y_train_pred)\n",
    "print(f\"Mean Squared Error (MSE) on training data: {mse}\")\n",
    "mse = mean_squared_error(y_val, y_val_pred)\n",
    "print(f\"Mean Squared Error (MSE) on training data: {mse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjIAAAHHCAYAAACle7JuAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuNSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/xnp5ZAAAACXBIWXMAAA9hAAAPYQGoP6dpAABPg0lEQVR4nO3deXwTdf4/8NckadMzKS09oYWCXKUc5ZRDRUEBEQEPFEEOrxVBZXFV+O4ioIsF/brrV+UHKiugIIquIKCiFQREoFBKuYqcBQq9aEubnmmbzO+PadKGtpBCksnxej4e8yCZmaTvDEpe/VwjiKIogoiIiMgFKeQugIiIiOhmMcgQERGRy2KQISIiIpfFIENEREQui0GGiIiIXBaDDBEREbksBhkiIiJyWQwyRERE5LIYZIiIiMhlMcgQkVMTBAELFiyQuwwiclIMMkQkux9//NHpwkp5eTkWLFiAHTt2yF0KEV2HSu4CiIh+/PFHLF26tNEwU1FRAZXK8f9UlZeXY+HChQCAIUOGOPznE5F12CJDRE7Nx8dHliBjL2VlZXKXQORWGGSIPMyCBQsgCALOnDmDqVOnIigoCFqtFtOmTUN5eXmz3uvPP//EI488guDgYPj4+KBPnz7YtGmTxTnV1dVYuHAhOnToAB8fH4SEhGDw4MFISkoCAEydOhVLly4FII2HMW0m146RMdV/6tQpTJo0CVqtFqGhoZg3bx5EUURmZibGjBkDjUaDiIgIvPfeexb1VFVV4Y033kDv3r2h1Wrh7++PO+64A7/99pv5nPPnzyM0NBQAsHDhQnNN9evYvn077rjjDvj7+yMoKAhjxozBiRMnGr3W6enpeOKJJ9CiRQsMHjwYAJCTk4Np06ahdevWUKvViIyMxJgxY3D+/Plm/R0QeTr3+TWHiJpl/PjxiI2NRWJiIlJTU7FixQqEhYVhyZIlVr3++PHjGDRoEFq1aoU5c+bA398f69evx9ixY/Hf//4X48aNAyB9mScmJuKZZ55Bv379oNPpkJKSgtTUVNx77734y1/+gqysLCQlJeGLL76wuv7HHnsMXbp0weLFi/HDDz/gn//8J4KDg/Hxxx/jnnvuwZIlS7B27Vr87W9/Q9++fXHnnXcCAHQ6HVasWIEJEybg2WefRUlJCf7zn/9g+PDh2L9/P3r27InQ0FAsW7YM06dPx7hx4/DQQw8BALp37w4A+PXXXzFy5Ei0a9cOCxYsQEVFBT788EMMGjQIqampaNu2rUWtjz76KDp06IC3334boigCAB5++GEcP34cL774Itq2bYu8vDwkJSXh4sWLDV5PRNchEpFHmT9/vghAfOqppyz2jxs3TgwJCbH6fYYOHSp269ZNrKysNO8zGo3iwIEDxQ4dOpj39ejRQxw1atR132vGjBliU/8cARDnz5/foP7nnnvOvK+mpkZs3bq1KAiCuHjxYvP+q1evir6+vuKUKVMsztXr9RY/4+rVq2J4eLjFNbly5UqDn23Ss2dPMSwsTCwoKDDvO3z4sKhQKMTJkyc3qHXChAkNfh4A8d133238ghCR1di1ROShnn/+eYvnd9xxBwoKCqDT6W742sLCQmzfvh3jx49HSUkJ8vPzkZ+fj4KCAgwfPhynT5/G5cuXAQBBQUE4fvw4Tp8+bdP6n3nmGfNjpVKJPn36QBRFPP300+b9QUFB6NSpE86dO2dxrre3NwDAaDSisLAQNTU16NOnD1JTU2/4c7Ozs5GWloapU6ciODjYvL979+6499578eOPPzZ4zbXX2tfXF97e3tixYweuXr1q/YcmogYYZIg8VExMjMXzFi1aAIBVX6xnzpyBKIqYN28eQkNDLbb58+cDAPLy8gAAb775JoqKitCxY0d069YNr776Ko4cOWLz+rVaLXx8fNCyZcsG+6/9TKtXr0b37t3NY3ZCQ0Pxww8/oLi4+IY/98KFCwCATp06NTjWpUsX5OfnNxjQGxsba/FcrVZjyZIl+OmnnxAeHo4777wT77zzDnJycm7484nIEoMMkYdSKpWN7hdrx3Bcj9FoBAD87W9/Q1JSUqPbbbfdBgC48847cfbsWXz22WeIj4/HihUr0KtXL6xYscLm9VvzmdasWYOpU6eiffv2+M9//oOtW7ciKSkJ99xzj/lz2Zqvr2+DfbNmzcKpU6eQmJgIHx8fzJs3D126dMGhQ4fsUgORu+JgXyJqtnbt2gEAvLy8MGzYsBueHxwcjGnTpmHatGkoLS3FnXfeiQULFpi7h+rPUrK3b7/9Fu3atcN3331n8XNNLUkmTdXUpk0bAMDJkycbHPvzzz/RsmVL+Pv7W1VL+/bt8corr+CVV17B6dOn0bNnT7z33ntYs2aNtR+HyOOxRYaImi0sLAxDhgzBxx9/jOzs7AbHr1y5Yn5cUFBgcSwgIAC33XYb9Hq9eZ/pi7+oqMg+BddjarWp30qTnJyMvXv3Wpzn5+fXaE2RkZHo2bMnVq9ebXHs2LFj+OWXX3D//fffsIby8nJUVlZa7Gvfvj0CAwMtrgsR3RhbZIjopixduhSDBw9Gt27d8Oyzz6Jdu3bIzc3F3r17cenSJRw+fBgAEBcXhyFDhqB3794IDg5GSkoKvv32W8ycOdP8Xr179wYAvPTSSxg+fDiUSiUef/xxu9T9wAMP4LvvvsO4ceMwatQoZGRkYPny5YiLi0Npaan5PF9fX8TFxeHrr79Gx44dERwcjPj4eMTHx+Pdd9/FyJEjMWDAADz99NPm6ddardaqWy2cOnUKQ4cOxfjx4xEXFweVSoUNGzYgNzfXbp+byG3JOmeKiBzONCX4ypUrFvtXrlwpAhAzMjKsfq+zZ8+KkydPFiMiIkQvLy+xVatW4gMPPCB+++235nP++c9/iv369RODgoJEX19fsXPnzuKiRYvEqqoq8zk1NTXiiy++KIaGhoqCIFhMxUYT06+vrX/KlCmiv79/gxrvuususWvXrubnRqNRfPvtt8U2bdqIarVaTEhIELds2SJOmTJFbNOmjcVr9+zZI/bu3Vv09vZuUMevv/4qDho0SPT19RU1Go04evRoMT093eL1TdWan58vzpgxQ+zcubPo7+8varVasX///uL69eubvthE1ChBFK0Y2UdERETkhDhGhoiIiFwWx8gQkYXi4mJUVFRc95yIiAgHVUNEdH3sWiIiC1OnTsXq1auvew7/2SAiZ8EgQ0QW0tPTkZWVdd1zrFk7hojIERhkiIiIyGVxsC8RERG5LLcf7Gs0GpGVlYXAwECHLoNOREREN08URZSUlCAqKgoKRdPtLm4fZLKyshAdHS13GURERHQTMjMz0bp16yaPu32QCQwMBCBdCI1GI3M1REREZA2dTofo6Gjz93hT3D7ImLqTNBoNgwwREZGLudGwEA72JSIiIpfFIENEREQui0GGiIiIXBaDDBEREbksBhkiIiJyWQwyRERE5LIYZIiIiMhlMcgQERGRy2KQISIiIpfl9iv7EhERkR0YDcCFPUBpLhAQDrQZCCiUDi+DQYaIiIiaJ30TsPV1QJdVt08TBYxYAsQ96NBS2LVERERE1kvfBKyfbBliAECXLe1P3+TQchhkiIiIyDpGg9QSA7GRg7X7ts6RznMQdi0RERGRJaMBKM0DSrKlTZcl/Zl1uGFLjAUR0F2Wxs7E3uGQUhlkiIiIPEmlrl44yQFKsqRuIXNoyZYG8Iq30KpSmmu7em+AQYaIiMgdGKprg0n9cFIbVkwtKiU5QFWpde8nKKTZSIGR0qaJBGr0wKEvbvzagPBb+yzNwCBDRETkzEQRqLha11pybXePaX/ZFTQ+dqURai0QGCGFk8Co2sdRdYElMBLwDwOU18QEowE4u036eY3+LEF6nzYDb/FDW49BhoiISC7VlXUtJY118ZhaVGoqrXs/haquBcUinNSGFVNoUQfcXL0KpTTFev1kAAIsw4wg/TFisUPXk2GQISIisjWjESgvaCSc1Ovi0WUBFYXWv6dvsGWLSf1wYtrn1xJQ2HlCctyDwPjPm1hHZrHD15FhkCEiImqOqrLrd/GYgoqx2rr3U6qv38Vj2rx87Pu5miPuQaDzKK7sS0RE5DTMU46b6OLR1QYUfbGVbygA/qFNd/GYgopvC0AQ7PrR7EKhdNgU6+thkCEiIvuS+548ogjodU3P4jE9Ls0FRKN17+nlf50uHtPzCEDpZd/PRgwyRERkR/a+J09NlRRAmuriMa2VUl1m3fsJSils1e/WaazbRx3omq0obohBhoiI7MN0T55rp+ma7skz/vOmw4xpynGDcHJNi0rZFevr8dHWCyemVpPIunASGAkEhMkyzoNuHoMMERHZ3g3vySMAP8yWphWX5lqGE1MrikFv3c9SeNVrOWmki8cUWrz9bfgByVkwyBARke1d2HPje/KUXQG+e/b67+MXcv0uHk2UNC3Z3lOOyWkxyJBrkXvQIBE1ThSBwnPApQNAZjJwKsm617XsCER0twwn9aceq9T2rZtcHoMMuQ57DxokIutVVwBZh6TQklkbXsrzm/8+o/7lFFN4yXUxyJBruJVBg0R064ovWYaWnCOAscbyHKU3ENkTiO4HtOoDbJ1Texdk57gnD7knBhlyftYMGtw6R1plkt1MRLeupkoKKpnJQOZ+aStpZLxLQDgQ3V8KLtH9gcgell1BCqVT3ZOH3BODDDk/awYN6i4Dh9cB3R9veLdWIrq+klzg0v660JJ1qOGMIUEJRHSrCy2t+wJBMddfS8XJ7slD7on/4pPzK8217rzvZwBbZgNhXaR/cCO6AxHxQHhXaf0IIgIMNUDe8brQcmk/cPV8w/N8g2tDSz+gdT+gVa+bm77sRPfkIffEIEPOLyDcuvNUPtKaFNlp0lZfUBvLcBPRDdBGc2VOcn/lhcClFKmb6NJ+4NLBRla5FaRfAEyhJbo/ENLedv9/OMk9ecg9MciQ82szUFpLorygiRNqBw2+dBgovgjkHgNyjtZuxwDdJaDogrT9uaXuZT5aILxbbcCpDTehnTndk1yX0Qjkn6oLLZn7pefXUmuA1n3quoha92GrJbksWYPMrl278O677+LgwYPIzs7Ghg0bMHbs2EbPff755/Hxxx/j3//+N2bNmuXQOklmOUcAfWkTB+sNGlR5Sb9FhrQH4sbUnVJe2DDcXPkTqCwGLuyWNhOFCmjZyTLchHcD/EPs9vGIblqlDrh8sK6L6NIB6b/ra4XcVhdaovsDoZ3YtUNuQ9YgU1ZWhh49euCpp57CQw891OR5GzZswL59+xAVFeXA6sgpXD0PrB0vDTwMj5dCSUkzBw36BQOxd0qbSU0VkH+yLtjkHJEeVxZJ4wfyjgNH6r1HYFTDcBPcjquJkuOYFpwzhZbM/UDucTSYzeflB7TqXRdaWvdlECe3JmuQGTlyJEaOHHndcy5fvowXX3wRP//8M0aNGuWgysgplBcCax4ByvKk4DDtR2mwoS0GDaq8a4NJt7p9Yu3sp2vDzdWM2hvVZQGnf64738tfGkhcP9yEx/F+LmQbVeXS7KH6s4kaW3AuKKY2sNQOzA2P58w98ihO/V+70WjEk08+iVdffRVdu3a16jV6vR56fd20QZ1OZ6/yyJ6qK4F1E4CC04CmFTBxPeCjkY7Za9CgIADa1tLWqV7A1pdIv/mau6aOAnnp0oDJS7W/Hde9idSMXz/cRHSTll/nwGJqiijWLThnWuI/52jjC85FJdS1tkT3k/7bIvJgTh1klixZApVKhZdeesnq1yQmJmLhwoV2rIrszmgENjwHZO4D1Fpg4rdSF5Jc1IFAzO3SZmKoAQrPWoab3GNSS1HBaWk7vqHufL+WDcNNyw6A0svxn4fkV6MHso/UtrbUrpbb6IJzEXXrtkT3a7jgHBE5b5A5ePAg/u///g+pqakQmvGb7Ny5czF79mzzc51Oh+joaHuUSPbyyz+A9O8BhRfw+Bqpu8bZKFXSgMnQTkC3R+r2l+Y1DDf5p6QugXM7pM38HmogrLNluImI5+wRd2RecK42tFx3wbn+deu3cIkAohty2iDz+++/Iy8vDzExMeZ9BoMBr7zyCt5//32cP3++0dep1Wqo1fyNxWXtWwbsWyo9HrvMcoCuKwgIA24bKm0m1RVA3gnLcJNzDKgqAbIPS1t9QTHSejfh8XXjeG60gio5j2sXnMtMlqb+X8svpG5cS3Q/qcuI46uIms1pg8yTTz6JYcOGWewbPnw4nnzySUybNk2mqsiu0r8Hts6VHg9bAHR/VNZybMbLV1oVtVWvun1Go/TlZg42tSGnOBMouiht9de8UWtrVymOr2u5Ce0CePk4/vOQpfLCunEtmfuBy6lNLDgXVxdaovtLs94YTolumaxBprS0FGfOnDE/z8jIQFpaGoKDgxETE4OQEMspg15eXoiIiECnTp0cXSrZ28V9wH+fBSACfZ8BBs2SuyL7UiiA4Fhpqz91vOKq1FpjDjdHgLw/AX0xcOEPaTMRlFLXVv1wE9Ed8G/p+M/jKYxGadp+/btAF5xueJ5aUzsgtza4tOrNLkMiO5E1yKSkpODuu+82PzeNbZkyZQpWrVolU1XkcPmngXWPS2MGOt0PjHzHc39T9W0hzcqqPzOrpkoaZ1M/3OQcAyoKpdlTeenA0fV15wdGWnZLRZjWvOECaM1WqQMup9SFlkspUqi8VkgHy9aWlp24xhCRgwiiKIo3Ps116XQ6aLVaFBcXQ6PRyF0OXas0D1gxTOpmadUHmLIZ8PaTuyrnJ4rS3YRz6613k3NMWjDt2gXSAGmRtLA4y3ATFgeoAxxeutOqv+CcqZsoLx1NLjhX/y7QfsGylEzkzqz9/nbaMTLkAfSlwNpHpRDTIhZ44muGGGsJAqBtJW0dh9ft15dKX771w03ucaC6XGpZuJxS/02klpr64Saim9Si4wktYlXlQFaq5V2gG7ufV1AbyynQYV254ByRE2GLDMnDUAN8NQE4/Ys0e+PpJOkeSWR7RoPU0mDqkjINLC7Nafx83+CG4aZlR9de80YUpYHU9UNLowvOqYGonvVaW/oBgVbefZ2IbMra728GGXI8UQQ2vwykrgZUvlJ3UnRfuavyPKVXgNyjluEm/xQgGhqeq/SW7gxeP9yExwO+QQ4v2yqmBefq3wW6JLvheYGRlqElsjsXnCNyEuxaIuf1+/9KIQYC8PAKhhi5BIQCAfcA7e+p21ddCVw5YRluco8Bel1ti84Ry/fQxtStWGwKNy3a3lzXlNFw8/fRKsmpG9ty6QCQldZwwTmFqm7BOdMS/9rWntGNRuTGGGTIsdLWAdv/KT2+/12gywPy1kOWvHykhdmiEur2iWLtmjf1w81Raa2b4trt5I9156s1tTfTrBduwuKuv+ZN+iZg6+vSAGYTTRQwYknDO5sbaqRwZb4LdLJUy7X8QixDS1QCx2ARuSF2LZHjnP0NWPuINC5h4EvAfW/JXRHdiooiy5tp5h6VVjA2VDU8V1BK42zM95uqXfMmIFQKMesno+Fsq9qWkrH/Txq3Y+oiunxQGrx87bnhXaVuItNquVxwjsilcYxMLQYZJ5FzFPhspLQsf/zDwEMruM6GOzJUS+sCmda7Ma1909hsIADwDwMqixt2A92IWit1Sbauv+Ac//8mciccI0POo/iSNM26qgRoM1i6hxJDjHtSekk3+QyPA3o8Ju0TRWkMi6nVxtSCU3AWKMuz7n01rYF2Q+otONeR/w0REQAGGbK3iiJgzSPSjJHQztLdrDkrxLMIAqCJlLaO99XtryoD9nwE7Hj7xu9x70LLu4wTEdXirzRkPzV64OtJ0iyYgAhg4rfSEvxEgHSn5zYDrTs3gGu5EFHjGGTIPoxG4PuZwPnfAe8AYOI3QFC03FWRs2kzUJqdhKYG5QqAppX1gYeIPA6DDNnH9jelGxkqVMD4z6WFxoiupVBKU6wBNAwztc9HLOYNL4moSQwyZHsHVgC7/y09Hv0BcNtQeesh5xb3oBR2NZGW+zVR0v5r15EhIqqHg33Jtv78EfjxVenxkP8BEibKWw+5hrgHgc6jbn5lXyLyWAwyZDuXDgLfPgWIRiDhSeCu1+SuiFyJQgnE3iF3FUTkYti1RLZReA74cjxQUwHcNgx44N9cVZWIiOyOQYZuXVmBtFZMeb607Pyjq6SF0YiIiOyMQYZuTVU5sO4xoPCsdCfkid8A6kC5qyIiIg/BIEM3z2gAvnsWuHQA8AkCJn0LBEbIXRUREXkQBhm6OaIIbJ0D/LkFUHoDE9YBoZ3kroqIiDwMgwzdnD0fAvs/kR6P+5grrxIRkSwYZKj5jn4LJM2THt+3CIh/SN56iIjIYzHIUPOc3w1snC497v88MGCGvPUQEZFHY5Ah6+X9CXz1BGCoArqMBoa/zbViiIhIVgwyZB1dNrD2EaCyGIjuDzz0KZePJyIi2THI0I3pS4AvHwWKM4Hg9sDj6wAvX7mrIiIiYpChGzBUA+snAzlHAf9QYNJ/Af8QuasiIiICwCBD1yOKwOZZwNntgJcf8MTXQHCs3FURERGZMchQ03YsBtLWAIICeGQl0Kq33BURERFZYJChxqV+AexcLD0e9R7QaYS89RARETWCQYYaOv0rsPll6fEdrwB9npK3HiIioiYwyJClrDTgmymAaAC6PwbcM0/uioiIiJrEIEN1rl4AvhwPVJUCsXcBD37EBe+IiMipMciQpLwQWPsoUJoLhHUFHvsCUHnLXRUREdF1yRpkdu3ahdGjRyMqKgqCIGDjxo3mY9XV1Xj99dfRrVs3+Pv7IyoqCpMnT0ZWVpZ8Bbur6krgq4lA/kkgMAqY+A3go5W7KiIiohuSNciUlZWhR48eWLp0aYNj5eXlSE1Nxbx585CamorvvvsOJ0+exIMPPihDpW7GaAAyfpfuYn1uF7DhL8DFPYBaA0z6FtC2krtCIiIiq6jk/OEjR47EyJEjGz2m1WqRlJRkse+jjz5Cv379cPHiRcTExDiiRPeTvgnY+jqgu6ZlS1BK3UnhXeWpi4iI6CbIGmSaq7i4GIIgICgoqMlz9Ho99Hq9+blOp3NAZS4ifZN0uwGIDY+JBqCS14qIiFyLywz2raysxOuvv44JEyZAo9E0eV5iYiK0Wq15i46OdmCVTsxokFpiGgsxAAAB2DpHOo+IiMhFuESQqa6uxvjx4yGKIpYtW3bdc+fOnYvi4mLzlpmZ6aAqndyFPQ27kyyIgO6ydB4REZGLcPquJVOIuXDhArZv337d1hgAUKvVUKvVDqrOhZTm2vY8IiIiJ+DUQcYUYk6fPo3ffvsNISEhcpfkugLCbXseERGRE5A1yJSWluLMmTPm5xkZGUhLS0NwcDAiIyPxyCOPIDU1FVu2bIHBYEBOTg4AIDg4GN7eXKytWdoMBALCgNK8Jk4QAE2UdB4REZGLkDXIpKSk4O677zY/nz17NgBgypQpWLBgATZt2gQA6Nmzp8XrfvvtNwwZMsRRZboPtbaJIFN7G4IRiwGF0qElERER3QpZg8yQIUMgik3NosF1j1Ez7VsGFJwGVD7Sqr31x8JooqQQE8fFBomIyLU49RgZspH8M8D2t6THI5cACU9Ks5NKc6UxMW0GsiWGiIhcEoOMuzMagO9nADWVQLshQK8p0h2tY++QuzIiIqJb5hLryNAtSP4YyNwHeAcCD34ohRgiIiI3wSDjzgrOAtvelB7f9xYQxPtTERGRe2GQcVdGA7DxBaCmQupS6j1V7oqIiIhsjkHGXe3/pLZLKQAY/QG7lIiIyC0xyLijgrPArwulx/e+CbRoI289REREdsIg426MRuD7mVKXUuydQJ+n5K6IiIjIbhhk3M3+T4CLewAvf+DBj9ilREREbo1Bxp0UnAV+XSA9vo9dSkRE5P4YZNyF0QhselHqUmp7B9CbXUpEROT+GGTcxYEVwIU/pC6lMR8BCv7VEhGR++O3nTsoPAf8Ol96fO9CoEVbWcshIiJyFAYZV2c0At+/CFSXS11KfZ6WuyIiIiKHYZBxdSn/AS7srp2l9CG7lIiIyKPwW8+VFWYASfW6lIJj5a2HiIjIwRhkXJVpllJ1GdBmMLuUiIjIIzHIuKqU/wDnfwe8/IAx7FIiIiLPxG8/V3T1fF2X0rAFQHA7OashIiKSDYOMqzHdS6m6DGgzCOj7rNwVERERyYZBxtUcXCl1Kal8ufAdERF5PH4LupKrF4CkN6TH7FIiIiJikHEZoghsmglUlQIxA4F+z8ldERERkewYZFzFwZVAxi52KREREdXDb0NXUHQR+GWe9HjYfCCkvbz1EBEROQkGGWcnitLCd1WlQMwAoN9f5K6IiIjIaajkLoAaYTQAF/YApbnA5VTg3I7aLqWl7FIiIiKqh0HG2aRvAra+DuiyLPfHP8QuJSIiomvw13tnkr4JWD+5YYgBgLQvpeNERERkxiDjLIwGqSUGYtPnbJ0jnUdEREQAGGScx4U9jbfEmImA7rJ0HhEREQFgkHEepbm2PY+IiMgDMMg4i4Bw255HRETkAWQNMrt27cLo0aMRFRUFQRCwceNGi+OiKOKNN95AZGQkfH19MWzYMJw+fVqeYu2tzUBAE3WdEwRA00o6j4iIiADIHGTKysrQo0cPLF26tNHj77zzDj744AMsX74cycnJ8Pf3x/Dhw1FZWengSh1AoQR6PNHEQUH6Y8Ri6TwiIiICIPM6MiNHjsTIkSMbPSaKIt5//3384x//wJgxYwAAn3/+OcLDw7Fx40Y8/vjjjizV/gzVQPr30mPvAGklXxNNlBRi4h6UpzYiIiIn5bQL4mVkZCAnJwfDhg0z79Nqtejfvz/27t3rfkHmwH+AgtOAX0tg5gEg97g0sDcgXOpOYksMERFRA04bZHJycgAA4eGWg1vDw8PNxxqj1+uh1+vNz3U6nX0KtKXyQmBHovT4nn8AfsFA7B3y1kREROQC3G7WUmJiIrRarXmLjo6Wu6Qb27EYqCwCwuOBXpPlroaIiMhlOG2QiYiIAADk5lqum5Kbm2s+1pi5c+eiuLjYvGVmZtq1zlt25SRwYIX0ePjb7EIiIiJqBqcNMrGxsYiIiMC2bdvM+3Q6HZKTkzFgwIAmX6dWq6HRaCw2p/bz3wHRAHQaBbS7S+5qiIiIXIqsY2RKS0tx5swZ8/OMjAykpaUhODgYMTExmDVrFv75z3+iQ4cOiI2Nxbx58xAVFYWxY8fKV7QtnU4CziQBCi/gvrfkroaIiMjlyBpkUlJScPfdd5ufz549GwAwZcoUrFq1Cq+99hrKysrw3HPPoaioCIMHD8bWrVvh4+MjV8m2Y6iWWmMAoP9fgJD28tZDRETkggRRFK9zu2XXp9PpoNVqUVxc7FzdTMmfAD+9CviFAC+mAr5BcldERETkNKz9/nbaMTJurbwQ2PG29PjuvzPEEBER3SQGGTnsfAeouAqEdQV6TZG7GiIiIpfFIONoV04BBz6VHo94G1A67ZqERERETo9BxtF++QdgrAE63Q+0GyJ3NURERC6NQcaRzvwKnP65drr1P+WuhoiIyOUxyDiKoYbTrYmIiGyMQcZRDq4ErvwJ+AYDd74qdzVERERugUHGESquAr/VTre+h9OtiYiIbIVBxhF2vgtUFAKhXYBeU+WuhoiIyG0wyNhb/hlg/8fSY063JiIisikGGXszTbfuOAJof4/c1RAREbkVBhl7OrsdOPUToFBxujUREZEdMMjYS/3p1v2eA1p2kLceIiIiN8QgYy+pq4G8dMC3BXDXa3JXQ0RE5JYYZOyhogj4bZH0+O6/S2GGiIiIbI5Bxh52vQuUFwChnYHe0+SuhoiIyG0xyNhawVkguXa69fBFnG5NRERkRwwytvbLPMBYDXS4D7htmNzVEBERuTUGGVs6twM4+QMgKIH7FsldDRERkdtjkLEVQw2w9X+kx/2eBUI7ylsPERGRB2CQsZVDnwN5xwGfIOCu1+WuhoiIyCNwJOpNMBhF7M8oRF5JJcICfdAvUgnl9tqVe+/+H8AvWN4CiYiIPASDTDNtPZaNhZvTkV1cad63yP9rTDQUAC07An2ekrE6IiIiz8Ig0wxbj2Vj+ppUCDDidsWfCEMRBBjxaM1mQABSOv0NfZRecpdJRETkMRhkrGQwili4OR33KfZjvtfniBIKLY4fM7TBiyktsXuoCKVCkKlKIiIiz8LBvlban1GI7iW7sMzrfUTAMsSIItBVcQHdS3Zhf0ZhE+9AREREtsYgY6U8XRnme30OALi2wUUQABHAfK8vkKcrc3xxREREHopBxkq3lR9FlFDYIMSYKAQgSijAbeVHHVsYERGRB2OQsVKXwHKbnkdERES3jkHGSorACJueR0RERLeOQcZabQYCmiiIaLxvSYQAaFpJ5xEREZFDMMhYS6EERiyBADQIM0YRAERgxGLpPCIiInIIBpnmiHsQGP85BE2kxe4chOA1xauo6fSATIURERF5Ji6I11xxDwKdRwEX9gCluajxC8ODa8uRX27AqDP5GNIpTO4KiYiIPIZTt8gYDAbMmzcPsbGx8PX1Rfv27fHWW29BFEV5C1Mogdg7gG6PQNX+Tozq0RoAsPHQZXnrIiIi8jBO3SKzZMkSLFu2DKtXr0bXrl2RkpKCadOmQavV4qWXXpK7PLOxCa2weu8F/Hw8F2X6GvirnfqyEhERuQ2nbpHZs2cPxowZg1GjRqFt27Z45JFHcN9992H//v1yl2ahZ3QQYlv6o6LagJ+P58hdDhERkcdoVpB55513UFFRYX7+xx9/QK/Xm5+XlJTghRdesFlxAwcOxLZt23Dq1CkAwOHDh7F7926MHDnSZj/DFgRBwNierQAAG9i9RERE5DDNCjJz585FSUmJ+fnIkSNx+XLdF3d5eTk+/vhjmxU3Z84cPP744+jcuTO8vLyQkJCAWbNmYeLEiU2+Rq/XQ6fTWWyOMDYhCgDwx5l85OkqHfIziYiIPF2zgsy1g2ztPeh2/fr1WLt2Lb788kukpqZi9erV+N///V+sXr26ydckJiZCq9Wat+joaLvWaNImxB+9YoJgFIFNh7Mc8jOJiIg8nVOPkXn11VfNrTLdunXDk08+ib/+9a9ITExs8jVz585FcXGxecvMzHRYveN6SbOX2L1ERETkGE4dZMrLy6FQWJaoVCphNBqbfI1arYZGo7HYHOWBbpHwUgo4nqXDqdySG7+AiIiIbkmz5wmvWLECAQEBAICamhqsWrUKLVu2BACL8TO2MHr0aCxatAgxMTHo2rUrDh06hH/961946qmnbPpzbKWFvzeGdApDUnouNhy6jNdHdJa7JCIiIrcmiM0Y6NK2bVsIQuM3TawvIyPjlooyKSkpwbx587Bhwwbk5eUhKioKEyZMwBtvvAFvb2+r3kOn00Gr1aK4uNghrTM/Hs3GC2tTEaX1we7X74FCcePrRURERJas/f5uVpBxRY4OMpXVBvRd9CtKKmuw7tnbMaB9iN1/JhERkbux9vvbqcfIuCIfLyVGdZNuKslbFhAREdlXs4LM3r17sWXLFot9n3/+OWJjYxEWFobnnnvOYoE8TzU2QVoc78ej2aisNshcDRERkftqVpB58803cfz4cfPzo0eP4umnn8awYcMwZ84cbN68+bpToz1Fv7bBaBXkixJ9DbadyJO7HCIiIrfVrCCTlpaGoUOHmp9/9dVX6N+/Pz799FPMnj0bH3zwAdavX2/zIl2NQiFgTE9ppV+uKUNERGQ/zQoyV69eRXh4uPn5zp07Le571LdvX4cuQOfMxtV2L+04mYfCsiqZqyEiInJPzQoy4eHh5qnVVVVVSE1Nxe23324+XlJSAi8vL9tW6KI6hAcivpUGNUYRPxzhLQuIiIjsoVlB5v7778ecOXPw+++/Y+7cufDz88Mdd9xhPn7kyBG0b9/e5kW6Kt4Rm4iIyL6aFWTeeustqFQq3HXXXfj000/xySefWCxM99lnn+G+++6zeZGu6sEeUVAIQOrFIpzPL5O7HCIiIrfTrFsUtGzZErt27UJxcTECAgKgVCotjn/zzTcIDAy0aYGuLEzjg8EdQrHr1BVsTLuMWcM6yl0SERGRW2lWkLH2HkefffbZTRXjjsYlRElB5tBlvDy0g1W3eCAiIiLrNCvIrFq1Cm3atEFCQgLc/M4GNnNfXAR8vY7hfEE5DmUWoVdMC7lLIiIichvNCjLTp0/HunXrkJGRgWnTpmHSpEkIDg62V21uwV+twoj4CGw4dBkbD11mkCEiIrKhZg32Xbp0KbKzs/Haa69h8+bNiI6Oxvjx4/Hzzz+zheY6TLcs2Hw4C9UGo8zVEBERuY9m3zRSrVZjwoQJSEpKQnp6Orp27YoXXngBbdu2RWlpqT1qdHmD2ocgNFCNq+XV2HnyitzlEBERuY1buvu1QqGAIAgQRREGA2+O2BSVUoEHe9TesiCNa8oQERHZSrODjF6vx7p163DvvfeiY8eOOHr0KD766CNcvHgRAQEB9qjRLZhuWfBrei50ldUyV0NEROQemjXY94UXXsBXX32F6OhoPPXUU1i3bh1atmxpr9rcStcoDTqEBeB0Xim2Hs3B+L7RcpdERETk8gSxGaN0FQoFYmJikJCQcN31UL777jubFGcLOp0OWq0WxcXF0Gg0stay9LczePfnkxjQLgTrnrv9xi8gIiLyUNZ+fzerRWby5Mlc0O0WjOkZhXd/Pol9GQXIKqpAVJCv3CURERG5tGYviEc3r3ULP/SPDUZyRiG+T8vC9CG8wSYREdGtuKVZS9R8pkG/Gw5d4to7REREt4hBxsFGdouEt0qBU7mlSM/WyV0OERGRS2OQcTCtrxeGdQkDAGw8xDVliIiIbgWDjAzG9pS6l75Py4LByO4lIiKim8UgI4MhncIQ5OeFvBI99pzNl7scIiIil8UgIwNvlQIPdI8EAGxg9xIREdFNY5CRiWn20s/HclBeVSNzNURERK6JQUYmvWJaICbYD2VVBiSl58pdDhERkUtikJGJIAgYa15Tht1LREREN4NBRkam7qXfT+fjSole5mqIiIhcD4OMjGJb+qNndBAMRhGbD2fJXQ4REZHLYZCRmalVZmMau5eIiIiai0FGZg90j4RKIeDIpWKcySuVuxwiIiKXwiAjs5AANe7qGAqAtywgIiJqLqcPMpcvX8akSZMQEhICX19fdOvWDSkpKXKXZVNj63UvGXnLAiIiIqup5C7geq5evYpBgwbh7rvvxk8//YTQ0FCcPn0aLVq0kLs0m7o3LhwBahUuXa1AyoWr6BcbLHdJRERELsGpg8ySJUsQHR2NlStXmvfFxsbKWJF9+HgpMTI+At8cvIQNhy4zyBAREVnJqbuWNm3ahD59+uDRRx9FWFgYEhIS8Omnn8pdll2YZi/9cCQL+hqDzNUQERG5BqcOMufOncOyZcvQoUMH/Pzzz5g+fTpeeuklrF69usnX6PV66HQ6i80V3N4uBJFaH+gqa/Dbn3lyl0NEROQSnDrIGI1G9OrVC2+//TYSEhLw3HPP4dlnn8Xy5cubfE1iYiK0Wq15i46OdmDFN0+hEPBgzygAvGUBERGRtZw6yERGRiIuLs5iX5cuXXDx4sUmXzN37lwUFxebt8zMTHuXaTMPJbQGAPz25xUUlVfJXA0REZHzc+ogM2jQIJw8edJi36lTp9CmTZsmX6NWq6HRaCw2V9EpIhBdIjWoMhjxw9FsucshIiJyek4dZP76179i3759ePvtt3HmzBl8+eWX+OSTTzBjxgy5S7ObcQlS99Lne87j+7TL2Hu2AAauLUNERNQop55+3bdvX2zYsAFz587Fm2++idjYWLz//vuYOHGi3KXZjcbHCwBwMrcUL3+VBgCI1Ppg/ug4jIiPlLEyIiIi5yOIoujWv+7rdDpotVoUFxc7fTfT1mPZmL4mFdf+hQi1fy6b1IthhoiIPIK1399O3bXkSQxGEQs3pzcIMQDM+xZuTmc3ExERUT0MMk5if0YhsosrmzwuAsgursT+jELHFUVEROTkGGScRF5J0yHmZs4jIiLyBAwyTiIs0Mem5xEREXkCBhkn0S82GJFaH/PA3msJkGYv8YaSREREdRhknIRSIWD+aGkV46bCzPzRcVAqmjpKRETkeRhknMiI+Egsm9QLEdqG3UfTBrXl1GsiIqJrOPWCeJ5oRHwk7o2LwP6MQuSVVOL3U/n4NvUS0jKL5C6NiIjI6TDIOCGlQsCA9iEAgAHtQ/D94ctIvViEo5eK0a21VubqiIiInAe7lpxcWKAPRnWTupRW7TkvbzFEREROhkHGBUwZ2BYAsPlIFgpK9fIWQ0RE5EQYZFxAQkwL9GitRVWNEV8dyJS7HCIiIqfBIOMiTK0ya/ZdQI3BKG8xREREToJBxkWM6h6JlgHeyC6uxC/puXKXQ0RE5BQYZFyEWqXEhH4xADjol4iIyIRBxoVM7N8GKoWA/RmFOJGtk7scIiIi2THIuJAIrQ+Gx0cAAFazVYaIiIhBxtVMrR30uzHtMorKq+QthoiISGYMMi6mT5sWiIvUoLLaiK85FZuIiDwcg4yLEQTB3Crzxb4LMBhFeQsiIiKSEYOMC3qwZxRa+Hnh0tUKbDvBqdhEROS5GGRckI+XEo/1laZir957Xt5iiIiIZMQg46Im3R4DhQD8caYAp3NL5C6HiIhIFgwyLqp1Cz/cGxcOgK0yRETkuRhkXJjp/kvfpV6GrrJa3mKIiIhkwCDjwga0C0Gn8ECUVxnwTcolucshIiJyOAYZFyYIAiYPbAMA+HzveRg5FZuIiDwMg4yLG5fQChofFS4UlGPHqTy5yyEiInIoBhkX5+etwvg+0QCAVXsuyFwNERGRYzHIuIHJA9pCEIBdp67g7JVSucshIiJyGAYZNxAT4od7OoUBAL7Yy1YZIiLyHAwybsI0Ffvbg5dQqq+RtxgiIiIHYZBxE4Nva4l2of4o1dfgvwc5FZuIiDwDg4ybUCgETBnQFoC00i+nYhMRkSdwqSCzePFiCIKAWbNmyV2KU3q4d2sEqFU4d6UMu8/ky10OERGR3blMkDlw4AA+/vhjdO/eXe5SnFaAWoVHercGAKzec17eYoiIiBzAJYJMaWkpJk6ciE8//RQtWrSQuxynNnmAtNLv9pN5uFhQLnM1RERE9uUSQWbGjBkYNWoUhg0bdsNz9Xo9dDqdxeZJ2oUG4M6OoRBF6bYFRERE7szpg8xXX32F1NRUJCYmWnV+YmIitFqteYuOjrZzhc5nau39l9anZKK8ilOxiYjIfTl1kMnMzMTLL7+MtWvXwsfHx6rXzJ07F8XFxeYtMzPTzlU6nyEdw9AmxA+6yhpsOHRZ7nKIiIjsxqmDzMGDB5GXl4devXpBpVJBpVJh586d+OCDD6BSqWAwGBq8Rq1WQ6PRWGyeRqEQ8OTtUqvM6j3nIYqcik1ERO7JqYPM0KFDcfToUaSlpZm3Pn36YOLEiUhLS4NSqZS7RKf1aJ9o+HopcSq3FHvPFchdDhERkV2o5C7gegIDAxEfH2+xz9/fHyEhIQ32kyWtrxce6tUKa5MvYvWe8xjYvqXcJREREdmcU7fI0K0x3X8pKT0Xl65yKjYREbkflwsyO3bswPvvvy93GS6hY3ggBrYPgVEE1uy7KHc5RERENudyQYaax9Qq89WBi6isbjg4moiIyJUxyLi5YV3C0SrIF0Xl1diUliV3OURERDbFIOPmlAoBT9betmAVp2ITEZGbYZDxAI/1iYZapUB6tg4pF67KXQ4REZHNMMh4gBb+3hiX0AqA1CpDRETkLhhkPIRp0O/WYznILq6QtxgiIiIbYZDxEF0iNegXGwyDUcRaTsUmIiI34dQr+5JtTR3YFvszCvFl8gX0jW2BovJqhAX6oF9sMJQKQe7yiIiImo1BxoPcFxeOID8vFJZXY8pnB8z7I7U+mD86DiPiI2WsjoiIqPnYteRBfj2Ri6Ly6gb7c4orMX1NKrYey5ahKiIiopvHIOMhDEYRCzenN3rMtLLMws3pMBi5zgwREbkOBhkPsT+jENnFlU0eFwFkF1dif0ah44oiIiK6RQwyHiKvpOkQczPnEREROQMGGQ8RFuhj0/OIiIicAYOMh+gXG4xIrQ+uN8k6UitNxSYiInIVDDIeQqkQMH90HAA0GWZCArxRVWN0XFFERES3iEHGg4yIj8SySb0QobXsPgr284aXUsCxyzpM/iwZxRUNp2gTERE5I0EURbeeb6vT6aDValFcXAyNRiN3OU7BYBSxP6MQeSWV5pV9Uy9exVOrDqCksgZxkRqsfqofQgPVcpdKREQeytrvbwYZMkvP0mHyZ/uRX6pH2xA/fPF0f0QH+8ldFhEReSBrv7/ZtURmcVEafPv8ALRu4YvzBeV4dPlenM4tkbssIiKiJjHIkIW2Lf3x7fMD0SEsADm6Sjz68V6kZRbJXRYREVGjGGSogQitD9b/ZQB6RAehqLwaT3y6D3+cyZe7LCIiogYYZKhRLfy98eUz/THothCUVxkwbeUBbD2WI3dZREREFhhkqEn+ahU+m9oXI7pGoMpgxAtrD2L9gUy5yyIiIjJjkKHrUquU+OiJBDzWJxpGEXjtv0fw6a5zcpdFREQEgEGGrKBSKrD44W74y53tAACLfjyBd7b+CTefuU9ERC6AQYasIggC5t7fBa+P6AwA+H87zuLvG4/BYGSYISIi+TDIULNMH9Ieb4/rBkEAvky+iJe+OsT7MxERkWwYZKjZnugfgw8nJMBLKeCHI9l45vMUlFfVyF0WERF5IAYZuikPdI/Ciil94eulxK5TVzBpRTKKy3mzSSIiciwGGbppd3UMxZpn+kPjo0LqxSI89sle5Okq5S6LiIg8CIMM3ZLebVpg/fMDEBaoxp85JXhk+V5cLCiXuywiIvIQDDJ0yzpHaPDt8wMRE+yHi4XleGT5HvyZo5O7LCIi8gAMMmQTMSF++Pb5AegcEYi8Ej3GL9+Lgxeuyl0WERG5OacOMomJiejbty8CAwMRFhaGsWPH4uTJk3KXRU0I0/jg6+cGoFdMEHSVNZi0Ihm7Tl2RuywiInJjTh1kdu7ciRkzZmDfvn1ISkpCdXU17rvvPpSVlcldGjVB6+eFNc/0x50dQ1FRbcDTqw/ghyPZcpdFRERuShBdaJ35K1euICwsDDt37sSdd95p1Wt0Oh20Wi2Ki4uh0WjsXCGZVNUYMXt9GrYcyYYgAG+P64YJ/WLkLouIiFyEtd/fKgfWdMuKi4sBAMHBwU2eo9frodfrzc91Og46lYO3SoH/ezwBGl8vfJl8EXO/O4qi8mpMH9Je7tKIiMiNOHXXUn1GoxGzZs3CoEGDEB8f3+R5iYmJ0Gq15i06OtqBVVJ9SoWARWPjMeNuKbws2fonEn88wZtNEhGRzbhM19L06dPx008/Yffu3WjdunWT5zXWIhMdHc2uJZl9uuscFv14AgDwWJ9ovP1QNygVgsxVERGRs3KrrqWZM2diy5Yt2LVr13VDDACo1Wqo1WoHVUbWevbOdtD6emHOd0fwdUomdJXVeP/xnlCrlHKXRkRELsypu5ZEUcTMmTOxYcMGbN++HbGxsXKXRLdgfN9o/L+JveCtVOCnYzl4elUKyvS82SQREd08pw4yM2bMwJo1a/Dll18iMDAQOTk5yMnJQUVFhdyl0U0aER+JldP6ws9bid1n8jFxRTKullXJXRYREbkopx4jIwiNj6FYuXIlpk6datV7cPq1c0rLLMLUlftRVF6NDmEB+OLp/ojQ+shdFhEROQlrv7+dukVGFMVGN2tDDDmvntFB+OYvAxCh8cHpvFI8snwPzudzoUMiImoepw4y5N46hAfim+cHoG2IHy5drcAjy/ciPYvr/hARkfUYZEhW0cF++Ob5gYiL1CC/VI/HPtmLlPOFcpdFREQugkGGZBcaqMa6525H37YtUFJZg0n/ScZvf+bJXRYREbkABhlyClpfL3z+VH/c0zkMldVGPPt5Cr5Puyx3WURE5OQYZMhp+Hor8fGTvTGmZxRqjCJmfZ2GL/ael7ssIiJyYgwy5FS8lAr8e3xPTBnQBqIIzPv+OD7cdpr3ZyIioka5xC0KyLMoFAIWPNgVWj9vfLDtNN5LOoWr5dX4x6guEAHszyhEXkklwgJ90C82mPdsIiLyYAwy5JQEQcDsezsiyNcLb25Jx2d/ZCA9S4fzBWXI0VWaz4vU+mD+6DiMiI+UsVoiIpILu5bIqT01OBbvPdoDCgHYl1FgEWIAIKe4EtPXpGLrsWyZKiQiIjkxyJDTG5vQClpfr0aPmUbOLNycDoOR42iIiDwNgww5vf0ZhbhaXt3kcRFAdnEl9mdwIT0iIk/DMTLk9PJKKm98EoDX/nsYfdsEo31YANqH+qN9aADahPjDW8W8TkTkrhhkyOmFBVp3V+zMwgpkFlouoqdUCGgT7Id2oQFoH+aP20IDaoNOQJPdVURE5DoYZMjp9YsNRqTWBznFlWhsFIwAoGWgGgtHd0VGQRnO5pXi7JVSnL1ShlJ9Dc7ll+Fcfhl+PWH5upYBarQP9cdttcHG1JITpfWFglO6iYhcAoMMOT2lQsD80XGYviYVAmARZkxx460xXRtMwRZFEbk6fW2oKcXZvFKcuVKKs3nSFO78Uj3yS/VIvmZsja+XEu1qu6bahwZIQSfMH21D/OHjpbTrZyUiouYRRDdfMlWn00Gr1aK4uBgajUbucugWbD2WjYWb05FdfOvryJTqa3CuNuCcyZPCzdkrpThfUIZqQ+P/SwgCEN3Cr7YFx9/cinNbaABa+Hvf0mcjIiJL1n5/M8iQSzEYRbuu7FtjMOJiYTnOXimzaMU5k1eKksqaJl8X7O9dF25MrTihAWjVwpcrDxMR3QQGmVoMMmQLoigiv7SqrgWndgzO2bxSXC6qaPJ13ioF2rX0Nw8wrh92fL3ZTUVE1BRrv785RobICoIgIDRQjdBANW5vF2JxrLyqBudMLThX6gYbn8svQ1WNEX/mlODPnJIG79kqyNdiqripFadlgDcEga04RETWYIsMkZ0YjCIuX63AmSsl5jE4phad6y3wp/FRmcfe1G/JiQn2g0rJNXGIyDOwa6kWgww5o8KyKvMYnLruqjJkXi1HU/9HeikFtA0xDTKua8VpFxqAADUbV4nIvTDI1GKQIVdSWW3A+YIyi5lUpq2y2tjk6yI0Pg0W/GsfGoBwjZrdVETkkhhkajHIkDswGkVkFVeYx+CcMbfmlCG/VN/k6wLUKoup4qYFAGOCeesGInJuDDK1GGTI3RWXV0vBxrzwn9SSc7GwvMk7gte/dYN5XRzeuoGInAiDTC0GGfJU+hoDLhaUW4zBMY3LKasyNPm60EB1wzVxwgIQqfHhrRuIyGE4/ZrIw6lVSnQID0SH8ECL/aZbN9Sth1M34DhXp8eVEmnbd67xWzfcVm8Mji1v3WDvxQ6JyD2xRYaIzEoqq81r4tRf+O98fhlqmuimUghAdLCfxYJ/prBj7a0bbHn7CSJyD+xaqsUgQ3Trqk23bqjXRWUKOtbcusGiFeeaWzdsPZaN6WtSG9zZ3NQWs2xSL4YZIg/EIFOLQYbIfkRRxJVSPc7mldWbSVWKc1fKrnvrBrVKgdiW/mgX6o9dp/JRqm88DAkAIrQ+2P36PexmIvIwDDK1GGSI5FGmr0FGflm9hf+k9XEy8stQZWh6TZzGdIkIRJjGBz5eCqhVSvh4KeDjpYSPlxJqlaLRP6XtmvNVSqi9FOY/1SoF19lxAI5/opvBwb5EJCt/tQrxrbSIb6W12G8wirh0VZpN9X1aFr5Py7rhe53IKcGJRu5XZQt1weeaIGQOO/WDU73nqtogVS8YXTdIqeqClyfN/uL4J7I3BhkiciilQkCbEH+0CfGHr5fKqiDz0j23ITrYD5U1RuirDdDXGFFZbUClxWOj5fNGzq2sNqKyxmBxGwh9jRH6GiOKm+4JszlvpcIcfJoKO+aQdE248qltSbo2LKmvbXXyUsKnXiuVHPfpamr8U05xJaavSeX4JxfnLC1tDDJEJJt+scGI1Pogp7iywZcdUDdG5uVhHW32D6Qoiqg2iKisqQ1C1UboaxoJQg2CkbRPXyO9ptEgdZ1z6s/6qjIYUWUwXnegtK2pFELD4KNqpPvt2iBlcW5j59c9V9drpfJSKLBgc3qjf68ipL/bhZvTcW9cBLuZXJAztbRxjAwRycr0WzsAiy89d5u1VGMworLm2rDUSPCxeNwwXOmbCFeV1cYG79fcsUhyaNfSH1o/L6gUApTmTWF+rlIIUNT+qaz3p/RYcZ1zFFAqYPFeymveQ9XIOQ3fSwGFAhY/q9H3UQpQCpbv4a4cNdPQrQb7Ll26FO+++y5ycnLQo0cPfPjhh+jXr59Vr2WQIXJ+zvTbnTsxGMW6kNRoq9M1QarGct+14ajuz6ZbrvQ1zh+eHEEQYBFslAoBKqUCCqH+87rwY36uUEAp1AtOytrjQsNzzAFMWRueTO+trBfmhLr3MJ+jvH7gayzMmc4RADy9+gDyS6sa/9yw3UxDtxns+/XXX2P27NlYvnw5+vfvj/fffx/Dhw/HyZMnERYWJnd5RGQDI+IjcW9chFP0t7sTpUKAn7cKftatS2gToihCX2PE7tP5eObzlBue/+rwjugQFgiDUUSNUTT/aTQ/N5r3W3tO/fPqnhsb7L/eexmvOd7UezXVFCCKQI0ondP0bV3djwggu7gS+zMKMaB9iEN+ptO3yPTv3x99+/bFRx99BAAwGo2Ijo7Giy++iDlz5tzw9WyRISJyPINRxOAl2284/snV1wgyGkUYxIaBxxx2DCKMYr1QZPHciBpD7WtM+wz13kdseI7pPcwBTDQ9v7XAV2M0wmhEo4Gv/vNSfQ2KK6pveF3+7/GeGNOz1S1dW7dokamqqsLBgwcxd+5c8z6FQoFhw4Zh7969jb5Gr9dDr6/Lvzqdzu51EhGRJaVCwPzRcZi+JhUCGh//NH90nEuHGABQKAQoIMAGtxtzCXvPFmDCp/tueF5YoI8DqpE4fj5eM+Tn58NgMCA8PNxif3h4OHJychp9TWJiIrRarXmLjo52RKlERHSNEfGRWDapFyK0ll9qEVoftxnE7WlMMw2bip8CpPFt/WKDHVaTU7fI3Iy5c+di9uzZ5uc6nY5hhohIJhz/5F6csaXNqYNMy5YtoVQqkZuba7E/NzcXERERjb5GrVZDrVY7ojwiIrKCUiE4bOAn2Z+ppe3amYYRMs00dOog4+3tjd69e2Pbtm0YO3YsAGmw77Zt2zBz5kx5iyMiIvJQztTS5tRBBgBmz56NKVOmoE+fPujXrx/ef/99lJWVYdq0aXKXRkRE5LGcpaXN6YPMY489hitXruCNN95ATk4Oevbsia1btzYYAExERESex+nXkblVXEeGiIjI9Vj7/e3U06+JiIiIrodBhoiIiFwWgwwRERG5LAYZIiIiclkMMkREROSyGGSIiIjIZTHIEBERkcty+gXxbpVpmRydTidzJURERGQt0/f2jZa7c/sgU1JSAgC8AzYREZELKikpgVarbfK426/sazQakZWVhcDAQAgCbxvvKDqdDtHR0cjMzOSKyg7Gay8fXnt58LrLx57XXhRFlJSUICoqCgpF0yNh3L5FRqFQoHXr1nKX4bE0Gg3/YZEJr718eO3lwesuH3td++u1xJhwsC8RERG5LAYZIiIiclkMMmQXarUa8+fPh1qtlrsUj8NrLx9ee3nwusvHGa692w/2JSIiIvfFFhkiIiJyWQwyRERE5LIYZIiIiMhlMcgQERGRy2KQoZuWmJiIvn37IjAwEGFhYRg7dixOnjxpcU5lZSVmzJiBkJAQBAQE4OGHH0Zubq5MFbuvxYsXQxAEzJo1y7yP195+Ll++jEmTJiEkJAS+vr7o1q0bUlJSzMdFUcQbb7yByMhI+Pr6YtiwYTh9+rSMFbsHg8GAefPmITY2Fr6+vmjfvj3eeusti3vx8Nrbxq5duzB69GhERUVBEARs3LjR4rg117mwsBATJ06ERqNBUFAQnn76aZSWltq8VgYZumk7d+7EjBkzsG/fPiQlJaG6uhr33XcfysrKzOf89a9/xebNm/HNN99g586dyMrKwkMPPSRj1e7nwIED+Pjjj9G9e3eL/bz29nH16lUMGjQIXl5e+Omnn5Ceno733nsPLVq0MJ/zzjvv4IMPPsDy5cuRnJwMf39/DB8+HJWVlTJW7vqWLFmCZcuW4aOPPsKJEyewZMkSvPPOO/jwww/N5/Da20ZZWRl69OiBpUuXNnrcmus8ceJEHD9+HElJSdiyZQt27dqF5557zvbFikQ2kpeXJwIQd+7cKYqiKBYVFYleXl7iN998Yz7nxIkTIgBx7969cpXpVkpKSsQOHTqISUlJ4l133SW+/PLLoijy2tvT66+/Lg4ePLjJ40ajUYyIiBDfffdd876ioiJRrVaL69atc0SJbmvUqFHiU089ZbHvoYceEidOnCiKIq+9vQAQN2zYYH5uzXVOT08XAYgHDhwwn/PTTz+JgiCIly9ftml9bJEhmykuLgYABAcHAwAOHjyI6upqDBs2zHxO586dERMTg71798pSo7uZMWMGRo0aZXGNAV57e9q0aRP69OmDRx99FGFhYUhISMCnn35qPp6RkYGcnByLa6/VatG/f39e+1s0cOBAbNu2DadOnQIAHD58GLt378bIkSMB8No7ijXXee/evQgKCkKfPn3M5wwbNgwKhQLJyck2rcftbxpJjmE0GjFr1iwMGjQI8fHxAICcnBx4e3sjKCjI4tzw8HDk5OTIUKV7+eqrr5CamooDBw40OMZrbz/nzp3DsmXLMHv2bPzP//wPDhw4gJdeegne3t6YMmWK+fqGh4dbvI7X/tbNmTMHOp0OnTt3hlKphMFgwKJFizBx4kQA4LV3EGuuc05ODsLCwiyOq1QqBAcH2/zvgkGGbGLGjBk4duwYdu/eLXcpHiEzMxMvv/wykpKS4OPjI3c5HsVoNKJPnz54++23AQAJCQk4duwYli9fjilTpshcnXtbv3491q5diy+//BJdu3ZFWloaZs2ahaioKF57D8auJbplM2fOxJYtW/Dbb7+hdevW5v0RERGoqqpCUVGRxfm5ubmIiIhwcJXu5eDBg8jLy0OvXr2gUqmgUqmwc+dOfPDBB1CpVAgPD+e1t5PIyEjExcVZ7OvSpQsuXrwIAObre+0MMV77W/fqq69izpw5ePzxx9GtWzc8+eST+Otf/4rExEQAvPaOYs11joiIQF5ensXxmpoaFBYW2vzvgkGGbpooipg5cyY2bNiA7du3IzY21uJ479694eXlhW3btpn3nTx5EhcvXsSAAQMcXa5bGTp0KI4ePYq0tDTz1qdPH0ycONH8mNfePgYNGtRgmYFTp06hTZs2AIDY2FhERERYXHudTofk5GRe+1tUXl4OhcLya0upVMJoNALgtXcUa67zgAEDUFRUhIMHD5rP2b59O4xGI/r372/bgmw6dJg8yvTp00WtVivu2LFDzM7ONm/l5eXmc55//nkxJiZG3L59u5iSkiIOGDBAHDBggIxVu6/6s5ZEkdfeXvbv3y+qVCpx0aJF4unTp8W1a9eKfn5+4po1a8znLF68WAwKChK///578ciRI+KYMWPE2NhYsaKiQsbKXd+UKVPEVq1aiVu2bBEzMjLE7777TmzZsqX42muvmc/htbeNkpIS8dChQ+KhQ4dEAOK//vUv8dChQ+KFCxdEUbTuOo8YMUJMSEgQk5OTxd27d4sdOnQQJ0yYYPNaGWTopgFodFu5cqX5nIqKCvGFF14QW7RoIfr5+Ynjxo0Ts7Oz5SvajV0bZHjt7Wfz5s1ifHy8qFarxc6dO4uffPKJxXGj0SjOmzdPDA8PF9VqtTh06FDx5MmTMlXrPnQ6nfjyyy+LMTExoo+Pj9iuXTvx73//u6jX683n8Nrbxm+//dbov+9TpkwRRdG661xQUCBOmDBBDAgIEDUajTht2jSxpKTE5rUKolhvSUQiIiIiF8IxMkREROSyGGSIiIjIZTHIEBERkctikCEiIiKXxSBDRERELotBhoiIiFwWgwwRERG5LAYZInIKQ4YMwaxZs+z+cwRBwMaNG+3+c4jIMRhkiMgtLViwAD179pS7DCKyMwYZIiIiclkMMkTkcGVlZZg8eTICAgIQGRmJ9957z+K4Xq/H3/72N7Rq1Qr+/v7o378/duzYYT6+atUqBAUFYePGjejQoQN8fHwwfPhwZGZmmo8vXLgQhw8fhiAIEAQBq1atMr8+Pz8f48aNg5+fHzp06IBNmzY54mMTkR0wyBCRw7366qvYuXMnvv/+e/zyyy/YsWMHUlNTzcdnzpyJvXv34quvvsKRI0fw6KOPYsSIETh9+rT5nPLycixatAiff/45/vjjDxQVFeHxxx8HADz22GN45ZVX0LVrV2RnZyM7OxuPPfaY+bULFy7E+PHjceTIEdx///2YOHEiCgsLHXcBiMh2bH4bSiKi6ygpKRG9vb3F9evXm/cVFBSIvr6+4ssvvyxeuHBBVCqV4uXLly1eN3ToUHHu3LmiKIriypUrRQDivn37zMdPnDghAhCTk5NFURTF+fPniz169Gjw8wGI//jHP8zPS0tLRQDiTz/9ZMuPSUQOopI3RhGRpzl79iyqqqrQv39/877g4GB06tQJAHD06FEYDAZ07NjR4nV6vR4hISHm5yqVCn379jU/79y5M4KCgnDixAn069fvujV0797d/Njf3x8ajQZ5eXm39LmISB4MMkTkVEpLS6FUKnHw4EEolUqLYwEBATb5GV5eXhbPBUGA0Wi0yXsTkWNxjAwROVT79u3h5eWF5ORk876rV6/i1KlTAICEhAQYDAbk5eXhtttus9giIiLMr6mpqUFKSor5+cmTJ1FUVIQuXboAALy9vWEwGBz0qYhILgwyRORQAQEBePrpp/Hqq69i+/btOHbsGKZOnQqFQvrnqGPHjpg4cSImT56M7777DhkZGdi/fz8SExPxww8/mN/Hy8sLL774IpKTk3Hw4EFMnToVt99+u7lbqW3btsjIyEBaWhry8/Oh1+tl+bxEZF8MMkTkcO+++y7uuOMOjB49GsOGDcPgwYPRu3dv8/GVK1di8uTJeOWVV9CpUyeMHTsWBw4cQExMjPkcPz8/vP7663jiiScwaNAgBAQE4OuvvzYff/jhhzFixAjcfffdCA0Nxbp16xz6GYnIMQRRFEW5iyAiao5Vq1Zh1qxZKCoqkrsUIpIZW2SIiIjIZTHIEBERkcti1xIRERG5LLbIEBERkctikCEiIiKXxSBDRERELotBhoiIiFwWgwwRERG5LAYZIiIiclkMMkREROSyGGSIiIjIZTHIEBERkcv6/zBlL4YCHskfAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "max_depth1 = [5,10,15,25,50,75,100]\n",
    "train_result=[]\n",
    "val_result=[]\n",
    "for i in max_depth1:\n",
    "    tree_c= DecisionTreeRegressor(max_depth = i)\n",
    "    tree_c.fit(x_train,y_train)\n",
    "    y_train_pred = tree_c.predict(x_train)\n",
    "    train_result.append(mean_squared_error(y_train, y_train_pred))\n",
    "    y_val_pred = tree_c.predict(x_val)\n",
    "    val_result.append(mean_squared_error(y_val, y_val_pred))\n",
    "\n",
    "    \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "\n",
    "plt.plot(max_depth1,train_result, marker='o', linestyle='-')\n",
    "plt.plot(max_depth1,val_result, marker='o', linestyle='-')\n",
    "plt.xlabel(\"depth\")\n",
    "plt.ylabel('MSE')\n",
    "plt.title('n_estimators')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[14.21995654671602,\n",
       " 22.920112052190575,\n",
       " 22.361776130745305,\n",
       " 25.49158100259187,\n",
       " 25.61272391874598,\n",
       " 23.63010003366536,\n",
       " 23.94269660776414]"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "max_fe1 = [5,8,12,15,18,23,30]\n",
    "train_result=[]\n",
    "val_result=[]\n",
    "for i in max_fe1:\n",
    "    tree_= DecisionTreeRegressor(max_features = i)\n",
    "    tree_c.fit(x_train,y_train)\n",
    "    y_train_pred = tree_c.predict(x_train)\n",
    "    train_result.append(mean_squared_error(y_train, y_train_pred))\n",
    "    y_val_pred = tree_c.predict(x_val)\n",
    "    val_result.append(mean_squared_error(y_val, y_val_pred))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "plt.plot(max_fe1,train_result, marker='o', linestyle='-')\n",
    "plt.plot(max_fe1,val_result, marker='o', linestyle='-')\n",
    "plt.xlabel(\"features\")\n",
    "plt.ylabel('MSE')\n",
    "plt.title('Max Features')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For max_depth:5,max_features:None,min_samples_split:None\n",
      "            train accuracy:0.09868907194970461 validation accuracy:14.825452065145962\n",
      "For max_depth:5,max_features:None,min_samples_split:1.0\n",
      "            train accuracy:0.09868879617792438 validation accuracy:14.491686762364017\n",
      "For max_depth:5,max_features:None,min_samples_split:12\n",
      "            train accuracy:0.09891317203340717 validation accuracy:13.386814272937723\n",
      "For max_depth:5,max_features:None,min_samples_split:14\n",
      "            train accuracy:0.09869273775928085 validation accuracy:14.121092760440462\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[46], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m min_samples_s:\n\u001b[1;32m      8\u001b[0m     tree_\u001b[38;5;241m=\u001b[39m DecisionTreeRegressor(max_depth \u001b[38;5;241m=\u001b[39m j, max_features \u001b[38;5;241m=\u001b[39m k, min_samples_split \u001b[38;5;241m=\u001b[39m l)\n\u001b[0;32m----> 9\u001b[0m     \u001b[43mtree_c\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m     y_train_pred \u001b[38;5;241m=\u001b[39m tree_c\u001b[38;5;241m.\u001b[39mpredict(x_train)\n\u001b[1;32m     11\u001b[0m     train_accuracy \u001b[38;5;241m=\u001b[39m mean_squared_error(y_train, y_train_pred)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1144\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1146\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1147\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1149\u001b[0m     )\n\u001b[1;32m   1150\u001b[0m ):\n\u001b[0;32m-> 1151\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/tree/_classes.py:1320\u001b[0m, in \u001b[0;36mDecisionTreeRegressor.fit\u001b[0;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[1;32m   1290\u001b[0m \u001b[38;5;129m@_fit_context\u001b[39m(prefer_skip_nested_validation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m   1291\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, check_input\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m   1292\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Build a decision tree regressor from the training set (X, y).\u001b[39;00m\n\u001b[1;32m   1293\u001b[0m \n\u001b[1;32m   1294\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1317\u001b[0m \u001b[38;5;124;03m        Fitted estimator.\u001b[39;00m\n\u001b[1;32m   1318\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1320\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1321\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1322\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1323\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1324\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcheck_input\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1325\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1326\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/tree/_classes.py:443\u001b[0m, in \u001b[0;36mBaseDecisionTree._fit\u001b[0;34m(self, X, y, sample_weight, check_input, missing_values_in_feature_mask)\u001b[0m\n\u001b[1;32m    432\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    433\u001b[0m     builder \u001b[38;5;241m=\u001b[39m BestFirstTreeBuilder(\n\u001b[1;32m    434\u001b[0m         splitter,\n\u001b[1;32m    435\u001b[0m         min_samples_split,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    440\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmin_impurity_decrease,\n\u001b[1;32m    441\u001b[0m     )\n\u001b[0;32m--> 443\u001b[0m \u001b[43mbuilder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtree_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmissing_values_in_feature_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    445\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_outputs_ \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m is_classifier(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    446\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "list1=[]\n",
    "depth = [5,10]\n",
    "features= [None]\n",
    "min_samples_s = [None,1.0,12,14]\n",
    "for j in depth:\n",
    "    for k in features:\n",
    "        for l in min_samples_s:\n",
    "            tree_= DecisionTreeRegressor(max_depth = j, max_features = k, min_samples_split = l)\n",
    "            tree_c.fit(x_train,y_train)\n",
    "            y_train_pred = tree_c.predict(x_train)\n",
    "            train_accuracy = mean_squared_error(y_train, y_train_pred)\n",
    "            y_val_pred = tree_c.predict(x_val)\n",
    "            val_accuracy = mean_squared_error(y_val, y_val_pred)\n",
    "            list1.append((j,k,l,train_accuracy,val_accuracy))\n",
    "            print(f'''For max_depth:{j},max_features:{k},min_samples_split:{l}\n",
    "            train accuracy:{train_accuracy} validation accuracy:{val_accuracy}''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.09868559555971745, 0.09868681957981033, 0.0988796417551417, 0.09887252089264603, 0.09889953373253454, 0.09868642243156203, 0.09847377054735078, 0.09868524639452511, 0.09868063919978282, 0.09891010907178086, 0.0988019875120844, 0.09869139003982162, 0.09891371454299211, 0.09869182205377405, 0.09878874559107732, 0.09869334162546521, 0.09868116927446578, 0.09870059624895228, 0.09853571187513281, 0.0987075662446557, 0.09869298770392759, 0.09868712215659257, 0.0989155725395942, 0.09879489326276687, 0.09869901443573567, 0.09854278628590178, 0.09867926265786812, 0.09890764500818931, 0.09891709131958937, 0.09868815014359714, 0.09891558977333241, 0.0989075680452534, 0.09891652051156641, 0.09891347899241097, 0.09890893378704155, 0.09868812724690022, 0.09868652891134162, 0.09869117437595992, 0.09868565736820775, 0.09868359402195656, 0.09869623786666408, 0.09870199017500485]\n",
      "[14.388527647357881, 13.530729119328415, 14.180291165425988, 13.825499798441436, 14.666253462922176, 14.767411900911402, 14.603503549731467, 13.960197977632763, 13.692037740993868, 14.43985467594276, 14.337711694977068, 14.133592387872937, 13.270990198061032, 14.663870851103752, 14.12085355681794, 13.967301778131693, 14.69042856877636, 13.589707198389268, 13.105853836617767, 14.313535686945164, 14.160055591022994, 14.20913587396148, 14.27868269211328, 13.599918565292748, 14.531500904938015, 14.925920020359987, 14.321489196506679, 13.932409705275944, 13.600165405073474, 14.735172338757753, 13.956657387138405, 13.978342836874067, 14.607814224309394, 13.94160836504854, 14.50452728530889, 14.34751252580708, 14.552514773066779, 13.996621250197851, 14.13006739665533, 15.35453168043614, 15.220162559752351, 13.780567982031913]\n"
     ]
    }
   ],
   "source": [
    "all_train_acc=[list1[i][3] for i in range(len(list1))]\n",
    "all_val_acc=[list1[i][4] for i in range(len(list1))]\n",
    "print(all_train_acc)\n",
    "print(all_val_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[13.105853836617767,\n",
       " 13.270990198061032,\n",
       " 13.530729119328415,\n",
       " 13.589707198389268,\n",
       " 13.599918565292748,\n",
       " 13.600165405073474,\n",
       " 13.692037740993868,\n",
       " 13.780567982031913,\n",
       " 13.825499798441436,\n",
       " 13.932409705275944]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import heapq\n",
    "max_5_val_acc = heapq.nsmallest(10, all_val_acc)\n",
    "max_5_val_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 30, 1.0, 0.09853571187513281, 13.105853836617767)\n",
      "(5, 18, 1.0, 0.09891371454299211, 13.270990198061032)\n",
      "(5, 5, 12, 0.09868681957981033, 13.530729119328415)\n",
      "(5, 23, 14, 0.09870059624895228, 13.589707198389268)\n",
      "(10, 5, 14, 0.09879489326276687, 13.599918565292748)\n",
      "(10, 12, 12, 0.09891709131958937, 13.600165405073474)\n",
      "(5, 12, 14, 0.09868063919978282, 13.692037740993868)\n",
      "(10, 30, 14, 0.09870199017500485, 13.780567982031913)\n",
      "(5, 8, 1.0, 0.09887252089264603, 13.825499798441436)\n",
      "(10, 12, 1.0, 0.09890764500818931, 13.932409705275944)\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(max_5_val_acc)):\n",
    "    print(list1[all_val_acc.index(max_5_val_acc[i])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error (MSE) on training data: 0.0\n",
      "Mean Squared Error (MSE) on training data: 13.996078512739647\n"
     ]
    }
   ],
   "source": [
    "tree_regressor = DecisionTreeRegressor()\n",
    "tree_regressor.fit(x_train,y_train)\n",
    "y_train_pred = tree_regressor.predict(x_train)\n",
    "y_val_pred = tree_regressor.predict(x_val)\n",
    "mse = mean_squared_error(y_train, y_train_pred)\n",
    "print(f\"Mean Squared Error (MSE) on training data: {mse}\")\n",
    "mse = mean_squared_error(y_val, y_val_pred)\n",
    "print(f\"Mean Squared Error (MSE) on training data: {mse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error (MSE) on training data: 7.373552884490313\n",
      "Mean Squared Error (MSE) on training data: 7.864480551002882\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBRegressor\n",
    "xgb = XGBRegressor(n_estimators=100, learning_rate=0.1, max_depth=3, random_state=0)\n",
    "xgb.fit(x_train, y_train)\n",
    "y_train_pred = xgb.predict(x_train)\n",
    "mse = mean_squared_error(y_train, y_train_pred)\n",
    "print(f\"Mean Squared Error (MSE) on training data: {mse}\")\n",
    "y_val_pred = xgb.predict(x_val)\n",
    "mse1 = mean_squared_error(y_val, y_val_pred)\n",
    "print(f\"Mean Squared Error (MSE) on training data: {mse1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011715 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1968\n",
      "[LightGBM] [Info] Number of data points in the train set: 718091, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 9.241747\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Mean Squared Error (MSE) on training data: 7.35393618671843\n",
      "Mean Squared Error (MSE) on training data: 7.609841468743703\n"
     ]
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "lgbm = lgb.LGBMRegressor(n_estimators=100, learning_rate=0.1, max_depth=3, random_state=0)\n",
    "lgbm.fit(x_train, y_train)\n",
    "y_train_pred = lgbm.predict(x_train)\n",
    "mse = mean_squared_error(y_train, y_train_pred)\n",
    "print(f\"Mean Squared Error (MSE) on training data: {mse}\")\n",
    "y_val_pred = lgbm.predict(x_val)\n",
    "mse1 = mean_squared_error(y_val, y_val_pred)\n",
    "print(f\"Mean Squared Error (MSE) on training data: {mse1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error (MSE) on training data: 7.858578832098094\n",
      "Mean Squared Error (MSE) on training data: 7.634794630684779\n"
     ]
    }
   ],
   "source": [
    "from catboost import CatBoostRegressor\n",
    "catboost = CatBoostRegressor(iterations=100, learning_rate=0.1, depth=3, random_state=0, silent=True)\n",
    "catboost.fit(x_train, y_train)\n",
    "y_train_pred = catboost.predict(x_train)\n",
    "mse = mean_squared_error(y_train, y_train_pred)\n",
    "print(f\"Mean Squared Error (MSE) on training data: {mse}\")\n",
    "y_val_pred = catboost.predict(x_val)\n",
    "mse1 = mean_squared_error(y_val, y_val_pred)\n",
    "print(f\"Mean Squared Error (MSE) on training data: {mse1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lightgbm Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011991 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1968\n",
      "[LightGBM] [Info] Number of data points in the train set: 718091, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 9.241747\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012188 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1968\n",
      "[LightGBM] [Info] Number of data points in the train set: 718091, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 9.241747\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013071 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1968\n",
      "[LightGBM] [Info] Number of data points in the train set: 718091, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 9.241747\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011912 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1968\n",
      "[LightGBM] [Info] Number of data points in the train set: 718091, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 9.241747\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011563 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1968\n",
      "[LightGBM] [Info] Number of data points in the train set: 718091, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 9.241747\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011771 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1968\n",
      "[LightGBM] [Info] Number of data points in the train set: 718091, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 9.241747\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011978 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1968\n",
      "[LightGBM] [Info] Number of data points in the train set: 718091, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 9.241747\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011656 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1968\n",
      "[LightGBM] [Info] Number of data points in the train set: 718091, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 9.241747\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011953 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1968\n",
      "[LightGBM] [Info] Number of data points in the train set: 718091, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 9.241747\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011690 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1968\n",
      "[LightGBM] [Info] Number of data points in the train set: 718091, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 9.241747\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011592 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1968\n",
      "[LightGBM] [Info] Number of data points in the train set: 718091, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 9.241747\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011651 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1968\n",
      "[LightGBM] [Info] Number of data points in the train set: 718091, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 9.241747\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011553 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1968\n",
      "[LightGBM] [Info] Number of data points in the train set: 718091, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 9.241747\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "estim = [5,10,15,25,50,60,75,100,125,150,200,250,300]\n",
    "train_result=[]\n",
    "val_result=[]\n",
    "for i in estim:\n",
    "    lgbm = lgb.LGBMRegressor(n_estimators=i, learning_rate=0.1, max_depth=3, random_state=0)\n",
    "    lgbm.fit(x_train, y_train)\n",
    "    y_train_pred = lgbm.predict(x_train)\n",
    "    train_result.append(mean_squared_error(y_train, y_train_pred))\n",
    "    y_val_pred = lgbm.predict(x_val)\n",
    "    val_result.append(mean_squared_error(y_val, y_val_pred))\n",
    "\n",
    "    \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "\n",
    "plt.plot(estim,train_result, marker='o', linestyle='-')\n",
    "plt.plot(estim,val_result, marker='o', linestyle='-')\n",
    "plt.xlabel(\"estimators\")\n",
    "plt.ylabel('MSE')\n",
    "plt.title('n_estimators')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[18.114441095132864,\n",
       " 11.894981527700898,\n",
       " 9.163041289854174,\n",
       " 7.671183541186087,\n",
       " 7.440341071842932,\n",
       " 7.460204981769586,\n",
       " 7.543486108439111,\n",
       " 7.609841468743703,\n",
       " 7.743447667843093,\n",
       " 7.896848089769793,\n",
       " 7.883395820097669,\n",
       " 7.898753552249559,\n",
       " 7.86452427587386]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012095 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1967\n",
      "[LightGBM] [Info] Number of data points in the train set: 718091, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 9.241747\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012127 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1967\n",
      "[LightGBM] [Info] Number of data points in the train set: 718091, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 9.241747\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011651 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1967\n",
      "[LightGBM] [Info] Number of data points in the train set: 718091, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 9.241747\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011685 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1967\n",
      "[LightGBM] [Info] Number of data points in the train set: 718091, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 9.241747\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012325 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1967\n",
      "[LightGBM] [Info] Number of data points in the train set: 718091, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 9.241747\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011321 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1967\n",
      "[LightGBM] [Info] Number of data points in the train set: 718091, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 9.241747\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011149 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1967\n",
      "[LightGBM] [Info] Number of data points in the train set: 718091, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 9.241747\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011803 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1967\n",
      "[LightGBM] [Info] Number of data points in the train set: 718091, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 9.241747\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "estim = [2,5,9,10,15,20,25,50]\n",
    "train_result=[]\n",
    "val_result=[]\n",
    "for i in estim:\n",
    "    lgbm = lgb.LGBMRegressor(n_estimators=50, learning_rate= 0.1 , max_depth=9, random_state=32)\n",
    "    lgbm.fit(x_train, y_train)\n",
    "    y_train_pred = lgbm.predict(x_train)\n",
    "    train_result.append(mean_squared_error(y_train, y_train_pred))\n",
    "    y_val_pred = lgbm.predict(x_val)\n",
    "    val_result.append(mean_squared_error(y_val, y_val_pred))\n",
    "\n",
    "    \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "\n",
    "plt.plot(estim,train_result, marker='o', linestyle='-')\n",
    "plt.plot(estim,val_result, marker='o', linestyle='-')\n",
    "plt.xlabel(\"lr\")\n",
    "plt.ylabel('MSE')\n",
    "plt.title('Learning Rate')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012729 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1967\n",
      "[LightGBM] [Info] Number of data points in the train set: 718091, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 9.241747\n",
      "For max_depth:5,n_estimators:5,learning_rate:0.01\n",
      "            train accuracy:36.1510298109849 validation accuracy:32.4098536029734\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012248 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1967\n",
      "[LightGBM] [Info] Number of data points in the train set: 718091, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 9.241747\n",
      "For max_depth:5,n_estimators:5,learning_rate:0.1\n",
      "            train accuracy:19.0792471541391 validation accuracy:16.626750799625615\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012095 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1967\n",
      "[LightGBM] [Info] Number of data points in the train set: 718091, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 9.241747\n",
      "For max_depth:5,n_estimators:5,learning_rate:1\n",
      "            train accuracy:6.887312439602985 validation accuracy:8.934858202349103\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011357 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1967\n",
      "[LightGBM] [Info] Number of data points in the train set: 718091, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 9.241747\n",
      "For max_depth:5,n_estimators:10,learning_rate:0.01\n",
      "            train accuracy:33.51188038959396 validation accuracy:29.95875345463871\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011159 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1967\n",
      "[LightGBM] [Info] Number of data points in the train set: 718091, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 9.241747\n",
      "For max_depth:5,n_estimators:10,learning_rate:0.1\n",
      "            train accuracy:11.824411465158777 validation accuracy:10.27276795757112\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011664 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1967\n",
      "[LightGBM] [Info] Number of data points in the train set: 718091, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 9.241747\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "For max_depth:5,n_estimators:10,learning_rate:1\n",
      "            train accuracy:6.212862142630698 validation accuracy:10.03957109219477\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011217 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1967\n",
      "[LightGBM] [Info] Number of data points in the train set: 718091, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 9.241747\n",
      "For max_depth:5,n_estimators:15,learning_rate:0.01\n",
      "            train accuracy:31.125080592705153 validation accuracy:27.761787179229668\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011502 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1967\n",
      "[LightGBM] [Info] Number of data points in the train set: 718091, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 9.241747\n",
      "For max_depth:5,n_estimators:15,learning_rate:0.1\n",
      "            train accuracy:9.044898879007789 validation accuracy:8.18401904295112\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012666 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1967\n",
      "[LightGBM] [Info] Number of data points in the train set: 718091, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 9.241747\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "For max_depth:5,n_estimators:15,learning_rate:1\n",
      "            train accuracy:5.716901710809538 validation accuracy:10.529033347670408\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011293 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1967\n",
      "[LightGBM] [Info] Number of data points in the train set: 718091, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 9.241747\n",
      "For max_depth:5,n_estimators:25,learning_rate:0.01\n",
      "            train accuracy:27.009906077774325 validation accuracy:23.965998581335302\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012864 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1967\n",
      "[LightGBM] [Info] Number of data points in the train set: 718091, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 9.241747\n",
      "For max_depth:5,n_estimators:25,learning_rate:0.1\n",
      "            train accuracy:7.325159967307473 validation accuracy:7.104238004114926\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011678 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1967\n",
      "[LightGBM] [Info] Number of data points in the train set: 718091, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 9.241747\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "For max_depth:5,n_estimators:25,learning_rate:1\n",
      "            train accuracy:5.265310504671655 validation accuracy:13.642247373753952\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011604 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1967\n",
      "[LightGBM] [Info] Number of data points in the train set: 718091, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 9.241747\n",
      "For max_depth:5,n_estimators:50,learning_rate:0.01\n",
      "            train accuracy:19.61166251243849 validation accuracy:17.211401353096708\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012190 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1967\n",
      "[LightGBM] [Info] Number of data points in the train set: 718091, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 9.241747\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "For max_depth:5,n_estimators:50,learning_rate:0.1\n",
      "            train accuracy:6.317523631551223 validation accuracy:7.2042821652952025\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011976 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1967\n",
      "[LightGBM] [Info] Number of data points in the train set: 718091, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 9.241747\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "For max_depth:5,n_estimators:50,learning_rate:1\n",
      "            train accuracy:4.567967234947485 validation accuracy:15.72168016429994\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012256 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1967\n",
      "[LightGBM] [Info] Number of data points in the train set: 718091, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 9.241747\n",
      "For max_depth:5,n_estimators:60,learning_rate:0.01\n",
      "            train accuracy:17.524165436599368 validation accuracy:15.348721584176497\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011249 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1967\n",
      "[LightGBM] [Info] Number of data points in the train set: 718091, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 9.241747\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "For max_depth:5,n_estimators:60,learning_rate:0.1\n",
      "            train accuracy:6.141711968971616 validation accuracy:7.159325525089289\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012232 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1967\n",
      "[LightGBM] [Info] Number of data points in the train set: 718091, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 9.241747\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "For max_depth:5,n_estimators:60,learning_rate:1\n",
      "            train accuracy:4.319195063862755 validation accuracy:16.531134821300988\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012118 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1967\n",
      "[LightGBM] [Info] Number of data points in the train set: 718091, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 9.241747\n",
      "For max_depth:5,n_estimators:75,learning_rate:0.01\n",
      "            train accuracy:15.057922007357382 validation accuracy:13.183496946270962\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012370 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1967\n",
      "[LightGBM] [Info] Number of data points in the train set: 718091, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 9.241747\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "For max_depth:5,n_estimators:75,learning_rate:0.1\n",
      "            train accuracy:5.929390376746009 validation accuracy:7.285295169239076\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012435 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1967\n",
      "[LightGBM] [Info] Number of data points in the train set: 718091, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 9.241747\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "For max_depth:5,n_estimators:75,learning_rate:1\n",
      "            train accuracy:4.081689762432775 validation accuracy:17.461827892393565\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011279 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1967\n",
      "[LightGBM] [Info] Number of data points in the train set: 718091, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 9.241747\n",
      "For max_depth:5,n_estimators:100,learning_rate:0.01\n",
      "            train accuracy:12.215511771560614 validation accuracy:10.689304898620676\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013348 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1967\n",
      "[LightGBM] [Info] Number of data points in the train set: 718091, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 9.241747\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "For max_depth:5,n_estimators:100,learning_rate:0.1\n",
      "            train accuracy:5.671810819055032 validation accuracy:7.228834208631496\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012376 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1967\n",
      "[LightGBM] [Info] Number of data points in the train set: 718091, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 9.241747\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "For max_depth:5,n_estimators:100,learning_rate:1\n",
      "            train accuracy:3.77600532390352 validation accuracy:18.277454558105\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011472 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1967\n",
      "[LightGBM] [Info] Number of data points in the train set: 718091, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 9.241747\n",
      "For max_depth:5,n_estimators:125,learning_rate:0.01\n",
      "            train accuracy:10.419588323986646 validation accuracy:9.201288564208\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012052 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1967\n",
      "[LightGBM] [Info] Number of data points in the train set: 718091, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 9.241747\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "For max_depth:5,n_estimators:125,learning_rate:0.1\n",
      "            train accuracy:5.4443583456575695 validation accuracy:7.311239586614756\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013266 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1967\n",
      "[LightGBM] [Info] Number of data points in the train set: 718091, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 9.241747\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "For max_depth:5,n_estimators:125,learning_rate:1\n",
      "            train accuracy:3.5790227780389623 validation accuracy:17.85490655815877\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012220 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1967\n",
      "[LightGBM] [Info] Number of data points in the train set: 718091, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 9.241747\n",
      "For max_depth:5,n_estimators:150,learning_rate:0.01\n",
      "            train accuracy:9.2692290557904 validation accuracy:8.333168061305987\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011764 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1967\n",
      "[LightGBM] [Info] Number of data points in the train set: 718091, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 9.241747\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "For max_depth:5,n_estimators:150,learning_rate:0.1\n",
      "            train accuracy:5.209943257434961 validation accuracy:7.3914374200533866\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011670 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1967\n",
      "[LightGBM] [Info] Number of data points in the train set: 718091, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 9.241747\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "For max_depth:5,n_estimators:150,learning_rate:1\n",
      "            train accuracy:3.4271424476133223 validation accuracy:18.60446854151484\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011500 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1967\n",
      "[LightGBM] [Info] Number of data points in the train set: 718091, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 9.241747\n",
      "For max_depth:5,n_estimators:200,learning_rate:0.01\n",
      "            train accuracy:8.012694824294373 validation accuracy:7.478659381486712\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011462 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1967\n",
      "[LightGBM] [Info] Number of data points in the train set: 718091, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 9.241747\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "For max_depth:5,n_estimators:200,learning_rate:0.1\n",
      "            train accuracy:4.941176819493239 validation accuracy:7.4985102798061\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011848 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1967\n",
      "[LightGBM] [Info] Number of data points in the train set: 718091, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 9.241747\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "For max_depth:5,n_estimators:200,learning_rate:1\n",
      "            train accuracy:3.190165898074657 validation accuracy:19.47967722659873\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011932 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1967\n",
      "[LightGBM] [Info] Number of data points in the train set: 718091, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 9.241747\n",
      "For max_depth:5,n_estimators:250,learning_rate:0.01\n",
      "            train accuracy:7.3825682500551135 validation accuracy:7.138427010589993\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011984 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1967\n",
      "[LightGBM] [Info] Number of data points in the train set: 718091, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 9.241747\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "For max_depth:5,n_estimators:250,learning_rate:0.1\n",
      "            train accuracy:4.714982436490067 validation accuracy:7.78354177377903\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013358 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1967\n",
      "[LightGBM] [Info] Number of data points in the train set: 718091, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 9.241747\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "For max_depth:5,n_estimators:250,learning_rate:1\n",
      "            train accuracy:3.0384623148721657 validation accuracy:27.00969776299401\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011967 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1967\n",
      "[LightGBM] [Info] Number of data points in the train set: 718091, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 9.241747\n",
      "For max_depth:5,n_estimators:300,learning_rate:0.01\n",
      "            train accuracy:7.011735205342217 validation accuracy:7.002819324059821\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011764 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1967\n",
      "[LightGBM] [Info] Number of data points in the train set: 718091, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 9.241747\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "For max_depth:5,n_estimators:300,learning_rate:0.1\n",
      "            train accuracy:4.493292450080644 validation accuracy:8.260804817430381\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011916 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1967\n",
      "[LightGBM] [Info] Number of data points in the train set: 718091, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 9.241747\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "For max_depth:5,n_estimators:300,learning_rate:1\n",
      "            train accuracy:2.913054120223044 validation accuracy:27.68086952531165\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011424 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1967\n",
      "[LightGBM] [Info] Number of data points in the train set: 718091, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 9.241747\n",
      "For max_depth:7,n_estimators:5,learning_rate:0.01\n",
      "            train accuracy:36.11438369444857 validation accuracy:32.366047599975246\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011361 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1967\n",
      "[LightGBM] [Info] Number of data points in the train set: 718091, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 9.241747\n",
      "For max_depth:7,n_estimators:5,learning_rate:0.1\n",
      "            train accuracy:18.818216854977972 validation accuracy:16.424989002306816\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013203 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1967\n",
      "[LightGBM] [Info] Number of data points in the train set: 718091, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 9.241747\n",
      "For max_depth:7,n_estimators:5,learning_rate:1\n",
      "            train accuracy:6.564050220848866 validation accuracy:8.669390941110311\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012197 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1967\n",
      "[LightGBM] [Info] Number of data points in the train set: 718091, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 9.241747\n",
      "For max_depth:7,n_estimators:10,learning_rate:0.01\n",
      "            train accuracy:33.442377547329855 validation accuracy:29.895077629001708\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013696 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1967\n",
      "[LightGBM] [Info] Number of data points in the train set: 718091, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 9.241747\n",
      "For max_depth:7,n_estimators:10,learning_rate:0.1\n",
      "            train accuracy:11.47662540590445 validation accuracy:10.065521306562502\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012330 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1967\n",
      "[LightGBM] [Info] Number of data points in the train set: 718091, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 9.241747\n",
      "For max_depth:7,n_estimators:10,learning_rate:1\n",
      "            train accuracy:5.848102461163173 validation accuracy:9.207716368354465\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013284 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1967\n",
      "[LightGBM] [Info] Number of data points in the train set: 718091, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 9.241747\n",
      "For max_depth:7,n_estimators:15,learning_rate:0.01\n",
      "            train accuracy:31.024839180190998 validation accuracy:27.67102873196682\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012348 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1967\n",
      "[LightGBM] [Info] Number of data points in the train set: 718091, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 9.241747\n",
      "For max_depth:7,n_estimators:15,learning_rate:0.1\n",
      "            train accuracy:8.655186553284112 validation accuracy:7.951003873933048\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011395 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1967\n",
      "[LightGBM] [Info] Number of data points in the train set: 718091, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 9.241747\n",
      "For max_depth:7,n_estimators:15,learning_rate:1\n",
      "            train accuracy:5.476943647766671 validation accuracy:10.083116527150558\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011325 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1967\n",
      "[LightGBM] [Info] Number of data points in the train set: 718091, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 9.241747\n",
      "For max_depth:7,n_estimators:25,learning_rate:0.01\n",
      "            train accuracy:26.852864522664373 validation accuracy:23.829504465906123\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012592 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1967\n",
      "[LightGBM] [Info] Number of data points in the train set: 718091, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 9.241747\n",
      "For max_depth:7,n_estimators:25,learning_rate:0.1\n",
      "            train accuracy:6.861302449827877 validation accuracy:7.1709698322716084\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011572 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1967\n",
      "[LightGBM] [Info] Number of data points in the train set: 718091, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 9.241747\n",
      "For max_depth:7,n_estimators:25,learning_rate:1\n",
      "            train accuracy:4.852564554859439 validation accuracy:12.360093764598227\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011286 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1967\n",
      "[LightGBM] [Info] Number of data points in the train set: 718091, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 9.241747\n",
      "For max_depth:7,n_estimators:50,learning_rate:0.01\n",
      "            train accuracy:19.358760912481834 validation accuracy:17.01786485161311\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011697 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1967\n",
      "[LightGBM] [Info] Number of data points in the train set: 718091, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 9.241747\n",
      "For max_depth:7,n_estimators:50,learning_rate:0.1\n",
      "            train accuracy:5.857721651422725 validation accuracy:7.289547771435393\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012311 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1967\n",
      "[LightGBM] [Info] Number of data points in the train set: 718091, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 9.241747\n",
      "For max_depth:7,n_estimators:50,learning_rate:1\n",
      "            train accuracy:4.056100787706094 validation accuracy:14.653880308307091\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012421 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1967\n",
      "[LightGBM] [Info] Number of data points in the train set: 718091, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 9.241747\n",
      "For max_depth:7,n_estimators:60,learning_rate:0.01\n",
      "            train accuracy:17.243287805077596 validation accuracy:15.118102587276864\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011928 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1967\n",
      "[LightGBM] [Info] Number of data points in the train set: 718091, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 9.241747\n",
      "For max_depth:7,n_estimators:60,learning_rate:0.1\n",
      "            train accuracy:5.666294419926367 validation accuracy:7.219483976661776\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011362 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1967\n",
      "[LightGBM] [Info] Number of data points in the train set: 718091, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 9.241747\n",
      "For max_depth:7,n_estimators:60,learning_rate:1\n",
      "            train accuracy:3.8395502079847734 validation accuracy:17.318414871581524\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012004 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1967\n",
      "[LightGBM] [Info] Number of data points in the train set: 718091, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 9.241747\n",
      "For max_depth:7,n_estimators:75,learning_rate:0.01\n",
      "            train accuracy:14.74180622808673 validation accuracy:12.910969883003595\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012202 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1967\n",
      "[LightGBM] [Info] Number of data points in the train set: 718091, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 9.241747\n",
      "For max_depth:7,n_estimators:75,learning_rate:0.1\n",
      "            train accuracy:5.453439072447597 validation accuracy:7.217363082678267\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011812 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1967\n",
      "[LightGBM] [Info] Number of data points in the train set: 718091, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 9.241747\n",
      "For max_depth:7,n_estimators:75,learning_rate:1\n",
      "            train accuracy:3.608856851881323 validation accuracy:17.072166476052068\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011981 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1967\n",
      "[LightGBM] [Info] Number of data points in the train set: 718091, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 9.241747\n",
      "For max_depth:7,n_estimators:100,learning_rate:0.01\n",
      "            train accuracy:11.878385666506578 validation accuracy:10.43391560344328\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011705 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1967\n",
      "[LightGBM] [Info] Number of data points in the train set: 718091, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 9.241747\n",
      "For max_depth:7,n_estimators:100,learning_rate:0.1\n",
      "            train accuracy:5.164596214807386 validation accuracy:7.340907751937307\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011702 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1967\n",
      "[LightGBM] [Info] Number of data points in the train set: 718091, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 9.241747\n",
      "For max_depth:7,n_estimators:100,learning_rate:1\n",
      "            train accuracy:3.348378409140225 validation accuracy:17.619478557080985\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011627 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1967\n",
      "[LightGBM] [Info] Number of data points in the train set: 718091, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 9.241747\n",
      "For max_depth:7,n_estimators:125,learning_rate:0.01\n",
      "            train accuracy:10.066209772382148 validation accuracy:8.968872053811841\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011138 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1967\n",
      "[LightGBM] [Info] Number of data points in the train set: 718091, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 9.241747\n",
      "For max_depth:7,n_estimators:125,learning_rate:0.1\n",
      "            train accuracy:4.940920854556559 validation accuracy:7.4285334169634\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012518 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1967\n",
      "[LightGBM] [Info] Number of data points in the train set: 718091, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 9.241747\n",
      "For max_depth:7,n_estimators:125,learning_rate:1\n",
      "            train accuracy:3.133907663552601 validation accuracy:18.278132840700582\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011735 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1967\n",
      "[LightGBM] [Info] Number of data points in the train set: 718091, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 9.241747\n",
      "For max_depth:7,n_estimators:150,learning_rate:0.01\n",
      "            train accuracy:8.897928071413094 validation accuracy:8.148099482467224\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011806 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1967\n",
      "[LightGBM] [Info] Number of data points in the train set: 718091, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 9.241747\n",
      "For max_depth:7,n_estimators:150,learning_rate:0.1\n",
      "            train accuracy:4.740034585432332 validation accuracy:7.331968348511433\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011117 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1967\n",
      "[LightGBM] [Info] Number of data points in the train set: 718091, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 9.241747\n",
      "For max_depth:7,n_estimators:150,learning_rate:1\n",
      "            train accuracy:2.960860851351648 validation accuracy:19.79978409296986\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011895 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1967\n",
      "[LightGBM] [Info] Number of data points in the train set: 718091, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 9.241747\n",
      "For max_depth:7,n_estimators:200,learning_rate:0.01\n",
      "            train accuracy:7.60480789939765 validation accuracy:7.376319260281392\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011981 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1967\n",
      "[LightGBM] [Info] Number of data points in the train set: 718091, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 9.241747\n",
      "For max_depth:7,n_estimators:200,learning_rate:0.1\n",
      "            train accuracy:4.467659367141473 validation accuracy:7.773918091150234\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011701 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1967\n",
      "[LightGBM] [Info] Number of data points in the train set: 718091, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 9.241747\n",
      "For max_depth:7,n_estimators:200,learning_rate:1\n",
      "            train accuracy:2.7520075014970815 validation accuracy:19.491929183275577\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012238 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1967\n",
      "[LightGBM] [Info] Number of data points in the train set: 718091, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 9.241747\n",
      "For max_depth:7,n_estimators:250,learning_rate:0.01\n",
      "            train accuracy:6.956997794954376 validation accuracy:7.10395954173065\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012137 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1967\n",
      "[LightGBM] [Info] Number of data points in the train set: 718091, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 9.241747\n",
      "For max_depth:7,n_estimators:250,learning_rate:0.1\n",
      "            train accuracy:4.230295967856061 validation accuracy:7.867055251581899\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013013 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1967\n",
      "[LightGBM] [Info] Number of data points in the train set: 718091, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 9.241747\n",
      "For max_depth:7,n_estimators:250,learning_rate:1\n",
      "            train accuracy:2.6063359637482346 validation accuracy:19.31954772966302\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011351 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1967\n",
      "[LightGBM] [Info] Number of data points in the train set: 718091, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 9.241747\n",
      "For max_depth:7,n_estimators:300,learning_rate:0.01\n",
      "            train accuracy:6.59316561232012 validation accuracy:6.982576981787806\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012110 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1967\n",
      "[LightGBM] [Info] Number of data points in the train set: 718091, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 9.241747\n",
      "For max_depth:7,n_estimators:300,learning_rate:0.1\n",
      "            train accuracy:4.0448157437628165 validation accuracy:7.882300844796235\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011650 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1967\n",
      "[LightGBM] [Info] Number of data points in the train set: 718091, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 9.241747\n",
      "For max_depth:7,n_estimators:300,learning_rate:1\n",
      "            train accuracy:2.482821388975249 validation accuracy:20.819897341699473\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011746 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1967\n",
      "[LightGBM] [Info] Number of data points in the train set: 718091, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 9.241747\n",
      "For max_depth:9,n_estimators:5,learning_rate:0.01\n",
      "            train accuracy:36.1100851928192 validation accuracy:32.40330110376537\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011620 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1967\n",
      "[LightGBM] [Info] Number of data points in the train set: 718091, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 9.241747\n",
      "For max_depth:9,n_estimators:5,learning_rate:0.1\n",
      "            train accuracy:18.81876765243617 validation accuracy:16.629171431026514\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011103 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1967\n",
      "[LightGBM] [Info] Number of data points in the train set: 718091, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 9.241747\n",
      "For max_depth:9,n_estimators:5,learning_rate:1\n",
      "            train accuracy:6.400790367763937 validation accuracy:8.735843826715152\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012315 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1967\n",
      "[LightGBM] [Info] Number of data points in the train set: 718091, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 9.241747\n",
      "For max_depth:9,n_estimators:10,learning_rate:0.01\n",
      "            train accuracy:33.43465682064453 validation accuracy:29.94663507675778\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011764 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1967\n",
      "[LightGBM] [Info] Number of data points in the train set: 718091, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 9.241747\n",
      "For max_depth:9,n_estimators:10,learning_rate:0.1\n",
      "            train accuracy:11.444514122768236 validation accuracy:10.100552170984837\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011333 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1967\n",
      "[LightGBM] [Info] Number of data points in the train set: 718091, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 9.241747\n",
      "For max_depth:9,n_estimators:10,learning_rate:1\n",
      "            train accuracy:5.512368974780828 validation accuracy:9.490424885535454\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011545 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1967\n",
      "[LightGBM] [Info] Number of data points in the train set: 718091, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 9.241747\n",
      "For max_depth:9,n_estimators:15,learning_rate:0.01\n",
      "            train accuracy:31.015225042626138 validation accuracy:27.72862261985223\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012784 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1967\n",
      "[LightGBM] [Info] Number of data points in the train set: 718091, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 9.241747\n",
      "For max_depth:9,n_estimators:15,learning_rate:0.1\n",
      "            train accuracy:8.62180932341812 validation accuracy:7.95450352799318\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011717 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1967\n",
      "[LightGBM] [Info] Number of data points in the train set: 718091, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 9.241747\n",
      "For max_depth:9,n_estimators:15,learning_rate:1\n",
      "            train accuracy:5.1618620026032636 validation accuracy:9.954361741132832\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011710 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1967\n",
      "[LightGBM] [Info] Number of data points in the train set: 718091, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 9.241747\n",
      "For max_depth:9,n_estimators:25,learning_rate:0.01\n",
      "            train accuracy:26.837617638433976 validation accuracy:23.911075973446565\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011234 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1967\n",
      "[LightGBM] [Info] Number of data points in the train set: 718091, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 9.241747\n",
      "For max_depth:9,n_estimators:25,learning_rate:0.1\n",
      "            train accuracy:6.838875741409382 validation accuracy:7.058825214075621\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012195 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1967\n",
      "[LightGBM] [Info] Number of data points in the train set: 718091, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 9.241747\n",
      "For max_depth:9,n_estimators:25,learning_rate:1\n",
      "            train accuracy:4.619796497282966 validation accuracy:13.302453746953859\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011807 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1967\n",
      "[LightGBM] [Info] Number of data points in the train set: 718091, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 9.241747\n",
      "For max_depth:9,n_estimators:50,learning_rate:0.01\n",
      "            train accuracy:19.32999218144027 validation accuracy:17.060863209614602\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011715 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1967\n",
      "[LightGBM] [Info] Number of data points in the train set: 718091, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 9.241747\n",
      "For max_depth:9,n_estimators:50,learning_rate:0.1\n",
      "            train accuracy:5.79335459659343 validation accuracy:6.862403055174539\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012095 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1967\n",
      "[LightGBM] [Info] Number of data points in the train set: 718091, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 9.241747\n",
      "For max_depth:9,n_estimators:50,learning_rate:1\n",
      "            train accuracy:3.887645012561424 validation accuracy:15.802021284714682\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012192 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1967\n",
      "[LightGBM] [Info] Number of data points in the train set: 718091, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 9.241747\n",
      "For max_depth:9,n_estimators:60,learning_rate:0.01\n",
      "            train accuracy:17.21709381935963 validation accuracy:15.140543991838733\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012210 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1967\n",
      "[LightGBM] [Info] Number of data points in the train set: 718091, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 9.241747\n",
      "For max_depth:9,n_estimators:60,learning_rate:0.1\n",
      "            train accuracy:5.609826744321922 validation accuracy:6.944909557591066\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011242 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1967\n",
      "[LightGBM] [Info] Number of data points in the train set: 718091, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 9.241747\n",
      "For max_depth:9,n_estimators:60,learning_rate:1\n",
      "            train accuracy:3.7098414555813926 validation accuracy:16.226143134057814\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011698 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1967\n",
      "[LightGBM] [Info] Number of data points in the train set: 718091, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 9.241747\n",
      "For max_depth:9,n_estimators:75,learning_rate:0.01\n",
      "            train accuracy:14.72339282735465 validation accuracy:12.90260141683059\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011730 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1967\n",
      "[LightGBM] [Info] Number of data points in the train set: 718091, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 9.241747\n",
      "For max_depth:9,n_estimators:75,learning_rate:0.1\n",
      "            train accuracy:5.396368263081369 validation accuracy:6.985789810082333\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011663 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1967\n",
      "[LightGBM] [Info] Number of data points in the train set: 718091, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 9.241747\n",
      "For max_depth:9,n_estimators:75,learning_rate:1\n",
      "            train accuracy:3.4889962214283594 validation accuracy:16.668571018718648\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012194 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1967\n",
      "[LightGBM] [Info] Number of data points in the train set: 718091, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 9.241747\n",
      "For max_depth:9,n_estimators:100,learning_rate:0.01\n",
      "            train accuracy:11.847676610475792 validation accuracy:10.421328183537943\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012310 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1967\n",
      "[LightGBM] [Info] Number of data points in the train set: 718091, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 9.241747\n",
      "For max_depth:9,n_estimators:100,learning_rate:0.1\n",
      "            train accuracy:5.073505384032191 validation accuracy:7.12044120059369\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011913 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1967\n",
      "[LightGBM] [Info] Number of data points in the train set: 718091, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 9.241747\n",
      "For max_depth:9,n_estimators:100,learning_rate:1\n",
      "            train accuracy:3.1626731029965978 validation accuracy:17.779421375720734\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011606 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1967\n",
      "[LightGBM] [Info] Number of data points in the train set: 718091, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 9.241747\n",
      "For max_depth:9,n_estimators:125,learning_rate:0.01\n",
      "            train accuracy:10.02834097109384 validation accuracy:8.961550140339698\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011720 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1967\n",
      "[LightGBM] [Info] Number of data points in the train set: 718091, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 9.241747\n",
      "For max_depth:9,n_estimators:125,learning_rate:0.1\n",
      "            train accuracy:4.863773354452936 validation accuracy:7.256082523888287\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011608 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1967\n",
      "[LightGBM] [Info] Number of data points in the train set: 718091, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 9.241747\n",
      "For max_depth:9,n_estimators:125,learning_rate:1\n",
      "            train accuracy:2.9755499076926566 validation accuracy:18.779872492145454\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012448 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1967\n",
      "[LightGBM] [Info] Number of data points in the train set: 718091, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 9.241747\n",
      "For max_depth:9,n_estimators:150,learning_rate:0.01\n",
      "            train accuracy:8.836222636225802 validation accuracy:8.0873744250447\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011985 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1967\n",
      "[LightGBM] [Info] Number of data points in the train set: 718091, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 9.241747\n",
      "For max_depth:9,n_estimators:150,learning_rate:0.1\n",
      "            train accuracy:4.689335703255237 validation accuracy:7.313379935743649\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011269 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1967\n",
      "[LightGBM] [Info] Number of data points in the train set: 718091, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 9.241747\n",
      "For max_depth:9,n_estimators:150,learning_rate:1\n",
      "            train accuracy:2.8429621653776556 validation accuracy:18.627453996369137\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012292 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1967\n",
      "[LightGBM] [Info] Number of data points in the train set: 718091, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 9.241747\n",
      "For max_depth:9,n_estimators:200,learning_rate:0.01\n",
      "            train accuracy:7.5355464119816435 validation accuracy:7.2945568849629305\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012161 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1967\n",
      "[LightGBM] [Info] Number of data points in the train set: 718091, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 9.241747\n",
      "For max_depth:9,n_estimators:200,learning_rate:0.1\n",
      "            train accuracy:4.387398348234794 validation accuracy:7.547840403493835\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012096 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1967\n",
      "[LightGBM] [Info] Number of data points in the train set: 718091, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 9.241747\n",
      "For max_depth:9,n_estimators:200,learning_rate:1\n",
      "            train accuracy:2.646300192391826 validation accuracy:20.197993793902395\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011570 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1967\n",
      "[LightGBM] [Info] Number of data points in the train set: 718091, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 9.241747\n",
      "For max_depth:9,n_estimators:250,learning_rate:0.01\n",
      "            train accuracy:6.8951307027972195 validation accuracy:6.993195644952389\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011750 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1967\n",
      "[LightGBM] [Info] Number of data points in the train set: 718091, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 9.241747\n",
      "For max_depth:9,n_estimators:250,learning_rate:0.1\n",
      "            train accuracy:4.153889424757686 validation accuracy:7.624255441274589\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011475 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1967\n",
      "[LightGBM] [Info] Number of data points in the train set: 718091, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 9.241747\n",
      "For max_depth:9,n_estimators:250,learning_rate:1\n",
      "            train accuracy:2.4799650270169398 validation accuracy:20.564284988790796\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011789 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1967\n",
      "[LightGBM] [Info] Number of data points in the train set: 718091, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 9.241747\n",
      "For max_depth:9,n_estimators:300,learning_rate:0.01\n",
      "            train accuracy:6.528886136628606 validation accuracy:6.888768302366576\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012428 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1967\n",
      "[LightGBM] [Info] Number of data points in the train set: 718091, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 9.241747\n",
      "For max_depth:9,n_estimators:300,learning_rate:0.1\n",
      "            train accuracy:3.9679300530114223 validation accuracy:7.7002311119665725\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011387 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1967\n",
      "[LightGBM] [Info] Number of data points in the train set: 718091, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 9.241747\n",
      "For max_depth:9,n_estimators:300,learning_rate:1\n",
      "            train accuracy:2.371983613422993 validation accuracy:20.00705280335408\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011796 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1967\n",
      "[LightGBM] [Info] Number of data points in the train set: 718091, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 9.241747\n",
      "For max_depth:12,n_estimators:5,learning_rate:0.01\n",
      "            train accuracy:36.1100851928192 validation accuracy:32.40330110376537\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011088 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1967\n",
      "[LightGBM] [Info] Number of data points in the train set: 718091, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 9.241747\n",
      "For max_depth:12,n_estimators:5,learning_rate:0.1\n",
      "            train accuracy:18.81876765243617 validation accuracy:16.629171431026514\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011370 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1967\n",
      "[LightGBM] [Info] Number of data points in the train set: 718091, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 9.241747\n",
      "For max_depth:12,n_estimators:5,learning_rate:1\n",
      "            train accuracy:6.4269340938036805 validation accuracy:8.691932290302596\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012395 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1967\n",
      "[LightGBM] [Info] Number of data points in the train set: 718091, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 9.241747\n",
      "For max_depth:12,n_estimators:10,learning_rate:0.01\n",
      "            train accuracy:33.43465682064453 validation accuracy:29.94663507675778\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012624 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1967\n",
      "[LightGBM] [Info] Number of data points in the train set: 718091, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 9.241747\n",
      "For max_depth:12,n_estimators:10,learning_rate:0.1\n",
      "            train accuracy:11.431832951324534 validation accuracy:10.136195008065027\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012400 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1967\n",
      "[LightGBM] [Info] Number of data points in the train set: 718091, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 9.241747\n",
      "For max_depth:12,n_estimators:10,learning_rate:1\n",
      "            train accuracy:5.686434121022398 validation accuracy:11.420519492662354\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012365 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1967\n",
      "[LightGBM] [Info] Number of data points in the train set: 718091, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 9.241747\n",
      "For max_depth:12,n_estimators:15,learning_rate:0.01\n",
      "            train accuracy:31.015225042626138 validation accuracy:27.72862261985223\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013144 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1967\n",
      "[LightGBM] [Info] Number of data points in the train set: 718091, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 9.241747\n",
      "For max_depth:12,n_estimators:15,learning_rate:0.1\n",
      "            train accuracy:8.587169147488623 validation accuracy:7.971724420335657\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012774 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1967\n",
      "[LightGBM] [Info] Number of data points in the train set: 718091, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 9.241747\n",
      "For max_depth:12,n_estimators:15,learning_rate:1\n",
      "            train accuracy:5.2449215194323235 validation accuracy:11.768756667242442\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012977 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1967\n",
      "[LightGBM] [Info] Number of data points in the train set: 718091, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 9.241747\n",
      "For max_depth:12,n_estimators:25,learning_rate:0.01\n",
      "            train accuracy:26.837617638433976 validation accuracy:23.911075973446565\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011765 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1967\n",
      "[LightGBM] [Info] Number of data points in the train set: 718091, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 9.241747\n",
      "For max_depth:12,n_estimators:25,learning_rate:0.1\n",
      "            train accuracy:6.799305399403307 validation accuracy:7.022459400241077\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011418 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1967\n",
      "[LightGBM] [Info] Number of data points in the train set: 718091, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 9.241747\n",
      "For max_depth:12,n_estimators:25,learning_rate:1\n",
      "            train accuracy:4.702729262787879 validation accuracy:12.863906075116178\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011781 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1967\n",
      "[LightGBM] [Info] Number of data points in the train set: 718091, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 9.241747\n",
      "For max_depth:12,n_estimators:50,learning_rate:0.01\n",
      "            train accuracy:19.326136748243666 validation accuracy:17.07338870859655\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012402 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1967\n",
      "[LightGBM] [Info] Number of data points in the train set: 718091, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 9.241747\n",
      "For max_depth:12,n_estimators:50,learning_rate:0.1\n",
      "            train accuracy:5.803280860300373 validation accuracy:7.198460319083208\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012431 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1967\n",
      "[LightGBM] [Info] Number of data points in the train set: 718091, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 9.241747\n",
      "For max_depth:12,n_estimators:50,learning_rate:1\n",
      "            train accuracy:3.962169716825341 validation accuracy:12.981523648956136\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011453 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1967\n",
      "[LightGBM] [Info] Number of data points in the train set: 718091, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 9.241747\n",
      "For max_depth:12,n_estimators:60,learning_rate:0.01\n",
      "            train accuracy:17.211998126801497 validation accuracy:15.1537443267202\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011661 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1967\n",
      "[LightGBM] [Info] Number of data points in the train set: 718091, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 9.241747\n",
      "For max_depth:12,n_estimators:60,learning_rate:0.1\n",
      "            train accuracy:5.598659991829689 validation accuracy:7.163036763685713\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012373 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1967\n",
      "[LightGBM] [Info] Number of data points in the train set: 718091, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 9.241747\n",
      "For max_depth:12,n_estimators:60,learning_rate:1\n",
      "            train accuracy:3.749828683499798 validation accuracy:12.953536307904386\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011742 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1967\n",
      "[LightGBM] [Info] Number of data points in the train set: 718091, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 9.241747\n",
      "For max_depth:12,n_estimators:75,learning_rate:0.01\n",
      "            train accuracy:14.719450385747555 validation accuracy:12.921410236766066\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012600 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1967\n",
      "[LightGBM] [Info] Number of data points in the train set: 718091, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 9.241747\n",
      "For max_depth:12,n_estimators:75,learning_rate:0.1\n",
      "            train accuracy:5.360531510180678 validation accuracy:7.168584701021729\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011710 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1967\n",
      "[LightGBM] [Info] Number of data points in the train set: 718091, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 9.241747\n",
      "For max_depth:12,n_estimators:75,learning_rate:1\n",
      "            train accuracy:3.4602853643631395 validation accuracy:13.092111825545139\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011750 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1967\n",
      "[LightGBM] [Info] Number of data points in the train set: 718091, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 9.241747\n",
      "For max_depth:12,n_estimators:100,learning_rate:0.01\n",
      "            train accuracy:11.83918521207329 validation accuracy:10.4350060556598\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011541 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1967\n",
      "[LightGBM] [Info] Number of data points in the train set: 718091, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 9.241747\n",
      "For max_depth:12,n_estimators:100,learning_rate:0.1\n",
      "            train accuracy:5.0472977867735525 validation accuracy:7.198833293875802\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011793 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1967\n",
      "[LightGBM] [Info] Number of data points in the train set: 718091, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 9.241747\n",
      "For max_depth:12,n_estimators:100,learning_rate:1\n",
      "            train accuracy:3.1684238176373776 validation accuracy:13.95658216314169\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011737 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1967\n",
      "[LightGBM] [Info] Number of data points in the train set: 718091, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 9.241747\n",
      "For max_depth:12,n_estimators:125,learning_rate:0.01\n",
      "            train accuracy:10.02062533702923 validation accuracy:8.963989093831417\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013176 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1967\n",
      "[LightGBM] [Info] Number of data points in the train set: 718091, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 9.241747\n",
      "For max_depth:12,n_estimators:125,learning_rate:0.1\n",
      "            train accuracy:4.833281443990455 validation accuracy:7.238703822458244\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012468 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1967\n",
      "[LightGBM] [Info] Number of data points in the train set: 718091, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 9.241747\n",
      "For max_depth:12,n_estimators:125,learning_rate:1\n",
      "            train accuracy:2.9340518228690673 validation accuracy:14.216621551469428\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011482 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1967\n",
      "[LightGBM] [Info] Number of data points in the train set: 718091, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 9.241747\n",
      "For max_depth:12,n_estimators:150,learning_rate:0.01\n",
      "            train accuracy:8.833657100565798 validation accuracy:8.096464192184317\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011557 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1967\n",
      "[LightGBM] [Info] Number of data points in the train set: 718091, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 9.241747\n",
      "For max_depth:12,n_estimators:150,learning_rate:0.1\n",
      "            train accuracy:4.628337706796416 validation accuracy:7.252026372812931\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011305 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1967\n",
      "[LightGBM] [Info] Number of data points in the train set: 718091, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 9.241747\n",
      "For max_depth:12,n_estimators:150,learning_rate:1\n",
      "            train accuracy:2.782249736511344 validation accuracy:14.565149794689177\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011651 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1967\n",
      "[LightGBM] [Info] Number of data points in the train set: 718091, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 9.241747\n",
      "For max_depth:12,n_estimators:200,learning_rate:0.01\n",
      "            train accuracy:7.520412955472662 validation accuracy:7.300575971857771\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011227 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1967\n",
      "[LightGBM] [Info] Number of data points in the train set: 718091, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 9.241747\n",
      "For max_depth:12,n_estimators:200,learning_rate:0.1\n",
      "            train accuracy:4.338986703813131 validation accuracy:7.420222969378341\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011551 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1967\n",
      "[LightGBM] [Info] Number of data points in the train set: 718091, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 9.241747\n",
      "For max_depth:12,n_estimators:200,learning_rate:1\n",
      "            train accuracy:2.5661155390463564 validation accuracy:14.238309519912088\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012313 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1967\n",
      "[LightGBM] [Info] Number of data points in the train set: 718091, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 9.241747\n",
      "For max_depth:12,n_estimators:250,learning_rate:0.01\n",
      "            train accuracy:6.872394115146643 validation accuracy:6.991727217259841\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011854 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1967\n",
      "[LightGBM] [Info] Number of data points in the train set: 718091, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 9.241747\n",
      "For max_depth:12,n_estimators:250,learning_rate:0.1\n",
      "            train accuracy:4.109001059462574 validation accuracy:7.6868268538967675\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011319 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1967\n",
      "[LightGBM] [Info] Number of data points in the train set: 718091, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 9.241747\n",
      "For max_depth:12,n_estimators:250,learning_rate:1\n",
      "            train accuracy:2.41135468081705 validation accuracy:14.518512355204527\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011849 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1967\n",
      "[LightGBM] [Info] Number of data points in the train set: 718091, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 9.241747\n",
      "For max_depth:12,n_estimators:300,learning_rate:0.01\n",
      "            train accuracy:6.512326026098987 validation accuracy:6.883402563784268\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011651 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1967\n",
      "[LightGBM] [Info] Number of data points in the train set: 718091, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 9.241747\n",
      "For max_depth:12,n_estimators:300,learning_rate:0.1\n",
      "            train accuracy:3.894099112813568 validation accuracy:7.664626383881851\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011964 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1967\n",
      "[LightGBM] [Info] Number of data points in the train set: 718091, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 9.241747\n",
      "For max_depth:12,n_estimators:300,learning_rate:1\n",
      "            train accuracy:2.2938642708885126 validation accuracy:14.708310173854914\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011764 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1967\n",
      "[LightGBM] [Info] Number of data points in the train set: 718091, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 9.241747\n",
      "For max_depth:15,n_estimators:5,learning_rate:0.01\n",
      "            train accuracy:36.1100851928192 validation accuracy:32.40330110376537\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011798 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1967\n",
      "[LightGBM] [Info] Number of data points in the train set: 718091, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 9.241747\n",
      "For max_depth:15,n_estimators:5,learning_rate:0.1\n",
      "            train accuracy:18.81876765243617 validation accuracy:16.629171431026514\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012278 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1967\n",
      "[LightGBM] [Info] Number of data points in the train set: 718091, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 9.241747\n",
      "For max_depth:15,n_estimators:5,learning_rate:1\n",
      "            train accuracy:6.4269340938036805 validation accuracy:8.691932290302596\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012131 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1967\n",
      "[LightGBM] [Info] Number of data points in the train set: 718091, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 9.241747\n",
      "For max_depth:15,n_estimators:10,learning_rate:0.01\n",
      "            train accuracy:33.43465682064453 validation accuracy:29.94663507675778\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012275 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1967\n",
      "[LightGBM] [Info] Number of data points in the train set: 718091, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 9.241747\n",
      "For max_depth:15,n_estimators:10,learning_rate:0.1\n",
      "            train accuracy:11.431832951324534 validation accuracy:10.136195008065027\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013699 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1967\n",
      "[LightGBM] [Info] Number of data points in the train set: 718091, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 9.241747\n",
      "For max_depth:15,n_estimators:10,learning_rate:1\n",
      "            train accuracy:5.686434121022398 validation accuracy:11.420519492662354\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011756 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1967\n",
      "[LightGBM] [Info] Number of data points in the train set: 718091, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 9.241747\n",
      "For max_depth:15,n_estimators:15,learning_rate:0.01\n",
      "            train accuracy:31.015225042626138 validation accuracy:27.72862261985223\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011943 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1967\n",
      "[LightGBM] [Info] Number of data points in the train set: 718091, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 9.241747\n",
      "For max_depth:15,n_estimators:15,learning_rate:0.1\n",
      "            train accuracy:8.587169147488623 validation accuracy:7.971724420335657\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011887 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1967\n",
      "[LightGBM] [Info] Number of data points in the train set: 718091, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 9.241747\n",
      "For max_depth:15,n_estimators:15,learning_rate:1\n",
      "            train accuracy:5.243414350580758 validation accuracy:11.490725976647802\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011682 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1967\n",
      "[LightGBM] [Info] Number of data points in the train set: 718091, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 9.241747\n",
      "For max_depth:15,n_estimators:25,learning_rate:0.01\n",
      "            train accuracy:26.837617638433976 validation accuracy:23.911075973446565\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011762 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1967\n",
      "[LightGBM] [Info] Number of data points in the train set: 718091, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 9.241747\n",
      "For max_depth:15,n_estimators:25,learning_rate:0.1\n",
      "            train accuracy:6.799305399403307 validation accuracy:7.022459400241077\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013323 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1967\n",
      "[LightGBM] [Info] Number of data points in the train set: 718091, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 9.241747\n",
      "For max_depth:15,n_estimators:25,learning_rate:1\n",
      "            train accuracy:4.616861942733784 validation accuracy:18.438365879195644\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011785 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1967\n",
      "[LightGBM] [Info] Number of data points in the train set: 718091, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 9.241747\n",
      "For max_depth:15,n_estimators:50,learning_rate:0.01\n",
      "            train accuracy:19.326136748243666 validation accuracy:17.07338870859655\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011612 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1967\n",
      "[LightGBM] [Info] Number of data points in the train set: 718091, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 9.241747\n",
      "For max_depth:15,n_estimators:50,learning_rate:0.1\n",
      "            train accuracy:5.782819106433898 validation accuracy:7.0909904486419535\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011836 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1967\n",
      "[LightGBM] [Info] Number of data points in the train set: 718091, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 9.241747\n",
      "For max_depth:15,n_estimators:50,learning_rate:1\n",
      "            train accuracy:3.8188628860213196 validation accuracy:19.91927594914108\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012195 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1967\n",
      "[LightGBM] [Info] Number of data points in the train set: 718091, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 9.241747\n",
      "For max_depth:15,n_estimators:60,learning_rate:0.01\n",
      "            train accuracy:17.211998126801497 validation accuracy:15.1537443267202\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013097 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1967\n",
      "[LightGBM] [Info] Number of data points in the train set: 718091, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 9.241747\n",
      "For max_depth:15,n_estimators:60,learning_rate:0.1\n",
      "            train accuracy:5.6021788352459145 validation accuracy:7.055728532364733\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012376 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1967\n",
      "[LightGBM] [Info] Number of data points in the train set: 718091, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 9.241747\n",
      "For max_depth:15,n_estimators:60,learning_rate:1\n",
      "            train accuracy:3.6835957113514817 validation accuracy:21.660807177119295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011854 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1967\n",
      "[LightGBM] [Info] Number of data points in the train set: 718091, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 9.241747\n",
      "For max_depth:15,n_estimators:75,learning_rate:0.01\n",
      "            train accuracy:14.719450385747555 validation accuracy:12.921410236766066\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012695 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1967\n",
      "[LightGBM] [Info] Number of data points in the train set: 718091, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 9.241747\n",
      "For max_depth:15,n_estimators:75,learning_rate:0.1\n",
      "            train accuracy:5.382615983897486 validation accuracy:7.090464943567633\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011843 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1967\n",
      "[LightGBM] [Info] Number of data points in the train set: 718091, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 9.241747\n",
      "For max_depth:15,n_estimators:75,learning_rate:1\n",
      "            train accuracy:3.4683346485167745 validation accuracy:19.697967307580065\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011633 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1967\n",
      "[LightGBM] [Info] Number of data points in the train set: 718091, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 9.241747\n",
      "For max_depth:15,n_estimators:100,learning_rate:0.01\n",
      "            train accuracy:11.83918521207329 validation accuracy:10.4350060556598\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011670 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1967\n",
      "[LightGBM] [Info] Number of data points in the train set: 718091, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 9.241747\n",
      "For max_depth:15,n_estimators:100,learning_rate:0.1\n",
      "            train accuracy:5.066651613068547 validation accuracy:7.189647731955335\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012339 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1967\n",
      "[LightGBM] [Info] Number of data points in the train set: 718091, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 9.241747\n",
      "For max_depth:15,n_estimators:100,learning_rate:1\n",
      "            train accuracy:3.185706845909787 validation accuracy:20.840337450995854\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011582 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1967\n",
      "[LightGBM] [Info] Number of data points in the train set: 718091, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 9.241747\n",
      "For max_depth:15,n_estimators:125,learning_rate:0.01\n",
      "            train accuracy:10.02062533702923 validation accuracy:8.963989093831417\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012280 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1967\n",
      "[LightGBM] [Info] Number of data points in the train set: 718091, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 9.241747\n",
      "For max_depth:15,n_estimators:125,learning_rate:0.1\n",
      "            train accuracy:4.8276801950741595 validation accuracy:7.276774076187259\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013090 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1967\n",
      "[LightGBM] [Info] Number of data points in the train set: 718091, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 9.241747\n",
      "For max_depth:15,n_estimators:125,learning_rate:1\n",
      "            train accuracy:2.956951266570726 validation accuracy:20.211696752472065\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013052 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1967\n",
      "[LightGBM] [Info] Number of data points in the train set: 718091, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 9.241747\n",
      "For max_depth:15,n_estimators:150,learning_rate:0.01\n",
      "            train accuracy:8.833611919020473 validation accuracy:8.095990315735431\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013058 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1967\n",
      "[LightGBM] [Info] Number of data points in the train set: 718091, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 9.241747\n",
      "For max_depth:15,n_estimators:150,learning_rate:0.1\n",
      "            train accuracy:4.628531753118902 validation accuracy:7.252799600494348\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012653 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1967\n",
      "[LightGBM] [Info] Number of data points in the train set: 718091, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 9.241747\n",
      "For max_depth:15,n_estimators:150,learning_rate:1\n",
      "            train accuracy:2.7942409926901495 validation accuracy:21.648376254068285\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012285 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1967\n",
      "[LightGBM] [Info] Number of data points in the train set: 718091, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 9.241747\n",
      "For max_depth:15,n_estimators:200,learning_rate:0.01\n",
      "            train accuracy:7.518660785656485 validation accuracy:7.2976523760920005\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011487 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1967\n",
      "[LightGBM] [Info] Number of data points in the train set: 718091, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 9.241747\n",
      "For max_depth:15,n_estimators:200,learning_rate:0.1\n",
      "            train accuracy:4.322314088621379 validation accuracy:7.416407685189925\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011058 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1967\n",
      "[LightGBM] [Info] Number of data points in the train set: 718091, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 9.241747\n",
      "For max_depth:15,n_estimators:200,learning_rate:1\n",
      "            train accuracy:2.560508769414161 validation accuracy:23.312890982404415\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011648 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1967\n",
      "[LightGBM] [Info] Number of data points in the train set: 718091, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 9.241747\n",
      "For max_depth:15,n_estimators:250,learning_rate:0.01\n",
      "            train accuracy:6.870727126444954 validation accuracy:6.97792439927659\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013344 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1967\n",
      "[LightGBM] [Info] Number of data points in the train set: 718091, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 9.241747\n",
      "For max_depth:15,n_estimators:250,learning_rate:0.1\n",
      "            train accuracy:4.089936709559804 validation accuracy:7.475696761757221\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011596 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1967\n",
      "[LightGBM] [Info] Number of data points in the train set: 718091, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 9.241747\n",
      "For max_depth:15,n_estimators:250,learning_rate:1\n",
      "            train accuracy:2.4213200642073405 validation accuracy:23.324863528086983\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012058 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1967\n",
      "[LightGBM] [Info] Number of data points in the train set: 718091, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 9.241747\n",
      "For max_depth:15,n_estimators:300,learning_rate:0.01\n",
      "            train accuracy:6.509703252332962 validation accuracy:6.866426822858114\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011918 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1967\n",
      "[LightGBM] [Info] Number of data points in the train set: 718091, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 9.241747\n",
      "For max_depth:15,n_estimators:300,learning_rate:0.1\n",
      "            train accuracy:3.8897567783867935 validation accuracy:7.486247019880277\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011503 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1967\n",
      "[LightGBM] [Info] Number of data points in the train set: 718091, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 9.241747\n",
      "For max_depth:15,n_estimators:300,learning_rate:1\n",
      "            train accuracy:2.2846687600571305 validation accuracy:23.328050466565443\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013073 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1967\n",
      "[LightGBM] [Info] Number of data points in the train set: 718091, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 9.241747\n",
      "For max_depth:25,n_estimators:5,learning_rate:0.01\n",
      "            train accuracy:36.1100851928192 validation accuracy:32.40330110376537\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011300 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1967\n",
      "[LightGBM] [Info] Number of data points in the train set: 718091, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 9.241747\n",
      "For max_depth:25,n_estimators:5,learning_rate:0.1\n",
      "            train accuracy:18.81876765243617 validation accuracy:16.629171431026514\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011744 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1967\n",
      "[LightGBM] [Info] Number of data points in the train set: 718091, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 9.241747\n",
      "For max_depth:25,n_estimators:5,learning_rate:1\n",
      "            train accuracy:6.4269340938036805 validation accuracy:8.691932290302596\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011371 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1967\n",
      "[LightGBM] [Info] Number of data points in the train set: 718091, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 9.241747\n",
      "For max_depth:25,n_estimators:10,learning_rate:0.01\n",
      "            train accuracy:33.43465682064453 validation accuracy:29.94663507675778\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011828 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1967\n",
      "[LightGBM] [Info] Number of data points in the train set: 718091, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 9.241747\n",
      "For max_depth:25,n_estimators:10,learning_rate:0.1\n",
      "            train accuracy:11.431832951324534 validation accuracy:10.136195008065027\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012384 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1967\n",
      "[LightGBM] [Info] Number of data points in the train set: 718091, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 9.241747\n",
      "For max_depth:25,n_estimators:10,learning_rate:1\n",
      "            train accuracy:5.686434121022398 validation accuracy:11.420519492662354\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013401 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1967\n",
      "[LightGBM] [Info] Number of data points in the train set: 718091, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 9.241747\n",
      "For max_depth:25,n_estimators:15,learning_rate:0.01\n",
      "            train accuracy:31.015225042626138 validation accuracy:27.72862261985223\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011967 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1967\n",
      "[LightGBM] [Info] Number of data points in the train set: 718091, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 9.241747\n",
      "For max_depth:25,n_estimators:15,learning_rate:0.1\n",
      "            train accuracy:8.587169147488623 validation accuracy:7.971724420335657\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011947 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1967\n",
      "[LightGBM] [Info] Number of data points in the train set: 718091, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 9.241747\n",
      "For max_depth:25,n_estimators:15,learning_rate:1\n",
      "            train accuracy:5.243414350580758 validation accuracy:11.490725976647802\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011732 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1967\n",
      "[LightGBM] [Info] Number of data points in the train set: 718091, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 9.241747\n",
      "For max_depth:25,n_estimators:25,learning_rate:0.01\n",
      "            train accuracy:26.837617638433976 validation accuracy:23.911075973446565\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012375 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1967\n",
      "[LightGBM] [Info] Number of data points in the train set: 718091, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 9.241747\n",
      "For max_depth:25,n_estimators:25,learning_rate:0.1\n",
      "            train accuracy:6.799305399403307 validation accuracy:7.022459400241077\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011530 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1967\n",
      "[LightGBM] [Info] Number of data points in the train set: 718091, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 9.241747\n",
      "For max_depth:25,n_estimators:25,learning_rate:1\n",
      "            train accuracy:4.616861942733784 validation accuracy:18.438365879195644\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011886 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1967\n",
      "[LightGBM] [Info] Number of data points in the train set: 718091, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 9.241747\n",
      "For max_depth:25,n_estimators:50,learning_rate:0.01\n",
      "            train accuracy:19.326136748243666 validation accuracy:17.07338870859655\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012526 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1967\n",
      "[LightGBM] [Info] Number of data points in the train set: 718091, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 9.241747\n",
      "For max_depth:25,n_estimators:50,learning_rate:0.1\n",
      "            train accuracy:5.782819106433898 validation accuracy:7.0909904486419535\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011795 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1967\n",
      "[LightGBM] [Info] Number of data points in the train set: 718091, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 9.241747\n",
      "For max_depth:25,n_estimators:50,learning_rate:1\n",
      "            train accuracy:3.8188628860213196 validation accuracy:19.91927594914108\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011881 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1967\n",
      "[LightGBM] [Info] Number of data points in the train set: 718091, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 9.241747\n",
      "For max_depth:25,n_estimators:60,learning_rate:0.01\n",
      "            train accuracy:17.211998126801497 validation accuracy:15.1537443267202\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011581 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1967\n",
      "[LightGBM] [Info] Number of data points in the train set: 718091, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 9.241747\n",
      "For max_depth:25,n_estimators:60,learning_rate:0.1\n",
      "            train accuracy:5.6021788352459145 validation accuracy:7.055728532364733\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011091 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1967\n",
      "[LightGBM] [Info] Number of data points in the train set: 718091, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 9.241747\n",
      "For max_depth:25,n_estimators:60,learning_rate:1\n",
      "            train accuracy:3.6812799396342 validation accuracy:19.29667880652944\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011494 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1967\n",
      "[LightGBM] [Info] Number of data points in the train set: 718091, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 9.241747\n",
      "For max_depth:25,n_estimators:75,learning_rate:0.01\n",
      "            train accuracy:14.719450385747555 validation accuracy:12.921410236766066\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011467 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1967\n",
      "[LightGBM] [Info] Number of data points in the train set: 718091, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 9.241747\n",
      "For max_depth:25,n_estimators:75,learning_rate:0.1\n",
      "            train accuracy:5.382615983897486 validation accuracy:7.090464943567633\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012140 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1967\n",
      "[LightGBM] [Info] Number of data points in the train set: 718091, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 9.241747\n",
      "For max_depth:25,n_estimators:75,learning_rate:1\n",
      "            train accuracy:3.4550835573569643 validation accuracy:19.497209654500413\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012429 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1967\n",
      "[LightGBM] [Info] Number of data points in the train set: 718091, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 9.241747\n",
      "For max_depth:25,n_estimators:100,learning_rate:0.01\n",
      "            train accuracy:11.83918521207329 validation accuracy:10.4350060556598\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011519 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1967\n",
      "[LightGBM] [Info] Number of data points in the train set: 718091, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 9.241747\n",
      "For max_depth:25,n_estimators:100,learning_rate:0.1\n",
      "            train accuracy:5.066651613068547 validation accuracy:7.189647731955335\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011412 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1967\n",
      "[LightGBM] [Info] Number of data points in the train set: 718091, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 9.241747\n",
      "For max_depth:25,n_estimators:100,learning_rate:1\n",
      "            train accuracy:3.1521101636491964 validation accuracy:21.349723582749135\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011639 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1967\n",
      "[LightGBM] [Info] Number of data points in the train set: 718091, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 9.241747\n",
      "For max_depth:25,n_estimators:125,learning_rate:0.01\n",
      "            train accuracy:10.02062533702923 validation accuracy:8.963989093831417\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011932 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1967\n",
      "[LightGBM] [Info] Number of data points in the train set: 718091, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 9.241747\n",
      "For max_depth:25,n_estimators:125,learning_rate:0.1\n",
      "            train accuracy:4.8276801950741595 validation accuracy:7.276774076187259\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012310 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1967\n",
      "[LightGBM] [Info] Number of data points in the train set: 718091, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 9.241747\n",
      "For max_depth:25,n_estimators:125,learning_rate:1\n",
      "            train accuracy:2.9564509926694047 validation accuracy:26.53458613172503\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011975 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1967\n",
      "[LightGBM] [Info] Number of data points in the train set: 718091, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 9.241747\n",
      "For max_depth:25,n_estimators:150,learning_rate:0.01\n",
      "            train accuracy:8.833611919020473 validation accuracy:8.095990315735431\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012186 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1967\n",
      "[LightGBM] [Info] Number of data points in the train set: 718091, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 9.241747\n",
      "For max_depth:25,n_estimators:150,learning_rate:0.1\n",
      "            train accuracy:4.620496655719607 validation accuracy:7.277714248237317\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012219 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1967\n",
      "[LightGBM] [Info] Number of data points in the train set: 718091, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 9.241747\n",
      "For max_depth:25,n_estimators:150,learning_rate:1\n",
      "            train accuracy:2.813551390682623 validation accuracy:27.340637024649745\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011218 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1967\n",
      "[LightGBM] [Info] Number of data points in the train set: 718091, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 9.241747\n",
      "For max_depth:25,n_estimators:200,learning_rate:0.01\n",
      "            train accuracy:7.518660785656485 validation accuracy:7.2976523760920005\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012308 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1967\n",
      "[LightGBM] [Info] Number of data points in the train set: 718091, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 9.241747\n",
      "For max_depth:25,n_estimators:200,learning_rate:0.1\n",
      "            train accuracy:4.322972233320188 validation accuracy:7.2710098608752\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011338 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1967\n",
      "[LightGBM] [Info] Number of data points in the train set: 718091, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 9.241747\n",
      "For max_depth:25,n_estimators:200,learning_rate:1\n",
      "            train accuracy:2.5962489033665186 validation accuracy:26.906819806341677\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012268 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1967\n",
      "[LightGBM] [Info] Number of data points in the train set: 718091, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 9.241747\n",
      "For max_depth:25,n_estimators:250,learning_rate:0.01\n",
      "            train accuracy:6.870727126444954 validation accuracy:6.97792439927659\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011700 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1967\n",
      "[LightGBM] [Info] Number of data points in the train set: 718091, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 9.241747\n",
      "For max_depth:25,n_estimators:250,learning_rate:0.1\n",
      "            train accuracy:4.0793982464963126 validation accuracy:7.394796058940536\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011915 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1967\n",
      "[LightGBM] [Info] Number of data points in the train set: 718091, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 9.241747\n",
      "For max_depth:25,n_estimators:250,learning_rate:1\n",
      "            train accuracy:2.418028134582925 validation accuracy:28.341293176045646\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012475 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1967\n",
      "[LightGBM] [Info] Number of data points in the train set: 718091, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 9.241747\n",
      "For max_depth:25,n_estimators:300,learning_rate:0.01\n",
      "            train accuracy:6.509703252332962 validation accuracy:6.866426822858114\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012173 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1967\n",
      "[LightGBM] [Info] Number of data points in the train set: 718091, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 9.241747\n",
      "For max_depth:25,n_estimators:300,learning_rate:0.1\n",
      "            train accuracy:3.868708138290228 validation accuracy:7.55010751717151\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011709 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1967\n",
      "[LightGBM] [Info] Number of data points in the train set: 718091, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 9.241747\n",
      "For max_depth:25,n_estimators:300,learning_rate:1\n",
      "            train accuracy:2.2981131109557853 validation accuracy:28.69092007097286\n"
     ]
    }
   ],
   "source": [
    "list1=[]\n",
    "depth = [5,7,9,12,15,25]\n",
    "features= [5,10,15,25,50,60,75,100,125,150,200,250,300]\n",
    "min_samples_s = [0.01,0.1,1]\n",
    "for j in depth:\n",
    "    for k in features:\n",
    "        for l in min_samples_s:\n",
    "            lgbm = lgb.LGBMRegressor(n_estimators=k, learning_rate= l , max_depth=j, random_state=32)\n",
    "            lgbm.fit(x_train, y_train)\n",
    "            y_train_pred = lgbm.predict(x_train)\n",
    "            train_accuracy = mean_squared_error(y_train, y_train_pred)\n",
    "            y_val_pred = lgbm.predict(x_val)\n",
    "            val_accuracy = mean_squared_error(y_val, y_val_pred)\n",
    "            list1.append((j,k,l,train_accuracy,val_accuracy))\n",
    "            print(f'''For max_depth:{j},n_estimators:{k},learning_rate:{l}\n",
    "            train accuracy:{train_accuracy} validation accuracy:{val_accuracy}''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[36.1510298109849, 19.0792471541391, 6.887312439602985, 33.51188038959396, 11.824411465158777, 6.212862142630698, 31.125080592705153, 9.044898879007789, 5.716901710809538, 27.009906077774325, 7.325159967307473, 5.265310504671655, 19.61166251243849, 6.317523631551223, 4.567967234947485, 17.524165436599368, 6.141711968971616, 4.319195063862755, 15.057922007357382, 5.929390376746009, 4.081689762432775, 12.215511771560614, 5.671810819055032, 3.77600532390352, 10.419588323986646, 5.4443583456575695, 3.5790227780389623, 9.2692290557904, 5.209943257434961, 3.4271424476133223, 8.012694824294373, 4.941176819493239, 3.190165898074657, 7.3825682500551135, 4.714982436490067, 3.0384623148721657, 7.011735205342217, 4.493292450080644, 2.913054120223044, 36.11438369444857, 18.818216854977972, 6.564050220848866, 33.442377547329855, 11.47662540590445, 5.848102461163173, 31.024839180190998, 8.655186553284112, 5.476943647766671, 26.852864522664373, 6.861302449827877, 4.852564554859439, 19.358760912481834, 5.857721651422725, 4.056100787706094, 17.243287805077596, 5.666294419926367, 3.8395502079847734, 14.74180622808673, 5.453439072447597, 3.608856851881323, 11.878385666506578, 5.164596214807386, 3.348378409140225, 10.066209772382148, 4.940920854556559, 3.133907663552601, 8.897928071413094, 4.740034585432332, 2.960860851351648, 7.60480789939765, 4.467659367141473, 2.7520075014970815, 6.956997794954376, 4.230295967856061, 2.6063359637482346, 6.59316561232012, 4.0448157437628165, 2.482821388975249, 36.1100851928192, 18.81876765243617, 6.400790367763937, 33.43465682064453, 11.444514122768236, 5.512368974780828, 31.015225042626138, 8.62180932341812, 5.1618620026032636, 26.837617638433976, 6.838875741409382, 4.619796497282966, 19.32999218144027, 5.79335459659343, 3.887645012561424, 17.21709381935963, 5.609826744321922, 3.7098414555813926, 14.72339282735465, 5.396368263081369, 3.4889962214283594, 11.847676610475792, 5.073505384032191, 3.1626731029965978, 10.02834097109384, 4.863773354452936, 2.9755499076926566, 8.836222636225802, 4.689335703255237, 2.8429621653776556, 7.5355464119816435, 4.387398348234794, 2.646300192391826, 6.8951307027972195, 4.153889424757686, 2.4799650270169398, 6.528886136628606, 3.9679300530114223, 2.371983613422993, 36.1100851928192, 18.81876765243617, 6.4269340938036805, 33.43465682064453, 11.431832951324534, 5.686434121022398, 31.015225042626138, 8.587169147488623, 5.2449215194323235, 26.837617638433976, 6.799305399403307, 4.702729262787879, 19.326136748243666, 5.803280860300373, 3.962169716825341, 17.211998126801497, 5.598659991829689, 3.749828683499798, 14.719450385747555, 5.360531510180678, 3.4602853643631395, 11.83918521207329, 5.0472977867735525, 3.1684238176373776, 10.02062533702923, 4.833281443990455, 2.9340518228690673, 8.833657100565798, 4.628337706796416, 2.782249736511344, 7.520412955472662, 4.338986703813131, 2.5661155390463564, 6.872394115146643, 4.109001059462574, 2.41135468081705, 6.512326026098987, 3.894099112813568, 2.2938642708885126, 36.1100851928192, 18.81876765243617, 6.4269340938036805, 33.43465682064453, 11.431832951324534, 5.686434121022398, 31.015225042626138, 8.587169147488623, 5.243414350580758, 26.837617638433976, 6.799305399403307, 4.616861942733784, 19.326136748243666, 5.782819106433898, 3.8188628860213196, 17.211998126801497, 5.6021788352459145, 3.6835957113514817, 14.719450385747555, 5.382615983897486, 3.4683346485167745, 11.83918521207329, 5.066651613068547, 3.185706845909787, 10.02062533702923, 4.8276801950741595, 2.956951266570726, 8.833611919020473, 4.628531753118902, 2.7942409926901495, 7.518660785656485, 4.322314088621379, 2.560508769414161, 6.870727126444954, 4.089936709559804, 2.4213200642073405, 6.509703252332962, 3.8897567783867935, 2.2846687600571305, 36.1100851928192, 18.81876765243617, 6.4269340938036805, 33.43465682064453, 11.431832951324534, 5.686434121022398, 31.015225042626138, 8.587169147488623, 5.243414350580758, 26.837617638433976, 6.799305399403307, 4.616861942733784, 19.326136748243666, 5.782819106433898, 3.8188628860213196, 17.211998126801497, 5.6021788352459145, 3.6812799396342, 14.719450385747555, 5.382615983897486, 3.4550835573569643, 11.83918521207329, 5.066651613068547, 3.1521101636491964, 10.02062533702923, 4.8276801950741595, 2.9564509926694047, 8.833611919020473, 4.620496655719607, 2.813551390682623, 7.518660785656485, 4.322972233320188, 2.5962489033665186, 6.870727126444954, 4.0793982464963126, 2.418028134582925, 6.509703252332962, 3.868708138290228, 2.2981131109557853]\n",
      "[32.4098536029734, 16.626750799625615, 8.934858202349103, 29.95875345463871, 10.27276795757112, 10.03957109219477, 27.761787179229668, 8.18401904295112, 10.529033347670408, 23.965998581335302, 7.104238004114926, 13.642247373753952, 17.211401353096708, 7.2042821652952025, 15.72168016429994, 15.348721584176497, 7.159325525089289, 16.531134821300988, 13.183496946270962, 7.285295169239076, 17.461827892393565, 10.689304898620676, 7.228834208631496, 18.277454558105, 9.201288564208, 7.311239586614756, 17.85490655815877, 8.333168061305987, 7.3914374200533866, 18.60446854151484, 7.478659381486712, 7.4985102798061, 19.47967722659873, 7.138427010589993, 7.78354177377903, 27.00969776299401, 7.002819324059821, 8.260804817430381, 27.68086952531165, 32.366047599975246, 16.424989002306816, 8.669390941110311, 29.895077629001708, 10.065521306562502, 9.207716368354465, 27.67102873196682, 7.951003873933048, 10.083116527150558, 23.829504465906123, 7.1709698322716084, 12.360093764598227, 17.01786485161311, 7.289547771435393, 14.653880308307091, 15.118102587276864, 7.219483976661776, 17.318414871581524, 12.910969883003595, 7.217363082678267, 17.072166476052068, 10.43391560344328, 7.340907751937307, 17.619478557080985, 8.968872053811841, 7.4285334169634, 18.278132840700582, 8.148099482467224, 7.331968348511433, 19.79978409296986, 7.376319260281392, 7.773918091150234, 19.491929183275577, 7.10395954173065, 7.867055251581899, 19.31954772966302, 6.982576981787806, 7.882300844796235, 20.819897341699473, 32.40330110376537, 16.629171431026514, 8.735843826715152, 29.94663507675778, 10.100552170984837, 9.490424885535454, 27.72862261985223, 7.95450352799318, 9.954361741132832, 23.911075973446565, 7.058825214075621, 13.302453746953859, 17.060863209614602, 6.862403055174539, 15.802021284714682, 15.140543991838733, 6.944909557591066, 16.226143134057814, 12.90260141683059, 6.985789810082333, 16.668571018718648, 10.421328183537943, 7.12044120059369, 17.779421375720734, 8.961550140339698, 7.256082523888287, 18.779872492145454, 8.0873744250447, 7.313379935743649, 18.627453996369137, 7.2945568849629305, 7.547840403493835, 20.197993793902395, 6.993195644952389, 7.624255441274589, 20.564284988790796, 6.888768302366576, 7.7002311119665725, 20.00705280335408, 32.40330110376537, 16.629171431026514, 8.691932290302596, 29.94663507675778, 10.136195008065027, 11.420519492662354, 27.72862261985223, 7.971724420335657, 11.768756667242442, 23.911075973446565, 7.022459400241077, 12.863906075116178, 17.07338870859655, 7.198460319083208, 12.981523648956136, 15.1537443267202, 7.163036763685713, 12.953536307904386, 12.921410236766066, 7.168584701021729, 13.092111825545139, 10.4350060556598, 7.198833293875802, 13.95658216314169, 8.963989093831417, 7.238703822458244, 14.216621551469428, 8.096464192184317, 7.252026372812931, 14.565149794689177, 7.300575971857771, 7.420222969378341, 14.238309519912088, 6.991727217259841, 7.6868268538967675, 14.518512355204527, 6.883402563784268, 7.664626383881851, 14.708310173854914, 32.40330110376537, 16.629171431026514, 8.691932290302596, 29.94663507675778, 10.136195008065027, 11.420519492662354, 27.72862261985223, 7.971724420335657, 11.490725976647802, 23.911075973446565, 7.022459400241077, 18.438365879195644, 17.07338870859655, 7.0909904486419535, 19.91927594914108, 15.1537443267202, 7.055728532364733, 21.660807177119295, 12.921410236766066, 7.090464943567633, 19.697967307580065, 10.4350060556598, 7.189647731955335, 20.840337450995854, 8.963989093831417, 7.276774076187259, 20.211696752472065, 8.095990315735431, 7.252799600494348, 21.648376254068285, 7.2976523760920005, 7.416407685189925, 23.312890982404415, 6.97792439927659, 7.475696761757221, 23.324863528086983, 6.866426822858114, 7.486247019880277, 23.328050466565443, 32.40330110376537, 16.629171431026514, 8.691932290302596, 29.94663507675778, 10.136195008065027, 11.420519492662354, 27.72862261985223, 7.971724420335657, 11.490725976647802, 23.911075973446565, 7.022459400241077, 18.438365879195644, 17.07338870859655, 7.0909904486419535, 19.91927594914108, 15.1537443267202, 7.055728532364733, 19.29667880652944, 12.921410236766066, 7.090464943567633, 19.497209654500413, 10.4350060556598, 7.189647731955335, 21.349723582749135, 8.963989093831417, 7.276774076187259, 26.53458613172503, 8.095990315735431, 7.277714248237317, 27.340637024649745, 7.2976523760920005, 7.2710098608752, 26.906819806341677, 6.97792439927659, 7.394796058940536, 28.341293176045646, 6.866426822858114, 7.55010751717151, 28.69092007097286]\n"
     ]
    }
   ],
   "source": [
    "all_train_acc=[list1[i][3] for i in range(len(list1))]\n",
    "all_val_acc=[list1[i][4] for i in range(len(list1))]\n",
    "print(all_train_acc)\n",
    "print(all_val_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[6.862403055174539,\n",
       " 6.866426822858114,\n",
       " 6.866426822858114,\n",
       " 6.883402563784268,\n",
       " 6.888768302366576,\n",
       " 6.944909557591066,\n",
       " 6.97792439927659,\n",
       " 6.97792439927659,\n",
       " 6.982576981787806,\n",
       " 6.985789810082333]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import heapq\n",
    "max_5_val_acc = heapq.nsmallest(10, all_val_acc)\n",
    "max_5_val_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9, 50, 0.1, 5.79335459659343, 6.862403055174539)\n",
      "(15, 300, 0.01, 6.509703252332962, 6.866426822858114)\n",
      "(15, 300, 0.01, 6.509703252332962, 6.866426822858114)\n",
      "(12, 300, 0.01, 6.512326026098987, 6.883402563784268)\n",
      "(9, 300, 0.01, 6.528886136628606, 6.888768302366576)\n",
      "(9, 60, 0.1, 5.609826744321922, 6.944909557591066)\n",
      "(15, 250, 0.01, 6.870727126444954, 6.97792439927659)\n",
      "(15, 250, 0.01, 6.870727126444954, 6.97792439927659)\n",
      "(7, 300, 0.01, 6.59316561232012, 6.982576981787806)\n",
      "(9, 75, 0.1, 5.396368263081369, 6.985789810082333)\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(max_5_val_acc)):\n",
    "    print(list1[all_val_acc.index(max_5_val_acc[i])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012883 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1968\n",
      "[LightGBM] [Info] Number of data points in the train set: 718091, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 9.241747\n",
      "Mean Squared Error (MSE) on training data: 5.841260083619429\n",
      "Mean Squared Error (MSE) on training data: 6.796103193512809\n"
     ]
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "lgbm = lgb.LGBMRegressor(n_estimators=50, learning_rate=0.1, max_depth=9, random_state=0)\n",
    "lgbm.fit(x_train, y_train)\n",
    "y_train_pred = lgbm.predict(x_train)\n",
    "mse = mean_squared_error(y_train, y_train_pred)\n",
    "print(f\"Mean Squared Error (MSE) on training data: {mse}\")\n",
    "y_val_pred = lgbm.predict(x_val)\n",
    "mse1 = mean_squared_error(y_val, y_val_pred)\n",
    "print(f\"Mean Squared Error (MSE) on training data: {mse1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred = lgbm.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df = pd.DataFrame({\n",
    "    'position': y_test_pred,\n",
    "    'result_driver_standing': test_data[\"result_driver_standing\"]\n",
    "})\n",
    "result_df.to_csv('submission_file_lgbm.csv', index=False, header=['position', 'result_driver_standing'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Xg Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "estim = [5,10,15,25,50,60,75,100,125,150,200,250,300]\n",
    "train_result=[]\n",
    "val_result=[]\n",
    "for i in estim:\n",
    "    lxgb = XGBRegressor(n_estimators=i, learning_rate=0.1, max_depth=3, random_state=0)\n",
    "    xgb.fit(x_train, y_train)\n",
    "    y_train_pred = xgb.predict(x_train)\n",
    "    train_result.append(mean_squared_error(y_train, y_train_pred))\n",
    "    y_val_pred = xgb.predict(x_val)\n",
    "    val_result.append(mean_squared_error(y_val, y_val_pred))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "plt.plot(estim,train_result, marker='o', linestyle='-')\n",
    "plt.plot(estim,val_result, marker='o', linestyle='-')\n",
    "plt.xlabel(\"estimators\")\n",
    "plt.ylabel('MSE')\n",
    "plt.title('n_estimators')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "5\n",
      "9\n",
      "10\n",
      "15\n",
      "20\n",
      "25\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "estim = [2,5,9,10,15,20,25]\n",
    "train_result=[]\n",
    "val_result=[]\n",
    "for i in estim:\n",
    "    print(i)\n",
    "    xgb = XGBRegressor(n_estimators=50, learning_rate=0.1, max_depth=i, random_state=0)\n",
    "    xgb.fit(x_train, y_train)\n",
    "    y_train_pred = xgb.predict(x_train)\n",
    "    train_result.append(mean_squared_error(y_train, y_train_pred))\n",
    "    y_val_pred = xgb.predict(x_val)\n",
    "    val_result.append(mean_squared_error(y_val, y_val_pred))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "plt.plot(estim,train_result, marker='o', linestyle='-')\n",
    "plt.plot(estim,val_result, marker='o', linestyle='-')\n",
    "plt.xlabel(\"max-depth\")\n",
    "plt.ylabel('MSE')\n",
    "plt.title('Max Depth')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.01\n",
      "0.1\n",
      "1\n",
      "2\n",
      "5\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkAAAAHHCAYAAABXx+fLAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuNSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/xnp5ZAAAACXBIWXMAAA9hAAAPYQGoP6dpAABWE0lEQVR4nO3deVxU9eL/8dcwCIgKLiCI4p5rigs6UlmWFJrXsrqlXs19abEyWm7eSm251/ZssdxFLbduZt28aUapN0MQEVNTU8OdRUlWBWTm/P7o2/yaXFHgAPN+Ph7zyDnzOYf3Oanz9pzPnLEYhmEgIiIi4kY8zA4gIiIiUt5UgERERMTtqACJiIiI21EBEhEREbejAiQiIiJuRwVIRERE3I4KkIiIiLgdFSARERFxOypAIiIi4nZUgESkymjatCkjRowwO4aIVAIqQCLiIiYmBovFQmJiotlRKhWLxeLy8PPz46abbmL16tVXvM0lS5Ywffr00gspIk6eZgcQESkte/fuxcPDvH/X3XrrrQwbNgzDMDh06BAffvgh/fv356uvviIqKqrE21uyZAk7d+5k4sSJpR9WxM2pAIlIhVRcXIzD4cDLy+uy1/H29i7DRJfWqlUrhg4d6nx+zz330K5dO955550rKkAiUnZ0CUxErsixY8cYNWoUQUFBeHt70759e+bPn+8ypqioiMmTJ9O1a1f8/f2pUaMGPXv25LvvvnMZd/DgQSwWC2+88QbTp0+nRYsWeHt789NPPzF16lQsFgv79+9nxIgR1K5dG39/f0aOHMnp06ddtvPnOUC/X87btGkT0dHRBAYGUqNGDe666y5OnDjhsq7D4WDq1KmEhITg6+vLzTffzE8//XRV84ratm1LQEAABw4ccFn++eef069fP0JCQvD29qZFixa89NJL2O1255hevXqxevVqDh065Lys1rRpU+frhYWFTJkyhZYtW+Lt7U1oaChPP/00hYWFV5RVxN3oDJCIlFh6ejo9evTAYrEwYcIEAgMD+eqrrxg9ejQ5OTnOSzY5OTnMnTuXwYMHM3bsWHJzc5k3bx5RUVEkJCTQqVMnl+0uWLCAgoICxo0bh7e3N3Xr1nW+dt9999GsWTOmTZtGUlISc+fOpX79+rz66quXzPvII49Qp04dpkyZwsGDB5k+fToTJkxg+fLlzjGTJk3itddeo3///kRFRbF9+3aioqIoKCi44uOUnZ3NqVOnaNGihcvymJgYatasSXR0NDVr1uTbb79l8uTJ5OTk8PrrrwPw7LPPkp2dzdGjR3n77bcBqFmzJvBbWbvjjjv4/vvvGTduHG3btmXHjh28/fbb/Pzzz6xateqKM4u4DUNE5A8WLFhgAMaWLVsuOGb06NFGgwYNjJMnT7osHzRokOHv72+cPn3aMAzDKC4uNgoLC13GnDp1yggKCjJGjRrlXJaSkmIAhp+fn5GRkeEyfsqUKQbgMt4wDOOuu+4y6tWr57KsSZMmxvDhw8/Zl8jISMPhcDiXP/7444bVajWysrIMwzCMtLQ0w9PT0xgwYIDL9qZOnWoALtu8EMAYPXq0ceLECSMjI8NITEw0+vTpYwDG66+/7jL29+PzR+PHjzd8fX2NgoIC57J+/foZTZo0OWfs4sWLDQ8PD+N///ufy/KZM2cagLFp06ZL5hVxd7oEJiIlYhgGn376Kf3798cwDE6ePOl8REVFkZ2dTVJSEgBWq9U5h8fhcPDrr79SXFxMeHi4c8wf3XPPPQQGBp735z7wwAMuz3v27ElmZiY5OTmXzDxu3DgsFovLuna7nUOHDgEQGxtLcXExDz30kMt6jzzyyCW3/Ufz5s0jMDCQ+vXrEx4eTmxsLE8//TTR0dEu46pXr+78dW5uLidPnqRnz56cPn2aPXv2XPLnfPLJJ7Rt25Y2bdq4HP9bbrkF4JxLjCJyLhWgS9i4cSP9+/cnJCQEi8VS4lPLv89t+PNj8+bNzjErV64kPDyc2rVrU6NGDTp16sTixYtLeU9ESseJEyfIyspi9uzZBAYGujxGjhwJQEZGhnP8woUL6dixIz4+PtSrV4/AwEBWr15Ndnb2Odtu1qzZBX9u48aNXZ7XqVMHgFOnTl0y86XW/b0ItWzZ0mVc3bp1nWMvx5133sm6detYvXq1c+7S6dOnz/lk2q5du7jrrrvw9/fHz8+PwMBA5+Tp8x2XP9u3bx+7du065/i3atUKcD3+InJ+mgN0Cfn5+YSFhTFq1CjuvvvuK97ON998Q/v27Z3P69Wr5/x13bp1efbZZ2nTpg1eXl58+eWXjBw5kvr16+uTI1LhOBwOAIYOHcrw4cPPO6Zjx44AfPTRR4wYMYIBAwbw1FNPUb9+faxWK9OmTTtnYjC4nhn5M6vVet7lhmFcMvPVrFsSjRo1IjIyEoDbb7+dgIAAJkyYwM033+z8+yMrK4ubbroJPz8/XnzxRVq0aIGPjw9JSUn8/e9/dx7fi3E4HHTo0IG33nrrvK+HhoaW3k6JVFEqQJfQt29f+vbte8HXCwsLefbZZ1m6dClZWVlce+21vPrqq/Tq1ctlXL169QgODj7vNv489rHHHmPhwoV8//33KkBS4QQGBlKrVi3sdrvzzf5C/v3vf9O8eXNWrlzpcglqypQpZR2zRJo0aQLA/v37Xc5CZWZmXtYZpgsZP348b7/9Ns899xx33XUXFouF9evXk5mZycqVK7nxxhudY1NSUs5Z/4/H7I9atGjB9u3b6d279wXHiMjF6RLYVZowYQJxcXEsW7aMH3/8kXvvvZc+ffqwb98+l3F33HEH9evX54YbbuCLL7644PYMwyA2Npa9e/e6/OUoUlFYrVbuuecePv30U3bu3HnO63/8ePnvZ17+eKYlPj6euLi4sg9aAr1798bT05MPP/zQZfn7779/Vdv19PTkiSeeYPfu3Xz++efA+Y9JUVERH3zwwTnr16hR47yXxO677z6OHTvGnDlzznntzJkz5OfnX1VuEXegM0BX4fDhwyxYsIDDhw8TEhICwJNPPsmaNWtYsGAB//rXv6hZsyZvvvkm119/PR4eHnz66acMGDCAVatWcccddzi3lZ2dTcOGDSksLMRqtfLBBx9w6623mrVrIsyfP581a9acs/yxxx7jlVde4bvvvsNmszF27FjatWvHr7/+SlJSEt988w2//vorAH/5y19YuXIld911F/369SMlJYWZM2fSrl078vLyynuXLigoKIjHHnuMN998kzvuuIM+ffqwfft2vvrqKwICAq7qLMuIESOYPHkyr776KgMGDOC6666jTp06DB8+nEcffRSLxcLixYvPezmua9euLF++nOjoaLp160bNmjXp378/999/PytWrOCBBx7gu+++4/rrr8dut7Nnzx5WrFjB2rVrCQ8Pv5pDIlLlqQBdhR07dmC3250TD39XWFjonOMTEBDg8gmQbt26cfz4cV5//XWXAlSrVi2Sk5PJy8sjNjaW6Ohomjdvfs7lMZHy8uezIb8bMWIEjRo1IiEhgRdffJGVK1fywQcfUK9ePdq3b+9yX54RI0aQlpbGrFmzWLt2Le3ateOjjz7ik08+Yf369eW0J5fn1VdfxdfXlzlz5vDNN98QERHB119/zQ033ICPj88Vb7d69epMmDCBqVOnsn79enr16sWXX37JE088wXPPPUedOnUYOnQovXv3PueS90MPPURycjILFizg7bffpkmTJvTv3x8PDw9WrVrF22+/zaJFi/jss8/w9fWlefPmPPbYY+f8nSQi57IYpT0LsAqzWCx89tlnDBgwAIDly5czZMgQdu3adc4ky5o1a15wzs+MGTN4+eWXSU1NveDPGjNmDEeOHGHt2rWlll9ESiYrK4s6derw8ssv8+yzz5odR0RKkc4AXYXOnTtjt9vJyMigZ8+el71ecnIyDRo0uOgYh8OhW9qLlKMzZ86c8ym037+JXWdiRaoeFaBLyMvLY//+/c7nKSkpJCcnU7duXVq1asWQIUMYNmwYb775Jp07d+bEiRPExsbSsWNH+vXrx8KFC/Hy8qJz587Ab/f8mT9/PnPnznVuc9q0aYSHh9OiRQsKCwv573//y+LFiy94CUJESt/y5cuJiYnh9ttvp2bNmnz//fcsXbqU2267jeuvv97seCJSylSALiExMZGbb77Z+fz3+TzDhw8nJiaGBQsW8PLLL/PEE09w7NgxAgIC6NGjB3/5y1+c67z00kscOnQIT09P2rRpw/Lly/nrX//qfD0/P5+HHnqIo0ePUr16ddq0acNHH33EwIEDy29HRdxcx44d8fT05LXXXiMnJ8c5Mfrll182O5qIlAHNARIRERG3o/sAiYiIiNtRARIRERG3ozlA5+FwODh+/Di1atXSbeZFREQqCcMwyM3NJSQk5JwvIf4zFaDzOH78uL5MUEREpJI6cuQIjRo1uugYFaDzqFWrFvDbAfTz8zM5jYiIiFyOnJwcQkNDne/jF6MCdB6/X/by8/NTARIREalkLmf6iiZBi4iIiNtRARIRERG3owIkIiIibkcFSERERNyOCpCIiIi4HVML0MaNG+nfvz8hISFYLBZWrVp10fEjRozAYrGc82jfvr1zzNSpU895vU2bNmW8JyIiIlKZmFqA8vPzCQsLY8aMGZc1/p133iE1NdX5OHLkCHXr1uXee+91Gde+fXuXcd9//31ZxBcREZFKytT7APXt25e+ffte9nh/f3/8/f2dz1etWsWpU6cYOXKkyzhPT0+Cg4NLLaeIiIhULZV6DtC8efOIjIykSZMmLsv37dtHSEgIzZs3Z8iQIRw+fPii2yksLCQnJ8flISIiIlVXpS1Ax48f56uvvmLMmDEuy202GzExMaxZs4YPP/yQlJQUevbsSW5u7gW3NW3aNOfZJX9/f30PmIiISBmwFxeza9NqEr+cza5Nq7EXF5uWxWIYhmHaT/8Di8XCZ599xoABAy5r/LRp03jzzTc5fvw4Xl5eFxyXlZVFkyZNeOuttxg9evR5xxQWFlJYWOh8/vt3iWRnZ+urMERERErBtrULCYl7gSAyncvSqcfxiCl0jhpeKj8jJycHf3//y3r/rpTfBWYYBvPnz+f++++/aPkBqF27Nq1atWL//v0XHOPt7Y23t3dpxxQRERF+Kz9hPzz625M/fE1XoJFJ4A+Psg1KrQRdrkp5CWzDhg3s37//gmd0/igvL48DBw7QoEGDckgmIiIif2QvLiYk7gUAPP70HaW/P28Q90K5Xw4ztQDl5eWRnJxMcnIyACkpKSQnJzsnLU+aNIlhw4ads968efOw2Wxce+2157z25JNPsmHDBg4ePMgPP/zAXXfdhdVqZfDgwWW6LyIiInKuPfFrCSLznPLzOw8LBJPJnvi15ZrL1EtgiYmJ3Hzzzc7n0dHRAAwfPpyYmBhSU1PP+QRXdnY2n376Ke+88855t3n06FEGDx5MZmYmgYGB3HDDDWzevJnAwMCy2xERERE5rzOnjpXquNJiagHq1asXF5uDHRMTc84yf39/Tp8+fcF1li1bVhrRREREpBRUr9OwVMeVlko5B0hEREQqhza2KE5Qhwud73AYkEY92tiiyjWXCpCIiIiUGcNwkOvhh8XCOSXI8X/PUyOmYPUs34tSKkAiIiJSZhLnPkJzxyEKDE8yLf4ur2VY6rH9unfL/SPwUEnvAyQiIiIV35bPP6BH+m9zc3df9xYdew9hV/xazpw6RvU6DWljiyK4nM/8/E4FSERERErdvm0b6Zg0GSwQ12gUEf93lqf99f1MTvYbXQITERGRUnUy7Qh+n4/A23KW5Oo9sI18w+xI51ABEhERkVJTVFjAiXkDCSKTwx4NaT5+CR5Wq9mxzqECJCIiIqVm2+zxtD27i1yjOgxagl/temZHOi8VIBERESkV8Z+8iS1zFQ7Dwi83Tadxq05mR7ogFSARERG5anviv6bzzn8CkNDsIcJuGWRyootTARIREZGrknEshYCvxuJlsZNU80Zsw142O9IlqQCJiIjIFSs4k0/WgvsIIIsUj6a0Hr8Yi0fFrxcVP6GIiIhUSIbDwY6Zo2hV/DNZ1MRr6DJq1KptdqzLogIkIiIiVyR++TS6Za/Bblg4cssHNGze1uxIl00FSEREREps56b/EL7ntxscbmkVTYcb7zQ5UcmoAImIiEiJHD+4l4brHsTT4iDR71Zsg58zO1KJqQCJiIjIZTuTn8uZxQOpQy77rC259oGYSjHp+c8qX2IRERExheFw8NPM+2lhTyETf2qNWI6Pb02zY10RFSARERG5LJs/mkLX3O84a1hJ7zOb4NCWZke6YipAIiIickk/fvdvbAfeAyCp/TO069HH5ERXRwVIRERELurI/h003fAIHhaDhLr96f7XJ82OdNVUgEREROSC8nJO4VgyGD9Os8ezLWHjZlfKSc9/Vvn3QERERMqEw25n38y/0cRxhAzqEjBqOd4+vmbHKhUqQCIiInJe8QufofPpHygyPDn1l3kEhDQxO1KpUQESERGRc2z7+iMiDs8GILnTFFqH32JyotKlAiQiIiIuDu3eSqtNTwAQH/hXut/1qMmJSp8KkIiIiDhl/3oC64oh1LAUsMsrjC5jPzA7UplQARIREREA7MXFHJo9mEZGKqkE0mDMUqp5eZsdq0yoAImIiAgACfMep2PBFs4YXpy+exF16zc0O1KZUQESERERElfPISJ1EQC7uv+LFh2vMzlR2VIBEhERcXMHfvyB9gn/ACCuwVDC+401OVHZUwESERFxY79mHMN35TCqW4r40Sec7qPfMTtSuVABEhERcVNniwpJnTuYBpzgqKUBTcYtw+rpaXascqECJCIi4qa2znmY9kXbyTd8KL7vI/zrBpodqdyoAImIiLihhM/eo8eJTwD4+fo3ado23ORE5UsFSERExM38nLSesOQXAIgLHUvn24aanKj8qQCJiIi4kZNph6n9xUi8LWfZ5nsdthGvmh3JFKYWoI0bN9K/f39CQkKwWCysWrXqouPXr1+PxWI555GWluYybsaMGTRt2hQfHx9sNhsJCQlluBciIiKVQ2HBaU7OG0h9fuWQRygtx3+Mh9VqdixTmFqA8vPzCQsLY8aMGSVab+/evaSmpjof9evXd762fPlyoqOjmTJlCklJSYSFhREVFUVGRkZpxxcREalUkmePp83Zn8jBF4/BH1PLv67ZkUxj6mfd+vbtS9++fUu8Xv369aldu/Z5X3vrrbcYO3YsI0eOBGDmzJmsXr2a+fPn88wzz1xNXBERkUorfsXr2H79Aodh4WCv9+h4TZjZkUxVKecAderUiQYNGnDrrbeyadMm5/KioiK2bt1KZGSkc5mHhweRkZHExcWZEVVERMR0P21eQ5dd0wCIb/EIHW/+q8mJzFepClCDBg2YOXMmn376KZ9++imhoaH06tWLpKQkAE6ePIndbicoKMhlvaCgoHPmCf1RYWEhOTk5Lg8REZGqIO3IfoLWjKOaxc7WWjfTY+gLZkeqECrV7R5bt25N69atnc+vu+46Dhw4wNtvv83ixYuveLvTpk3jhRf0G0JERKqWgtN55MYM5BqyOWBtRtvxC7F4VKpzH2Wm0h+F7t27s3//fgACAgKwWq2kp6e7jElPTyc4OPiC25g0aRLZ2dnOx5EjR8o0s4iISFkzHA52zhzBNfb9nKIW1e9fjm9Nf7NjVRiVvgAlJyfToEEDALy8vOjatSuxsbHO1x0OB7GxsURERFxwG97e3vj5+bk8REREKrP4pS8TnrOOYsODY5EfENK09aVXciOmXgLLy8tznr0BSElJITk5mbp169K4cWMmTZrEsWPHWLRoEQDTp0+nWbNmtG/fnoKCAubOncu3337L119/7dxGdHQ0w4cPJzw8nO7duzN9+nTy8/OdnwoTERGp6nZs/JxuP78FFkhs/QQ9brjD7EgVjqkFKDExkZtvvtn5PDo6GoDhw4cTExNDamoqhw8fdr5eVFTEE088wbFjx/D19aVjx4588803LtsYOHAgJ06cYPLkyaSlpdGpUyfWrFlzzsRoERGRqujYL7sJ/fYhrBaDLf59sA36h9mRKiSLYRiG2SEqmpycHPz9/cnOztblMBERqTRO52WT/taNNHMc5GfPVjR+Yj0+1WuYHavclOT9u9LPARIREZHfJj3vmXk/zRwHOUlt/Ecsc6vyU1IqQCIiIlXA5sXP0SVvA0WGlZN95xDUqIXZkSo0FSAREZFKbvu3y7D98gEA2659lja220xOVPGpAImIiFRih39OpvmGiXhYDOLr3Ynt3ifMjlQpqACJiIhUUrnZv2IsG0Ityxl2V2tP53GzzY5UaagAiYiIVEIOu50Ds/5GE8dRMqhL4OjleHn7mB2r0lABEhERqYQSFjxFp9NxFBrVyL5zIQHBoWZHqlRUgERERCqZbWsX0uPoPAB+7PwC13S+0eRElY8KkIiISCWS8tMWWv/wFACb6w+k24CHTU5UOakAiYiIVBLZmel4fTIEX0shO707ET72fbMjVVoqQCIiIpVA8dkiDs8eREMjneOW+jQcswzPal5mx6q0VIBEREQqgcR5E+lQmMRpw5szdy+mTmADsyNVaipAIiIiFVzif2bRI+1jAHbbptGiQw+TE1V+KkAiIiIV2P7t33Nt4rMAxIUMp+vto01OVDWoAImIiFRQmelHqfnZcHwsZ9nu043uo94yO1KVoQIkIiJSAZ0tKiR93iCCOckRSwhNxy/D6ulpdqwqQwVIRESkAkqa/SDtinaQZ1THMfBj/OsEmB2pSlEBEhERqWC2rHwH28lPAdh/w1s0adPF5ERVjwqQiIhIBbInMZaw7S8CENfkATrd+jeTE1VNKkAiIiIVxInjB6n35Wi8LMVsq3EDtmH/MjtSlaUCJCIiUgEUFpzm1/kDCeQUBz0ac834j/CwWs2OVWWpAImIiJjMcDjYPnM0rYv3kEMNPP+2lJp+dcyOVaWpAImIiJgs4ZPX6J71X+yGhYO93qNRy2vNjlTlqQCJiIiYaNcP/6XLT68BsKXlo3TsdY/JidyDCpCIiIhJ0g7vo8HX46lmsZNYqze2IVPNjuQ2VIBERERMcCY/l7yFA6lLDvutLWj/wEIsHnpbLi860iIiIuXMcDjYNWsELe0HOIUfNYYtpXqNWmbHcisqQCIiIuUsfsmLhOd8Q7HhwfFbZ9KgSWuzI7kdFSAREZFytGPDSrrtmw7A1rZP0/76fuYGclMqQCIiIuXk2C+7aPzdBKwWg4Tat9P9vr+bHcltqQCJiIiUg/zcLIo+Gow/+ez1bE3YA/M06dlEOvIiIiJlzGG3s3fmUJo5DnGS2tQdtQJvH1+zY7k1FSAREZEyFr/oH3TJ/x9Fhicn+80jMKSp2ZHcngqQiIhIGUr+ZikRh2b+9uuOz9GmW6TJiQRUgERERMrMob3JtPzf4wDEB9xN93seNzmR/E4FSEREpAxknzqJx7LB1LSc4SevDnQZN9PsSPIHKkAiIiKlzF5czMHZgwk1jpNGAEGjl1HNy9vsWPIHKkAiIiKlLGHBE4SdSaDAqEbugBjqBTUyO5L8iakFaOPGjfTv35+QkBAsFgurVq266PiVK1dy6623EhgYiJ+fHxEREaxdu9ZlzNSpU7FYLC6PNm3alOFeiIiI/H9b/7uAiGMxAOzs+jLXdOppbiA5L1MLUH5+PmFhYcyYMeOyxm/cuJFbb72V//73v2zdupWbb76Z/v37s23bNpdx7du3JzU11fn4/vvvyyK+iIiIi192xtM2/re7O28OGkz4HQ+YnEguxNPMH963b1/69u172eOnT5/u8vxf//oXn3/+Of/5z3/o3Lmzc7mnpyfBwcGlFVNEROSSsk6m4fPp/fhaCtnh3YXwMe+aHUkuolLPAXI4HOTm5lK3bl2X5fv27SMkJITmzZszZMgQDh8+fNHtFBYWkpOT4/IQERG5XMVnizg6ZyAhRjrHLEE0HrcMz2peZseSi6jUBeiNN94gLy+P++67z7nMZrMRExPDmjVr+PDDD0lJSaFnz57k5uZecDvTpk3D39/f+QgNDS2P+CIiUkUkzn2EawuTOW14U/TXxfjXCzI7klyCxTAMw+wQABaLhc8++4wBAwZc1vglS5YwduxYPv/8cyIjL3xXzaysLJo0acJbb73F6NGjzzumsLCQwsJC5/OcnBxCQ0PJzs7Gz8+vRPshIiLuZcvnH9Bt2yQAknq8Q5c+I8wN5MZycnLw9/e/rPdvU+cAXally5YxZswYPvnkk4uWH4DatWvTqlUr9u/ff8Ex3t7eeHvr/gwiIlIy+7ZtpGPSZLBAXKNRRKj8VBqV7hLY0qVLGTlyJEuXLqVfv36XHJ+Xl8eBAwdo0KBBOaQTERF3cTLtCH6fj8Dbcpbk6j2wjXzD7EhSAqYWoLy8PJKTk0lOTgYgJSWF5ORk56TlSZMmMWzYMOf4JUuWMGzYMN58801sNhtpaWmkpaWRnZ3tHPPkk0+yYcMGDh48yA8//MBdd92F1Wpl8ODB5bpvIiJSdRUVFnBi3kCCyOSwR0Oaj1+Ch9VqdiwpAVMLUGJiIp07d3Z+hD06OprOnTszefJkAFJTU10+wTV79myKi4t5+OGHadCggfPx2GOPOcccPXqUwYMH07p1a+677z7q1avH5s2bCQwMLN+dExGRKmvb7PG0PbuLXKM6DFqCX+16ZkeSEqowk6ArkpJMohIREfeS8O+36L7zBRyGhR03zSTslkFmR5L/U5L370o3B0hERMQsexLW0WnHywDEN3tA5acSUwESERG5DBnHUgj47xi8LHaSat5Ij2H/MjuSXAUVIBERkUsoOJNP1oL7CCCLFI+mtB6/GIuH3kIrM/3fExERuQjD4WDHrNG0Kv6ZbGrgNXQZNWrVNjuWXCUVIBERkYuIX/4K3bK+wm5YOHzLhzRs3tbsSFIKVIBEREQuYOem/xC+53UAtrR6nA433mlyIiktKkAiIiLncfzgXhquexBPi4NEv1uxDX7e7EhSilSARERE/uRMfi5nFg+kDrnss7bk2gdiNOm5itH/TRERkT8wHA5+mnk/Lewp/IoftUYsx8e3ptmxpJSpAImIiPxB/EdT6Jr7HWcNK2l95hAc2tLsSFIGVIBERET+z4/f/ZvuB94DIKn9M7Tr0cfkRFJWVIBERESAI/t30HTDo3hYDBLq/IXuf33S7EhShlSARETE7eXlnMK+ZDB+5LPHsy1h4+do0nMVp/+7IiLi1hx2O/tmDqGp4wgZ1CVg1HK8fXzNjiVlTAVIRETcWvzCZ+h8ehNFhien/jKPgJAmZkeScqACJCIibmvb1x8RcXg2AMmdptA6/BaTE0l5UQESERG3dGj3VlptegKA+MC/0v2uR01OJOVJBUhERNxO9q8nsK4YQg1LAbu8OtJl7AdmR5JypgIkIiJuxV5czKHZg2lkpJJKIA3GLKOal7fZsaScqQCJiIhbSZj3OB0LtnDG8CL/roXUrd/Q7EhiAhUgERFxG1tXzyUidREAu7r9k5Zh15ucSMyiAiQiIm7hwI8/0C5hEgBxDYYS/pdxJicSM6kAiYhIlXfqRCq+K4dR3VLEjz7hdB/9jtmRxGQqQCIiUqWdLSrk+JyBNOAERy3BNBm3DKunp9mxxGQqQCIiUqVtnTuB9kXbyTd8KL7vY/zrBpodSSoAFSAREamytqx6nx4ZKwDYe90bNG0bbnIiqShUgEREpEr6OWk9HbdNBSAudAxdou43N5BUKCpAIiJS5ZxMO0ztL0bibTnLNt/rsI14zexIUsGoAImISJVSVFjAyXkDqc+vHPIIpeX4j/GwWs2OJRWMCpCIiFQp22aNpc3Zn8jBF4/BH1PLv67ZkaQCUgESEZEqI37F69h+/QKHYSHlxncIvSbM7EhSQakAiYhIlfDT5jV02TUNgPjmDxN2y30mJ5KKTAVIREQqvbQj+wlaM45qFjtba/aix/0vmR1JKjgVIBERqdQKTueRGzOQemRzwNqMtg8swuKhtze5OP0OERGRSstwONgxayTX2PdzilpUv385vjX9zY4llYAKkIiIVFrxy/5Jt+yvKTY8OBb5ASFNW5sdSSoJFSAREamUdv7vc8L3vgVAYusnuPaGO0xOJJWJCpCIiFQ6x1P20Cj2ITwtDrb498E26B9mR5JKxtQCtHHjRvr3709ISAgWi4VVq1Zdcp3169fTpUsXvL29admyJTExMeeMmTFjBk2bNsXHxwebzUZCQkLphxcREVOczsumYPFAapPHz56t6PDAfE16lhIz9XdMfn4+YWFhzJgx47LGp6Sk0K9fP26++WaSk5OZOHEiY8aMYe3atc4xy5cvJzo6milTppCUlERYWBhRUVFkZGSU1W6IiEg5MRwO9sy8n+aOg5ykNv4jluFTvYbZsaQSshiGYZgdAsBisfDZZ58xYMCAC475+9//zurVq9m5c6dz2aBBg8jKymLNmjUA2Gw2unXrxvvvvw+Aw+EgNDSURx55hGeeeeaysuTk5ODv7092djZ+fn5XvlMiIlKq4hb+g4iUGRQZVn65fRltbLeZHUkqkJK8f1eqc4ZxcXFERka6LIuKiiIuLg6AoqIitm7d6jLGw8ODyMhI55jzKSwsJCcnx+UhIiIVy/Zvl2H75QMAtl37D5UfuSqVqgClpaURFBTksiwoKIicnBzOnDnDyZMnsdvt5x2TlpZ2we1OmzYNf39/5yM0NLRM8ouIyJU5/HMyzTdMxMNiEF/vTmz3Pml2JKnkKlUBKiuTJk0iOzvb+Thy5IjZkURE5P/kZv+KsWwItSxn2F2tHZ3HzTY7klQBnmYHKIng4GDS09NdlqWnp+Pn50f16tWxWq1YrdbzjgkODr7gdr29vfH29i6TzCIicuUcdjsHZv2NTo6jZFCXwNHL8fL2MTuWVAGV6gxQREQEsbGxLsvWrVtHREQEAF5eXnTt2tVljMPhIDY21jlGREQqj4QFT9HpdByFRjWy7oghILix2ZGkijC1AOXl5ZGcnExycjLw28fck5OTOXz4MPDbpalhw4Y5xz/wwAP88ssvPP300+zZs4cPPviAFStW8PjjjzvHREdHM2fOHBYuXMju3bt58MEHyc/PZ+TIkeW6byIicnW2rV1Ij6PzAPix8wu06nKTyYmkKjH1ElhiYiI333yz83l0dDQAw4cPJyYmhtTUVGcZAmjWrBmrV6/m8ccf55133qFRo0bMnTuXqKgo55iBAwdy4sQJJk+eTFpaGp06dWLNmjXnTIwWEZGKK+WnLbT+4SmwwOb6A+kx4GGzI0kVU2HuA1SR6D5AIiLmyc5MJ+/9njQ00tnp3Yk2T67Ds5qX2bGkEqiy9wESEZGqrfhsEYfmDKahkc5xS30ajlmm8iNlQgVIREQqjMR5E+lYsJXThjdn7l5MncAGZkeSKkoFSEREKoTE/8yiR9rHAOy2TaNFhx4mJ5KqTAVIRERMt3/791yb+CwAcSHD6Hr7aJMTSVWnAiQiIqbKTD9Kzc9G4GM5y3afbnQf9bbZkcQNqACJiIhpzhYVkj5vEMGc4IglhKbjl2H1rFRfUiCVlAqQiIiYJmn2g7Qr2kGeUR3HwI/xrxNgdiRxEypAIiJiii0r38F28lMA9l3/Bk3adDE5kbgTFSARESl3exJjCdv+IgBxjcfT+bahJicSd1OiAvTaa69x5swZ5/NNmzZRWFjofJ6bm8tDDz1UeulERKTKOXH8IPW+HI2XpZhtNW7ANnya2ZHEDZXoqzCsViupqanUr18fAD8/P5KTk2nevDkA6enphISEYLfbyyZtOdFXYYiIlI3CgtMcfONmWhfv4aBHYwImbqSmXx2zY0kVUWZfhfHnrqSvERMRkctlOBxsnzWG1sV7yKEGnn9bqvIjptEcIBERKRcJn7xO91OrsRsWDvZ6j0YtrzU7krgxFSARESlzP8V9RZefXgVgS8tH6djrHpMTibsr8d2m5s6dS82aNQEoLi4mJiaGgIDf7tuQm5tbuulERKTSSzu8j+C146hmsZNYqze2IVPNjiRSsknQTZs2xWKxXHJcSkrKVYUymyZBi4iUjjP5uRx76yZa2g9wwNqckOiNVK9Ry+xYUkWV5P27RGeADh48eDW5RETEjRgOB7tmjSDcfoBT+OE7bJnKj1QYmgMkIiJlIn7Ji4TnfEOx4cHxW2fSoElrsyOJOJWoAMXFxfHll1+6LFu0aBHNmjWjfv36jBs3zuXGiCIi4p52bFhJt33TAUhs8xTtr+9nbiCRPylRAXrxxRfZtWuX8/mOHTsYPXo0kZGRPPPMM/znP/9h2jTd0VNExJ0d+2UXjb+bgNVikFD7dmwDnzE7ksg5SlSAkpOT6d27t/P5smXLsNlszJkzh+joaN59911WrFhR6iFFRKRyyM/NouijwfiTz17P1nQcPxeLh2ZbSMVTot+Vp06dIigoyPl8w4YN9O3b1/m8W7duHDlypPTSiYhIpWE4HOydOZRmjkOcpDZ1R63Ap3oNs2OJnFeJClBQUJDzI+5FRUUkJSXRo0cP5+u5ublUq1atdBOKiEilsHnhJLrk/48iw8rJfvMIDGlqdiSRCypRAbr99tt55pln+N///sekSZPw9fWlZ8+eztd//PFHWrRoUeohRUSkYkv+Zim2g7N++3XH52nTLdLkRCIXV6L7AL300kvcfffd3HTTTdSsWZOYmBi8vLycr8+fP5/bbrut1EOKiEjFdWhvMi3/9zgeFoP4gLux3fO42ZFELqlEd4L+XXZ2NjVr1sRqtbos//XXX6lVq1alvwymO0GLiFyenKxMst+5gVDjOD9Vu5aWT8bi5e1jdixxU2V2J+hRo0Zd1rj58+eXZLMiIlIJ2YuLSZk1mDDjOOnUI2jMcpUfqTRKVIBiYmJo0qQJnTt35gpOHImISBWSsOBJIs7EU2BUI+euhVwT1MjsSCKXrUQF6MEHH2Tp0qWkpKQwcuRIhg4dSt26dcsqm4iIVFBJXy0g4tgCAHZ2fYnwTj0vsYZIxVKiT4HNmDGD1NRUnn76af7zn/8QGhrKfffdx9q1a3VGSETETfyyM542m/8OwOagwYTf8aDJiURK7oomQf/u0KFDxMTEsGjRIoqLi9m1axc1a9YszXym0CRoEZHzyzqZxukZNxJipLPDuzNtn/waz2pel15RpByU5P37qu5P7uHhgcViwTAM7Hb71WxKREQquOKzRRydM5AQI53jliBCxy5T+ZFKq8QFqLCwkKVLl3LrrbfSqlUrduzYwfvvv8/hw4erxNkfERE5v8S5j3JtYTKnDW8K/7qY2gHBZkcSuWIlmgT90EMPsWzZMkJDQxk1ahRLly4lICCgrLKJiEgFseXzD+iRvhSAPRGv0aW9zeREIlenRHOAPDw8aNy4MZ07d8ZisVxw3MqVK0slnFk0B0hE5P/bt20jjVfdjbflLHENRxIxdrrZkUTOq8xuhDhs2LCLFh8REalaTqYdwe/zEXhbzpJcvQe2UW+aHUmkVJT4RogiIuIeigoLODFvIG3J5LBHQ5qPX4LHn74CSaSyuqpPgZWWGTNm0LRpU3x8fLDZbCQkJFxwbK9evbBYLOc8+vXr5xwzYsSIc17v06dPeeyKiEiVsW32eNqe3UWuUR0GLcGvdj2zI4mUmhKdASoLy5cvJzo6mpkzZ2Kz2Zg+fTpRUVHs3buX+vXrnzN+5cqVFBUVOZ9nZmYSFhbGvffe6zKuT58+LFiwwPnc29u77HZCRKSKSfj3W9gyV+EwLBy4cTqdWnUyO5JIqTL9DNBbb73F2LFjGTlyJO3atWPmzJn4+vpe8AtV69atS3BwsPOxbt06fH19zylA3t7eLuPq1KlTHrsjIlLp7UlYR6cdLwMQ3+wBOvUeZHIikdJnagEqKipi69atREZGOpd5eHgQGRlJXFzcZW1j3rx5DBo0iBo1argsX79+PfXr16d169Y8+OCDZGZmlmp2EZGqKONYCgH/HYOXxU5SjRvpMexfZkcSKROmXgI7efIkdrudoKAgl+VBQUHs2bPnkusnJCSwc+dO5s2b57K8T58+3H333TRr1owDBw7wj3/8g759+xIXF4f1PBP4CgsLKSwsdD7Pycm5wj0SEam8Cs7kk7XgPlqRRYpHE1o/sBiLh+kXCkTKhOlzgK7GvHnz6NChA927d3dZPmjQ/z9d26FDBzp27EiLFi1Yv349vXv3Pmc706ZN44UXXijzvCIiFZXhcLBj1mi6Ff9MNjXwGrqUGrVqmx1LpMyYWu0DAgKwWq2kp6e7LE9PTyc4+OK3WM/Pz2fZsmWMHj36kj+nefPmBAQEsH///vO+PmnSJLKzs52PI0eOXP5OiIhUAfHLX6Fb1lfYDQuHb5lBw+btzY4kUqZMLUBeXl507dqV2NhY5zKHw0FsbCwREREXXfeTTz6hsLCQoUOHXvLnHD16lMzMTBo0aHDe1729vfHz83N5iIi4i52b/kP4ntcB2HLNRDrceJfJiUTKnukXd6Ojo5kzZw4LFy5k9+7dPPjgg+Tn5zNy5Ejgt7tPT5o06Zz15s2bx4ABA6hXz/W+FHl5eTz11FNs3ryZgwcPEhsby5133knLli2Jiooql30SEaksjh/cS8N1D+JpcZDodyu2v002O5JIuTB9DtDAgQM5ceIEkydPJi0tjU6dOrFmzRrnxOjDhw/j8adJeHv37uX777/n66+/Pmd7VquVH3/8kYULF5KVlUVISAi33XYbL730ku4FJCLyB2fyczmzeBAh5LLf2oJrH4jRpGdxGyX6MlR3oS9DFZGqznA4SHr7Hrrmfsuv+FE06luCG19jdiyRq1KS929VfRERNxT/0RS65n7LWcNKWtRslR9xOypAIiJu5sfv/k33A+8BkNTu77SL6GtyIpHypwIkIuJGju7fSdMNj+JhMUio8xe63/uU2ZFETKECJCLiJvJyTlG8ZBB+5LPHsy1h4+do0rO4Lf3OFxFxAw67nX0zh9DUcYQT1CFg1HK8fXzNjiViGhUgERE3EL/wGTqf3kSR4cmvf5lPQEgTsyOJmEoFSESkitv29UdEHJ4NQHKnKbQOv8XkRCLmUwESEanCDu3eSqtNTwAQH3AP3e961OREIhWDCpCISBWVfeok1hVDqGEpYJdXB7qM+9DsSCIVhgqQiEgVZC8u5tCsQTQyUkkjkAZjllPNS18HJPI7FSARkSooYf7jdCzYwhnDi7y7FlK3fkOzI4lUKCpAIiJVzNbVc4k4vgiAXd3+Scuw601OJFLxqACJiFQhB3Zspl3CJAA2Bw8h/C/jTE4kUjGpAImIVBGnTqTi++lQqluK+NGnK93GvGt2JJEKSwVIRKQKKD5bxPE5A2nACY5agmkybjlWT0+zY4lUWCpAIiJVQOKch2lftJ3ThjfF932Mf91AsyOJVGgqQCIildyWVe/TI2MFAHuue5OmbcNNTiRS8akAiYhUYj8nrafjtqkAxIWOoUvU/eYGEqkkVIBERCqpk2mHqf3FSLwtZ9nmex22Ea+ZHUmk0lABEhGphIoKCzg5byD1+ZVDHo1oOf5jPKxWs2OJVBoqQCIildC2WWNpc/YncvDFY/ASavnXNTuSSKWiAiQiUsnEf/IGtl+/wGFYSLnxHUKvCTM7kkilowIkIlKJ7I5fS5ed/wIgvvlDhN1yn8mJRConFSARkUoi/egB6n81lmoWO1tr9qLH/S+bHUmk0lIBEhGpBApO55ETM5B6ZPOLR1PaPrAIi4f+Che5UvrTIyJSwRkOBztmjeKa4n2cohY+9y/Ht6a/2bFEKjUVIBGRCi5+2T/plr2WYsODY71nENKsjdmRRCo9FSARkQps5/8+J3zvWwAkto7m2p53mpxIpGpQARIRqaCOp+yhUexDeFocbPGPwjboWbMjiVQZKkAiIhXQ6bxsChYPpDZ57PO8hg7j52vSs0gp0p8mEZEKxnA42DPzfpo7DpKJP34jluPjW9PsWCJVigqQiEgFs3nxc3TJ20CRYSWj7xyCGrUwO5JIlaMCJCJSgWz/dgW2Xz4AYNu1/6CtLcrkRCJVkwqQiEgFcWTfdpptfAwPi0F83Tuw3fuk2ZFEqiwVIBGRCiA3+1ccS/+GH6fZXa0dncfPMTuSSJWmAiQiYjKH3c6BWX+jieMoGdQlcPRyvLx9zI4lUqWpAImImCw+5mk6nY6j0KhG1h0xBAQ3NjuSSJWnAiQiYqJtaxcScWQuAD92foFWXW4yOZGIe6gQBWjGjBk0bdoUHx8fbDYbCQkJFxwbExODxWJxefj4uJ4qNgyDyZMn06BBA6pXr05kZCT79u0r690QESmRlJ+20PqHpwDYXP8+ug142OREIu7D9AK0fPlyoqOjmTJlCklJSYSFhREVFUVGRsYF1/Hz8yM1NdX5OHTokMvrr732Gu+++y4zZ84kPj6eGjVqEBUVRUFBQVnvjojIZcnOTKfaJ0PxtRSy07sT4WNnmB1JxK2YXoDeeustxo4dy8iRI2nXrh0zZ87E19eX+fPnX3Adi8VCcHCw8xEUFOR8zTAMpk+fznPPPcedd95Jx44dWbRoEcePH2fVqlXlsEciIhdnLy7m0JzBNDLSOG6pT8Mxy/Cs5mV2LBG3YmoBKioqYuvWrURGRjqXeXh4EBkZSVxc3AXXy8vLo0mTJoSGhnLnnXeya9cu52spKSmkpaW5bNPf3x+bzXbBbRYWFpKTk+PyEBEpK1vmPkrHgq2cMbw4c/di6gQ2MDuSiNsxtQCdPHkSu93ucgYHICgoiLS0tPOu07p1a+bPn8/nn3/ORx99hMPh4LrrruPo0aMAzvVKss1p06bh7+/vfISGhl7tromInFfif2bRI+1jAH7qPo0WHXqYnEjEPZl+CaykIiIiGDZsGJ06deKmm25i5cqVBAYGMmvWrCve5qRJk8jOznY+jhw5UoqJRUR+s3/791yb+CwAcSHD6NpvjMmJRNyXqQUoICAAq9VKenq6y/L09HSCg4MvaxvVqlWjc+fO7N+/H8C5Xkm26e3tjZ+fn8tDRKQ0ZaYfpeZnI/CxnGW7Tze6j3rb7Egibs3UAuTl5UXXrl2JjY11LnM4HMTGxhIREXFZ27Db7ezYsYMGDX67ht6sWTOCg4NdtpmTk0N8fPxlb1NEpDSdLSokbd4ggjnBEUsITccvw+rpaXYsEbdm+p/A6Ohohg8fTnh4ON27d2f69Onk5+czcuRIAIYNG0bDhg2ZNm0aAC+++CI9evSgZcuWZGVl8frrr3Po0CHGjPntVLLFYmHixIm8/PLLXHPNNTRr1oznn3+ekJAQBgwYYNZuiogbS5r9ILaiHeQbPjgGfoR/nQCzI4m4PdML0MCBAzlx4gSTJ08mLS2NTp06sWbNGuck5sOHD+Ph8f9PVJ06dYqxY8eSlpZGnTp16Nq1Kz/88APt2rVzjnn66afJz89n3LhxZGVlccMNN7BmzZpzbpgoIlLWtqx8B9vJTwH4+fo36dy2q8mJRATAYhiGYXaIiiYnJwd/f3+ys7M1H0hErtiexFia/+c+vCzFxDUeR8So182OJFKlleT9u9J9CkxEpDI4efwQ9b4cjZelmG2+12Mb/orZkUTkD1SARERKWWHBaTLn30cgpzjoEco1D3yMh9VqdiwR+QMVIBGRUmQ4HGyfNYbWxXvIoQaef1tGTb86ZscSkT9RARIRKUUJn7xO91OrsRsWDvZ6j0YtrzU7koichwqQiEgp+SnuK7r89CoAW1o8Qsde95icSEQuRAVIRKQUpB3eR/DacVSz2Nla6xZsQ18wO5KIXIQKkIjIVTqTn0vewoHUJYcD1ua0e2ARFg/99SpSkelPqIjIVTAcDnbNGkFL+wFO4YfvsGVUr1HL7FgicgkqQCIiVyF+yYuE53xDseHB8Vtn0qBJa7MjichlUAESEblCOzZ+Rrd90wFIbPMU7a/vZ24gEblsKkAiIlfg2C+7aPztw1gtBltq98U28BmzI4lICagAiYiUUH5uFkUfDcaffH72bEWH8fM06VmkktGfWBGREjAcDvbOvJ9mjkOcpDa1R67Ap3oNs2OJSAmpAImIlMDmRf+gS/5GigwrJ2+fS/2GzcyOJCJXQAVIROQyJccuw5Yy87dfd3yeNt1vNTmRiFwpFSARkctwaG8yLTZOxMNiEF9vAN3vedzsSCJyFVSAREQuIScrE8vyv1HLcoafql1L53GzzI4kIldJBUhE5CLsxcWkzBpMY8cx0qlH/dHL8PL2MTuWiFwlFSARkYtIWPAkYWfiKTCqkTNgIQHBoWZHEpFSoAIkInIBSV8tIOLYAgB2dn2Jazr1NDmRiJQWFSARkfP4ZWc8bTb/HYDNQYMJv+NBkxOJSGlSARIR+ZOsk2n4fHo/vpZCdnh3JnzMu2ZHEpFSpgIkIvIHxWeLODJnECFGOsctQYSOXYZnNS+zY4lIKVMBEhH5g8S5j9KhcBunDW8K7llM7YBgsyOJSBlQARIR+T+JX3xIj/SlAOzp8SrNr7WZnEhEyooKkIgIsC/5f1y79XkA4hqOpEvfkSYnEpGypAIkIm7vZNoR/FYNx8dylu3VbdhGvWl2JBEpYypAIuLWigoLyJg3iCAyOezRkGbjl+JhtZodS0TKmAqQiLi1bXMepN3ZneQa1TEGLsGvdj2zI4lIOVABEhG3lfDp29hOrsRhWDhw43SatO5kdiQRKScqQCLilvYkrKPTjy8BEN90PJ16DzI5kYiUJxUgEXE7GcdSCPjvGLwsdpJq3EiP4dPMjiQi5UwFSETcSsGZfLIW3EcAWaR4NKH1A4uxeOivQhF3oz/1IuI2DIeDHbNG06r4Z7KpgdfQpdSoVdvsWCJiAhUgEXEb8ctfoVvWV9gNC4dvmUHD5u3NjiQiJlEBEhG3sGvTasL3vA7Almsm0uHGu0xOJCJmUgESkSov9dBeQtY9gKfFQaJfJLa/TTY7koiYTAVIRKq0M/m5nF40iDrksN/agmsfWKhJzyJSMQrQjBkzaNq0KT4+PthsNhISEi44ds6cOfTs2ZM6depQp04dIiMjzxk/YsQILBaLy6NPnz5lvRsiUsEYDgc/zRxGC/sv/IofNYcvx8e3ptmxRKQCML0ALV++nOjoaKZMmUJSUhJhYWFERUWRkZFx3vHr169n8ODBfPfdd8TFxREaGsptt93GsWPHXMb16dOH1NRU52Pp0qXlsTsiUoHEfzyVrrnfctawkhY1m+DG15gdSUQqCIthGIaZAWw2G926deP9998HwOFwEBoayiOPPMIzzzxzyfXtdjt16tTh/fffZ9iwYcBvZ4CysrJYtWrVFWXKycnB39+f7Oxs/Pz8rmgbImKuH9d/SvvvRmO1GMS3/Qe2gX83O5KIlLGSvH+begaoqKiIrVu3EhkZ6Vzm4eFBZGQkcXFxl7WN06dPc/bsWerWreuyfP369dSvX5/WrVvz4IMPkpmZecFtFBYWkpOT4/IQkcrr6P6dNF3/CFaLQUKdfnS/9ymzI4lIBWNqATp58iR2u52goCCX5UFBQaSlpV3WNv7+978TEhLiUqL69OnDokWLiI2N5dVXX2XDhg307dsXu91+3m1MmzYNf39/5yM0NPTKd0pETJWXc4riJYPwI5+9nm0IGz9Xk55F5ByeZge4Gq+88grLli1j/fr1+Pj4OJcPGvT/v9SwQ4cOdOzYkRYtWrB+/Xp69+59znYmTZpEdHS083lOTo5KkEgl5LDb2TdzCJ0dRzhBHeqOWo63j6/ZsUSkAjL1n0UBAQFYrVbS09NdlqenpxMcHHzRdd944w1eeeUVvv76azp27HjRsc2bNycgIID9+/ef93Vvb2/8/PxcHiJS+cQvnETn05soMjzJ/Ms8AkOamh1JRCooUwuQl5cXXbt2JTY21rnM4XAQGxtLRETEBdd77bXXeOmll1izZg3h4eGX/DlHjx4lMzOTBg0alEpuEal4tn39ERGHZwGwPWwybcLPPdsrIvI70y+MR0dHM2fOHBYuXMju3bt58MEHyc/PZ+TIkQAMGzaMSZMmOce/+uqrPP/888yfP5+mTZuSlpZGWloaeXl5AOTl5fHUU0+xefNmDh48SGxsLHfeeSctW7YkKirKlH0UkbJ1aPdWWm16AoD4gHvodvdjJicSkYrO9DlAAwcO5MSJE0yePJm0tDQ6derEmjVrnBOjDx8+jMcfJjB++OGHFBUV8de//tVlO1OmTGHq1KlYrVZ+/PFHFi5cSFZWFiEhIdx222289NJLeHt7l+u+iUjZyz51Eo8VQ6lhKWCXVwe6jPvQ7EgiUgmYfh+gikj3ARKpHOzFxex8ow9hBVtIIxCvhzZQt35Ds2OJiEkqzX2ARESuRsL8xwkr2MIZw4u8u2JUfkTksqkAiUiltPW/84g4vgiAXd3+ScuwG0xOJCKViQqQiFQ6B3Zspm38bx+O2Bw8hPC/jDM5kYhUNipAIlKpnDqRSvWV9+NrKeRHn650G/Ou2ZFEpBJSARKRSqP4bBHH5g4ixMjgqCWYJmOXYvU0/cOsIlIJqQCJSKWROOdhri1M5rThzdl7P8K/XtClVxIROQ8VIBGpFLasep8eGSsA2Hvd6zRr183kRCJSmakAiUiF93PSejpumwrA5kaj6Rw13NxAIlLpqQCJSIV2Mu0wtb8YibflLMm+EXQf+brZkUSkClABEpEKq6iwgBPzBlKfXznk0YgW45fgYbWaHUtEqgAVIBGpsLbNHkfbsz+Ra1THY/ASavnXNTuSiFQRKkAiUiHFf/IGtszPcRgWfrnpXUKvCTM7kohUISpAIlLh7I5fS+ed/wIgvvlDhN1yn8mJRKSqUQESkQol/egBAr8ah5fFTlLNm+hx/8tmRxKRKkgFSEQqjIIz+eTEDCSALH7xaEqbBxZj8dBfUyJS+vQ3i4hUCIbDwY6ZI7mmeB9Z1MTn/uX41vQ3O5aIVFEqQCJSIcQv+yfdstdSbHhwtPcHhDRrY3YkEanCVIBExHQ7//c54XvfAiCxdTTX9rzT5EQiUtWpAImIqY6n7KFR7EN4Whxs8b8N26BnzY4kIm5ABUhETHM6L5uCxQOpTR77PK+hw/gFmvQsIuVCf9OIiCkMh4M9M++nueMgmfhTa/gyfHxrmh1LRNyECpCImGLz4ufpkreBs4aVjL5zCA5taXYkEXEjKkAiUu62f7sC2y8zAEhqP4m2tiiTE4mIu1EBEpFydWTfdpptfAwPi0F83Tuw3feU2ZFExA2pAIlIucnN/hXH0iH4cZo91drRefwcsyOJiJtSARKRcuGw29k/awhNHEfIoC4Bo5fj5e1jdiwRcVMqQCJSLuJjnqbz6R8oNKqRdccCAoIbmx1JRNyYCpCIlLmktYuJODIXgB87T6VVl17mBhIRt6cCJCJl6uDuRFr/8CQAm+vfR7cBE0xOJCKiAiQiZSg7Mx3PFUOoYSlgl1cYXce8b3YkERFABUhEyoi9uJhDcwbTyEgjlUBCxi6nmpe32bFERAAVIBEpI1vmPkrHgq2cMbw4ffci6gQ2MDuSiIiTCpCIlLrEL2fTI+1jAH7qPo0WHa8zOZGIiCsVIBEpVfu3b6L9lmcBiGswjK79xpicSETkXCpAIlJqfs04Rs3PhlPdUsSPPt3oPvptsyOJiJyXCpCIlIqzRYWkzh1IMCc4amlAk3FLsXp6mh1LROS8VIBEpFQkzXmI9kU7yDd8sN/3Mf51A82OJCJyQfrnWTmyFxezJ34tZ04do3qdhrSxRbn8C/lSr8ul6RiWjz8f57y0n7Gd+DcAP1//Jp3bdjU5oYjIxVWId4YZM2bw+uuvk5aWRlhYGO+99x7du3e/4PhPPvmE559/noMHD3LNNdfw6quvcvvttztfNwyDKVOmMGfOHLKysrj++uv58MMPueaaa8pjd85r29qFhMS9QHsyncvS19XjeMQUOkcNv+Trcmk6huXjfMfZMAALxDUeR8RtQ80LJyJymUy/BLZ8+XKio6OZMmUKSUlJhIWFERUVRUZGxnnH//DDDwwePJjRo0ezbds2BgwYwIABA9i5c6dzzGuvvca7777LzJkziY+Pp0aNGkRFRVFQUFBeu+Vi29qFhP3wKIFGpsvyQCOTsB8eJW7mQxd9fdvaheUZt1K61DHWMSwdFzrOFstvJcgruL1JyURESsZiGIZhZgCbzUa3bt14//3fbpHvcDgIDQ3lkUce4Zlnnjln/MCBA8nPz+fLL790LuvRowedOnVi5syZGIZBSEgITzzxBE8++dv3D2VnZxMUFERMTAyDBg26ZKacnBz8/f3Jzs7Gz8/vqvbPXlzMyZdbEWhk4mE593WHAQYWLBgXfD3TUofC+/+L1dN6VVmqKnuxHe/FfalnZOkYlqHLOc4ZlnoEPvezLjuKiClK8v5t6t9SRUVFbN26lUmTJjmXeXh4EBkZSVxc3HnXiYuLIzo62mVZVFQUq1atAiAlJYW0tDQiIyOdr/v7+2Oz2YiLiztvASosLKSwsND5PCcn52p2y8We+LW/XSo4zxsG8H9vJBfuoB4WCOQULI4otUxV1kWOsY5hKbrIcQ4mk13xa2l/fb/yzSQiUkKmFqCTJ09it9sJCgpyWR4UFMSePXvOu05aWtp5x6elpTlf/33Zhcb82bRp03jhhReuaB8u5cypY6WynSLDisP8K5YVkgcOvCz2S47TMbw6l3ucS+v3vIhIWdJ5amDSpEkuZ5VycnIIDQ0tlW1Xr9OwVLaz77bF+lf1BezatJr26/52yXE6hlfnco9zaf2eFxEpS6b+czggIACr1Up6errL8vT0dIKDg8+7TnBw8EXH//7fkmzT29sbPz8/l0dpaWOLIp16OC5wlcthgN3wuOjradSjjS2q1DJVNZdzjHUMr56Os4hUJaYWIC8vL7p27UpsbKxzmcPhIDY2loiI88/XiIiIcBkPsG7dOuf4Zs2aERwc7DImJyeH+Pj4C26zLFk9PTkeMQXgnDeO358nNBh80ddTI6ZoUulFXM4x1jG8ejrOIlKVmD4hIjo6mjlz5rBw4UJ2797Ngw8+SH5+PiNHjgRg2LBhLpOkH3vsMdasWcObb77Jnj17mDp1KomJiUyYMAEAi8XCxIkTefnll/niiy/YsWMHw4YNIyQkhAEDBpixi3SOGs72697lhKWey/IMSz22X/cuEQ98cNHXdQ+bS7vUMdYxLB06ziJSVZj+MXiA999/33kjxE6dOvHuu+9is9kA6NWrF02bNiUmJsY5/pNPPuG5555z3gjxtddeO++NEGfPnk1WVhY33HADH3zwAa1atbqsPKX5Mfg/0p2gy56OYfnQcRaRiqgk798VogBVNGVVgERERKTslOT92/RLYCIiIiLlTQVIRERE3I4KkIiIiLgdFSARERFxOypAIiIi4nZUgERERMTtqACJiIiI21EBEhEREbejAiQiIiJuR/euP4/fb46dk5NjchIRERG5XL+/b1/Ol1yoAJ1Hbm4uAKGhoSYnERERkZLKzc3F39//omP0XWDn4XA4OH78OLVq1cJisZTadnNycggNDeXIkSP6jrEypONcPnScy4+OdfnQcS4fZXmcDcMgNzeXkJAQPDwuPstHZ4DOw8PDg0aNGpXZ9v38/PSHqxzoOJcPHefyo2NdPnScy0dZHedLnfn5nSZBi4iIiNtRARIRERG3owJUjry9vZkyZQre3t5mR6nSdJzLh45z+dGxLh86zuWjohxnTYIWERERt6MzQCIiIuJ2VIBERETE7agAiYiIiNtRARIRERG3owJUTmbMmEHTpk3x8fHBZrORkJBgdqQqZ+PGjfTv35+QkBAsFgurVq0yO1KVNG3aNLp160atWrWoX78+AwYMYO/evWbHqnI+/PBDOnbs6LxZXEREBF999ZXZsaq8V155BYvFwsSJE82OUuVMnToVi8Xi8mjTpo1peVSAysHy5cuJjo5mypQpJCUlERYWRlRUFBkZGWZHq1Ly8/MJCwtjxowZZkep0jZs2MDDDz/M5s2bWbduHWfPnuW2224jPz/f7GhVSqNGjXjllVfYunUriYmJ3HLLLdx5553s2rXL7GhV1pYtW5g1axYdO3Y0O0qV1b59e1JTU52P77//3rQs+hh8ObDZbHTr1o33338f+O27xkJDQ3nkkUd45plnTE5XNVksFj777DMGDBhgdpQq78SJE9SvX58NGzZw4403mh2nSqtbty6vv/46o0ePNjtKlZOXl0eXLl344IMPePnll+nUqRPTp083O1aVMnXqVFatWkVycrLZUQCdASpzRUVFbN26lcjISOcyDw8PIiMjiYuLMzGZSOnIzs4GfntzlrJht9tZtmwZ+fn5REREmB2nSnr44Yfp16+fy9/VUvr27dtHSEgIzZs3Z8iQIRw+fNi0LPoy1DJ28uRJ7HY7QUFBLsuDgoLYs2ePSalESofD4WDixIlcf/31XHvttWbHqXJ27NhBREQEBQUF1KxZk88++4x27dqZHavKWbZsGUlJSWzZssXsKFWazWYjJiaG1q1bk5qaygsvvEDPnj3ZuXMntWrVKvc8KkAicsUefvhhdu7caep1/KqsdevWJCcnk52dzb///W+GDx/Ohg0bVIJK0ZEjR3jsscdYt24dPj4+Zsep0vr27ev8dceOHbHZbDRp0oQVK1aYcllXBaiMBQQEYLVaSU9Pd1menp5OcHCwSalErt6ECRP48ssv2bhxI40aNTI7TpXk5eVFy5YtAejatStbtmzhnXfeYdasWSYnqzq2bt1KRkYGXbp0cS6z2+1s3LiR999/n8LCQqxWq4kJq67atWvTqlUr9u/fb8rP1xygMubl5UXXrl2JjY11LnM4HMTGxupavlRKhmEwYcIEPvvsM7799luaNWtmdiS34XA4KCwsNDtGldK7d2927NhBcnKy8xEeHs6QIUNITk5W+SlDeXl5HDhwgAYNGpjy83UGqBxER0czfPhwwsPD6d69O9OnTyc/P5+RI0eaHa1KycvLc/mXREpKCsnJydStW5fGjRubmKxqefjhh1myZAmff/45tWrVIi0tDQB/f3+qV69ucrqqY9KkSfTt25fGjRuTm5vLkiVLWL9+PWvXrjU7WpVSq1atc+av1ahRg3r16mleWyl78skn6d+/P02aNOH48eNMmTIFq9XK4MGDTcmjAlQOBg4cyIkTJ5g8eTJpaWl06tSJNWvWnDMxWq5OYmIiN998s/N5dHQ0AMOHDycmJsakVFXPhx9+CECvXr1cli9YsIARI0aUf6AqKiMjg2HDhpGamoq/vz8dO3Zk7dq13HrrrWZHE7kiR48eZfDgwWRmZhIYGMgNN9zA5s2bCQwMNCWP7gMkIiIibkdzgERERMTtqACJiIiI21EBEhEREbejAiQiIiJuRwVIRERE3I4KkIiIiLgdFSARERFxOypAInLVevXqxcSJE82OAcDUqVPp1KmT2TFEpIJTARKRKuXJJ590+e69imb9+vVYLBaysrLMjiLi1lSARKRSKCoquqxxNWvWpF69emWc5lyXm09EKgYVIBEpdYWFhTz55JM0bNiQGjVqYLPZWL9+vfP1zMxMBg8eTMOGDfH19aVDhw4sXbrUZRu9evViwoQJTJw4kYCAAKKiopxnT2JjYwkPD8fX15frrruOvXv3Otf78yWwESNGMGDAAN544w0aNGhAvXr1ePjhhzl79qxzTGpqKv369aN69eo0a9aMJUuW0LRpU6ZPn37Bffx9u//85z8JCQmhdevWACxevJjw8HBq1apFcHAwf/vb38jIyADg4MGDzu+rq1OnDhaLxfn9aQ6Hg2nTptGsWTOqV69OWFgY//73v6/k8IvIZVABEpFSN2HCBOLi4li2bBk//vgj9957L3369GHfvn0AFBQU0LVrV1avXs3OnTsZN24c999/PwkJCS7bWbhwIV5eXmzatImZM2c6lz/77LO8+eabJCYm4unpyahRoy6a57vvvuPAgQN89913LFy4kJiYGJcvyB02bBjHjx9n/fr1fPrpp8yePdtZWi4mNjaWvXv3sm7dOr788ksAzp49y0svvcT27dtZtWoVBw8edJac0NBQPv30UwD27t1Lamoq77zzDgDTpk1j0aJFzJw5k127dvH4448zdOhQNmzYcMkcInIFDBGRq3TTTTcZjz32mGEYhnHo0CHDarUax44dcxnTu3dvY9KkSRfcRr9+/YwnnnjCZZudO3d2GfPdd98ZgPHNN984l61evdoAjDNnzhiGYRhTpkwxwsLCnK8PHz7caNKkiVFcXOxcdu+99xoDBw40DMMwdu/ebQDGli1bnK/v27fPAIy33377gnmHDx9uBAUFGYWFhRccYxiGsWXLFgMwcnNzXfbh1KlTzjEFBQWGr6+v8cMPP7isO3r0aGPw4MEX3b6IXBlPM8uXiFQ9O3bswG6306pVK5flhYWFzrk5drudf/3rX6xYsYJjx45RVFREYWEhvr6+Lut07dr1vD+jY8eOzl83aNAAgIyMDBo3bnze8e3bt8dqtbqss2PHDuC3MzGenp506dLF+XrLli2pU6fOJfe1Q4cOeHl5uSzbunUrU6dOZfv27Zw6dQqHwwHA4cOHadeu3Xm3s3//fk6fPs2tt97qsryoqIjOnTtfMoeIlJwKkIiUqry8PKxWK1u3bnUpHfDbBGWA119/nXfeeYfp06fToUMHatSowcSJE8+ZSFyjRo3z/oxq1ao5f22xWACcReNS439f52LjL9ef8+Xn5xMVFUVUVBQff/wxgYGBHD58mKioqItOks7LywNg9erVNGzY0OU1b2/vq84pIudSARKRUtW5c2fsdjsZGRn07NnzvGM2bdrEnXfeydChQ4HfysvPP/98wTMkZal169YUFxezbds25xmn/fv3c+rUqRJva8+ePWRmZvLKK68QGhoKQGJiosuY388Y2e1257J27drh7e3N4cOHuemmm650V0SkBDQJWkRKVatWrRgyZAjDhg1j5cqVpKSkkJCQwLRp01i9ejUA11xzDevWreOHH35g9+7djB8/nvT0dFPytmnThsjISMaNG0dCQgLbtm1j3LhxVK9e3Xl26XI1btwYLy8v3nvvPX755Re++OILXnrpJZcxTZo0wWKx8OWXX3LixAny8vKoVasWTz75JI8//jgLFy7kwIEDJCUl8d5777Fw4cLS3F0R+T8qQCJS6hYsWMCwYcN44oknaN26NQMGDGDLli3OOTrPPfccXbp0ISoqil69ehEcHMyAAQNMy7to0SKCgoK48cYbueuuuxg7diy1atXCx8enRNsJDAwkJiaGTz75hHbt2vHKK6/wxhtvuIxp2LAhL7zwAs888wxBQUFMmDABgJdeeonnn3+eadOm0bZtW/r06cPq1atp1qxZqe2niPx/FsMwDLNDiIhUJEePHiU0NJRvvvmG3r17mx1HRMqACpCIuL1vv/2WvLw8OnToQGpqKk8//TTHjh3j559/PmcCtYhUDZoELSJu7+zZs/zjH//gl19+oVatWlx33XV8/PHHKj8iVZjOAImIiIjb0SRoERERcTsqQCIiIuJ2VIBERETE7agAiYiIiNtRARIRERG3owIkIiIibkcFSERERNyOCpCIiIi4HRUgERERcTv/D4UvO+Nq7QsFAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "estim = [0.01,0.1,1,2,5]\n",
    "train_result=[]\n",
    "val_result=[]\n",
    "for i in estim:\n",
    "    print(i)\n",
    "    xgb = XGBRegressor(n_estimators=50, learning_rate=i, max_depth= 3 , random_state=0)\n",
    "    xgb.fit(x_train, y_train)\n",
    "    y_train_pred = xgb.predict(x_train)\n",
    "    train_result.append(mean_squared_error(y_train, y_train_pred))\n",
    "    y_val_pred = xgb.predict(x_val)\n",
    "    val_result.append(mean_squared_error(y_val, y_val_pred))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "plt.plot(estim,train_result, marker='o', linestyle='-')\n",
    "plt.plot(estim,val_result, marker='o', linestyle='-')\n",
    "plt.xlabel(\"learning rate\")\n",
    "plt.ylabel('MSE')\n",
    "plt.title('Learning Rate')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For max_depth:5,n_estimators:5,learning_rate:0.01\n",
      "            train accuracy:36.15103485361481 validation accuracy:32.40595076367675\n",
      "For max_depth:5,n_estimators:5,learning_rate:0.1\n",
      "            train accuracy:19.08711207312206 validation accuracy:16.653298966043064\n",
      "For max_depth:5,n_estimators:5,learning_rate:1\n",
      "            train accuracy:6.7528844586755765 validation accuracy:10.637303294432842\n",
      "For max_depth:5,n_estimators:10,learning_rate:0.01\n",
      "            train accuracy:33.51188379734885 validation accuracy:29.951519474768308\n",
      "For max_depth:5,n_estimators:10,learning_rate:0.1\n",
      "            train accuracy:11.808232135630869 validation accuracy:10.251799316210134\n",
      "For max_depth:5,n_estimators:10,learning_rate:1\n",
      "            train accuracy:6.12296730091129 validation accuracy:10.612837626682524\n",
      "For max_depth:5,n_estimators:15,learning_rate:0.01\n",
      "            train accuracy:31.125087565360914 validation accuracy:27.75289071754342\n",
      "For max_depth:5,n_estimators:15,learning_rate:0.1\n",
      "            train accuracy:9.047493361833174 validation accuracy:8.160551660282728\n",
      "For max_depth:5,n_estimators:15,learning_rate:1\n",
      "            train accuracy:5.81366467706509 validation accuracy:13.185082241887327\n",
      "For max_depth:5,n_estimators:25,learning_rate:0.01\n",
      "            train accuracy:27.00991267963088 validation accuracy:23.955900334579017\n",
      "For max_depth:5,n_estimators:25,learning_rate:0.1\n",
      "            train accuracy:7.341527812118083 validation accuracy:7.06324660253249\n",
      "For max_depth:5,n_estimators:25,learning_rate:1\n",
      "            train accuracy:5.1392859192451725 validation accuracy:16.462142247888963\n",
      "For max_depth:5,n_estimators:50,learning_rate:0.01\n",
      "            train accuracy:19.614326405050956 validation accuracy:17.21538306200086\n",
      "For max_depth:5,n_estimators:50,learning_rate:0.1\n",
      "            train accuracy:6.319994548698917 validation accuracy:7.114264055583997\n",
      "For max_depth:5,n_estimators:50,learning_rate:1\n",
      "            train accuracy:4.45855607563335 validation accuracy:26.54799188437628\n",
      "For max_depth:5,n_estimators:60,learning_rate:0.01\n",
      "            train accuracy:17.52399536106809 validation accuracy:15.340273671762036\n",
      "For max_depth:5,n_estimators:60,learning_rate:0.1\n",
      "            train accuracy:6.181793723503085 validation accuracy:7.259161033841803\n",
      "For max_depth:5,n_estimators:60,learning_rate:1\n",
      "            train accuracy:4.272197715258773 validation accuracy:28.029628095008082\n",
      "For max_depth:5,n_estimators:75,learning_rate:0.01\n",
      "            train accuracy:15.058040578042396 validation accuracy:13.162844985264456\n",
      "For max_depth:5,n_estimators:75,learning_rate:0.1\n",
      "            train accuracy:5.9362929386697365 validation accuracy:7.434358209863655\n",
      "For max_depth:5,n_estimators:75,learning_rate:1\n",
      "            train accuracy:4.042309146235322 validation accuracy:27.46052451069879\n",
      "For max_depth:5,n_estimators:100,learning_rate:0.01\n",
      "            train accuracy:12.217414619367837 validation accuracy:10.687277363526096\n",
      "For max_depth:5,n_estimators:100,learning_rate:0.1\n",
      "            train accuracy:5.709591701862106 validation accuracy:7.525059674650443\n",
      "For max_depth:5,n_estimators:100,learning_rate:1\n",
      "            train accuracy:3.7807760467020124 validation accuracy:25.568687037018442\n",
      "For max_depth:5,n_estimators:125,learning_rate:0.01\n",
      "            train accuracy:10.423156882160708 validation accuracy:9.216951288855967\n",
      "For max_depth:5,n_estimators:125,learning_rate:0.1\n",
      "            train accuracy:5.483335321597568 validation accuracy:7.677269950315682\n",
      "For max_depth:5,n_estimators:125,learning_rate:1\n",
      "            train accuracy:3.5261281255592496 validation accuracy:26.86333268316202\n",
      "For max_depth:7,n_estimators:5,learning_rate:0.01\n",
      "            train accuracy:36.04160364698999 validation accuracy:32.31119733033948\n",
      "For max_depth:7,n_estimators:5,learning_rate:0.1\n",
      "            train accuracy:18.292551198688123 validation accuracy:16.80588581732834\n",
      "For max_depth:7,n_estimators:5,learning_rate:1\n",
      "            train accuracy:5.672889895078722 validation accuracy:10.236626185185234\n",
      "For max_depth:7,n_estimators:10,learning_rate:0.01\n",
      "            train accuracy:33.3024799493666 validation accuracy:29.810437908323916\n",
      "For max_depth:7,n_estimators:10,learning_rate:0.1\n",
      "            train accuracy:10.716862190683532 validation accuracy:10.631069912798882\n",
      "For max_depth:7,n_estimators:10,learning_rate:1\n",
      "            train accuracy:4.757636300101311 validation accuracy:21.758971825382957\n",
      "For max_depth:7,n_estimators:15,learning_rate:0.01\n",
      "            train accuracy:30.821987746843636 validation accuracy:27.60082256088984\n",
      "For max_depth:7,n_estimators:15,learning_rate:0.1\n",
      "            train accuracy:7.785822453678407 validation accuracy:8.285892546546958\n",
      "For max_depth:7,n_estimators:15,learning_rate:1\n",
      "            train accuracy:4.340432563231448 validation accuracy:23.648770402881542\n",
      "For max_depth:7,n_estimators:25,learning_rate:0.01\n",
      "            train accuracy:26.543587192743512 validation accuracy:23.838800202016543\n",
      "For max_depth:7,n_estimators:25,learning_rate:0.1\n",
      "            train accuracy:5.937873419865919 validation accuracy:7.01444878242439\n",
      "For max_depth:7,n_estimators:25,learning_rate:1\n",
      "            train accuracy:3.8114468991491206 validation accuracy:21.863601474573233\n",
      "For max_depth:7,n_estimators:50,learning_rate:0.01\n",
      "            train accuracy:18.838144843876393 validation accuracy:17.426392300851955\n",
      "For max_depth:7,n_estimators:50,learning_rate:0.1\n",
      "            train accuracy:4.854271418183686 validation accuracy:7.023940190922021\n",
      "For max_depth:7,n_estimators:50,learning_rate:1\n",
      "            train accuracy:3.0839187628013263 validation accuracy:22.72464724635803\n",
      "For max_depth:7,n_estimators:60,learning_rate:0.01\n",
      "            train accuracy:16.656153314928872 validation accuracy:15.660177725865879\n",
      "For max_depth:7,n_estimators:60,learning_rate:0.1\n",
      "            train accuracy:4.696837516621953 validation accuracy:7.1994764371945\n",
      "For max_depth:7,n_estimators:60,learning_rate:1\n",
      "            train accuracy:2.9143673100798018 validation accuracy:23.28222568790734\n",
      "For max_depth:7,n_estimators:75,learning_rate:0.01\n",
      "            train accuracy:14.071792759112338 validation accuracy:13.576600703453872\n",
      "For max_depth:7,n_estimators:75,learning_rate:0.1\n",
      "            train accuracy:4.439674321648379 validation accuracy:7.346564446405063\n",
      "For max_depth:7,n_estimators:75,learning_rate:1\n",
      "            train accuracy:2.768367839152065 validation accuracy:25.72547858131716\n",
      "For max_depth:7,n_estimators:100,learning_rate:0.01\n",
      "            train accuracy:11.115551244356642 validation accuracy:11.167447478401044\n",
      "For max_depth:7,n_estimators:100,learning_rate:0.1\n",
      "            train accuracy:4.1694743627552375 validation accuracy:7.535352295887553\n",
      "For max_depth:7,n_estimators:100,learning_rate:1\n",
      "            train accuracy:2.572161584805344 validation accuracy:26.887057571695962\n",
      "For max_depth:7,n_estimators:125,learning_rate:0.01\n",
      "            train accuracy:9.239353186955622 validation accuracy:9.642833825737108\n",
      "For max_depth:7,n_estimators:125,learning_rate:0.1\n",
      "            train accuracy:3.970112378329399 validation accuracy:7.738631330741004\n",
      "For max_depth:7,n_estimators:125,learning_rate:1\n",
      "            train accuracy:2.4189676171420635 validation accuracy:27.21646769092659\n",
      "For max_depth:8,n_estimators:5,learning_rate:0.01\n",
      "            train accuracy:35.98444274519823 validation accuracy:32.26261418773923\n",
      "For max_depth:8,n_estimators:5,learning_rate:0.1\n",
      "            train accuracy:17.912585989826425 validation accuracy:16.831885194074076\n",
      "For max_depth:8,n_estimators:5,learning_rate:1\n",
      "            train accuracy:4.983428147333555 validation accuracy:9.753215387395644\n",
      "For max_depth:8,n_estimators:10,learning_rate:0.01\n",
      "            train accuracy:33.1905037822383 validation accuracy:29.716855991697788\n",
      "For max_depth:8,n_estimators:10,learning_rate:0.1\n",
      "            train accuracy:10.206407590092718 validation accuracy:10.920052341385672\n",
      "For max_depth:8,n_estimators:10,learning_rate:1\n",
      "            train accuracy:4.105992200287374 validation accuracy:11.583677364485709\n",
      "For max_depth:8,n_estimators:15,learning_rate:0.01\n",
      "            train accuracy:30.65920759972236 validation accuracy:27.465692442102704\n",
      "For max_depth:8,n_estimators:15,learning_rate:0.1\n",
      "            train accuracy:7.2255315136588685 validation accuracy:8.596500069529537\n",
      "For max_depth:8,n_estimators:15,learning_rate:1\n",
      "            train accuracy:3.6352475857344904 validation accuracy:12.542363004197723\n",
      "For max_depth:8,n_estimators:25,learning_rate:0.01\n",
      "            train accuracy:26.298282920480617 validation accuracy:23.677945077592007\n",
      "For max_depth:8,n_estimators:25,learning_rate:0.1\n",
      "            train accuracy:5.280322967222079 validation accuracy:7.398071225340328\n",
      "For max_depth:8,n_estimators:25,learning_rate:1\n",
      "            train accuracy:3.1102171473781848 validation accuracy:14.088039513017092\n",
      "For max_depth:8,n_estimators:50,learning_rate:0.01\n",
      "            train accuracy:18.45584375516076 validation accuracy:17.08505232864678\n",
      "For max_depth:8,n_estimators:50,learning_rate:0.1\n",
      "            train accuracy:4.222801078096403 validation accuracy:7.318192755413482\n",
      "For max_depth:8,n_estimators:50,learning_rate:1\n",
      "            train accuracy:2.5618287387407412 validation accuracy:15.306742128346192\n",
      "For max_depth:8,n_estimators:60,learning_rate:0.01\n",
      "            train accuracy:16.23670510252124 validation accuracy:15.353649503970518\n",
      "For max_depth:8,n_estimators:60,learning_rate:0.1\n",
      "            train accuracy:3.9931362765494027 validation accuracy:7.4263084259631755\n",
      "For max_depth:8,n_estimators:60,learning_rate:1\n",
      "            train accuracy:2.424880382729877 validation accuracy:15.542280617280463\n",
      "For max_depth:8,n_estimators:75,learning_rate:0.01\n",
      "            train accuracy:13.61231572152787 validation accuracy:13.347166051917474\n",
      "For max_depth:8,n_estimators:75,learning_rate:0.1\n",
      "            train accuracy:3.801752930026063 validation accuracy:7.631169495480355\n",
      "For max_depth:8,n_estimators:75,learning_rate:1\n",
      "            train accuracy:2.2871953307877475 validation accuracy:15.91418889448171\n",
      "For max_depth:8,n_estimators:100,learning_rate:0.01\n",
      "            train accuracy:10.573043616689352 validation accuracy:11.02109099732476\n",
      "For max_depth:8,n_estimators:100,learning_rate:0.1\n",
      "            train accuracy:3.5241883986518503 validation accuracy:7.792925888024522\n",
      "For max_depth:8,n_estimators:100,learning_rate:1\n",
      "            train accuracy:2.11676129011383 validation accuracy:16.251551795324232\n",
      "For max_depth:8,n_estimators:125,learning_rate:0.01\n",
      "            train accuracy:8.648560806418907 validation accuracy:9.552994152773856\n",
      "For max_depth:8,n_estimators:125,learning_rate:0.1\n",
      "            train accuracy:3.306812213851343 validation accuracy:7.931169237097267\n",
      "For max_depth:8,n_estimators:125,learning_rate:1\n",
      "            train accuracy:1.9761561597176396 validation accuracy:16.684084681234637\n",
      "For max_depth:9,n_estimators:5,learning_rate:0.01\n",
      "            train accuracy:35.92642197793301 validation accuracy:32.29748024410378\n",
      "For max_depth:9,n_estimators:5,learning_rate:0.1\n",
      "            train accuracy:17.558822764985052 validation accuracy:16.653975804431273\n",
      "For max_depth:9,n_estimators:5,learning_rate:1\n",
      "            train accuracy:4.097064936425996 validation accuracy:12.528920292872352\n",
      "For max_depth:9,n_estimators:10,learning_rate:0.01\n",
      "            train accuracy:33.08311772073608 validation accuracy:29.789689473935773\n",
      "For max_depth:9,n_estimators:10,learning_rate:0.1\n",
      "            train accuracy:9.685627573216465 validation accuracy:10.599956247511171\n",
      "For max_depth:9,n_estimators:10,learning_rate:1\n",
      "            train accuracy:3.3959612436096207 validation accuracy:14.04590685147264\n",
      "For max_depth:9,n_estimators:15,learning_rate:0.01\n",
      "            train accuracy:30.508557181037656 validation accuracy:27.54296021552352\n",
      "For max_depth:9,n_estimators:15,learning_rate:0.1\n",
      "            train accuracy:6.637307901347358 validation accuracy:8.411726500694813\n",
      "For max_depth:9,n_estimators:15,learning_rate:1\n",
      "            train accuracy:2.988904753241394 validation accuracy:15.876466535444646\n",
      "For max_depth:9,n_estimators:25,learning_rate:0.01\n",
      "            train accuracy:26.06363946242815 validation accuracy:23.677861828320328\n",
      "For max_depth:9,n_estimators:25,learning_rate:0.1\n",
      "            train accuracy:4.709406541714363 validation accuracy:7.185434074135138\n",
      "For max_depth:9,n_estimators:25,learning_rate:1\n",
      "            train accuracy:2.5964069003020787 validation accuracy:19.11603796001281\n",
      "For max_depth:9,n_estimators:50,learning_rate:0.01\n",
      "            train accuracy:18.11734920664966 validation accuracy:17.0517907940335\n",
      "For max_depth:9,n_estimators:50,learning_rate:0.1\n",
      "            train accuracy:3.603470408027309 validation accuracy:7.166018629375619\n",
      "For max_depth:9,n_estimators:50,learning_rate:1\n",
      "            train accuracy:2.162022269264123 validation accuracy:20.59846912411666\n",
      "For max_depth:9,n_estimators:60,learning_rate:0.01\n",
      "            train accuracy:15.859987095274967 validation accuracy:15.231811451930646\n",
      "For max_depth:9,n_estimators:60,learning_rate:0.1\n",
      "            train accuracy:3.410309434730039 validation accuracy:6.8825533821929\n",
      "For max_depth:9,n_estimators:60,learning_rate:1\n",
      "            train accuracy:2.0585638564457573 validation accuracy:20.819760918497387\n",
      "For max_depth:9,n_estimators:75,learning_rate:0.01\n",
      "            train accuracy:13.190437623330897 validation accuracy:13.101788178945307\n",
      "For max_depth:9,n_estimators:75,learning_rate:0.1\n",
      "            train accuracy:3.2221078572436976 validation accuracy:6.949967079503761\n",
      "For max_depth:9,n_estimators:75,learning_rate:1\n",
      "            train accuracy:1.9114245144513249 validation accuracy:19.503982014258778\n",
      "For max_depth:9,n_estimators:100,learning_rate:0.01\n",
      "            train accuracy:10.094074527101029 validation accuracy:10.832698281526316\n",
      "For max_depth:9,n_estimators:100,learning_rate:0.1\n",
      "            train accuracy:2.9724953667732894 validation accuracy:7.222963998035073\n",
      "For max_depth:9,n_estimators:100,learning_rate:1\n",
      "            train accuracy:1.7648442209327186 validation accuracy:19.73059600114042\n",
      "For max_depth:9,n_estimators:125,learning_rate:0.01\n",
      "            train accuracy:8.14207588195185 validation accuracy:9.482063144257022\n",
      "For max_depth:9,n_estimators:125,learning_rate:0.1\n",
      "            train accuracy:2.766165722417948 validation accuracy:7.355748470805075\n",
      "For max_depth:9,n_estimators:125,learning_rate:1\n",
      "            train accuracy:1.6408572499466672 validation accuracy:19.838108513258877\n",
      "For max_depth:10,n_estimators:5,learning_rate:0.01\n",
      "            train accuracy:35.87327759649704 validation accuracy:32.31666133390657\n",
      "For max_depth:10,n_estimators:5,learning_rate:0.1\n",
      "            train accuracy:17.197723118796496 validation accuracy:16.564309075840967\n",
      "For max_depth:10,n_estimators:5,learning_rate:1\n",
      "            train accuracy:3.8357959178361427 validation accuracy:12.374310224367967\n",
      "For max_depth:10,n_estimators:10,learning_rate:0.01\n",
      "            train accuracy:32.98041760955899 validation accuracy:29.795740056054868\n",
      "For max_depth:10,n_estimators:10,learning_rate:0.1\n",
      "            train accuracy:9.182616151426794 validation accuracy:10.588099807380186\n",
      "For max_depth:10,n_estimators:10,learning_rate:1\n",
      "            train accuracy:2.945644647195927 validation accuracy:13.958366312986065\n",
      "For max_depth:10,n_estimators:15,learning_rate:0.01\n",
      "            train accuracy:30.363987909142832 validation accuracy:27.554063202044166\n",
      "For max_depth:10,n_estimators:15,learning_rate:0.1\n",
      "            train accuracy:6.112430666264628 validation accuracy:8.518578617232212\n",
      "For max_depth:10,n_estimators:15,learning_rate:1\n",
      "            train accuracy:2.5685363122684355 validation accuracy:15.42743001899748\n",
      "For max_depth:10,n_estimators:25,learning_rate:0.01\n",
      "            train accuracy:25.84428278255864 validation accuracy:23.74058939641473\n",
      "For max_depth:10,n_estimators:25,learning_rate:0.1\n",
      "            train accuracy:4.170203780463453 validation accuracy:7.457371709452159\n",
      "For max_depth:10,n_estimators:25,learning_rate:1\n",
      "            train accuracy:2.2385545310187043 validation accuracy:16.487516432343707\n",
      "For max_depth:10,n_estimators:50,learning_rate:0.01\n",
      "            train accuracy:17.762953922556186 validation accuracy:17.093239050947528\n",
      "For max_depth:10,n_estimators:50,learning_rate:0.1\n",
      "            train accuracy:3.088371245533737 validation accuracy:7.2679557288794285\n",
      "For max_depth:10,n_estimators:50,learning_rate:1\n",
      "            train accuracy:1.8165896162646031 validation accuracy:17.239585813401295\n",
      "For max_depth:10,n_estimators:60,learning_rate:0.01\n",
      "            train accuracy:15.473820698305515 validation accuracy:15.274503478382753\n",
      "For max_depth:10,n_estimators:60,learning_rate:0.1\n",
      "            train accuracy:2.91894262456308 validation accuracy:7.224595727402475\n",
      "For max_depth:10,n_estimators:60,learning_rate:1\n",
      "            train accuracy:1.7286992903434408 validation accuracy:17.357023335607437\n",
      "For max_depth:10,n_estimators:75,learning_rate:0.01\n",
      "            train accuracy:12.77494902047996 validation accuracy:13.225775864384147\n",
      "For max_depth:10,n_estimators:75,learning_rate:0.1\n",
      "            train accuracy:2.762624905032678 validation accuracy:7.338539290432109\n",
      "For max_depth:10,n_estimators:75,learning_rate:1\n",
      "            train accuracy:1.600929755475066 validation accuracy:18.543162592190175\n",
      "For max_depth:10,n_estimators:100,learning_rate:0.01\n",
      "            train accuracy:9.626811761574723 validation accuracy:11.063829646147378\n",
      "For max_depth:10,n_estimators:100,learning_rate:0.1\n",
      "            train accuracy:2.539571799822059 validation accuracy:7.3753026918194164\n",
      "For max_depth:10,n_estimators:100,learning_rate:1\n",
      "            train accuracy:1.4535877057203694 validation accuracy:19.26497332427314\n",
      "For max_depth:10,n_estimators:125,learning_rate:0.01\n",
      "            train accuracy:7.640384569403416 validation accuracy:9.791810849740868\n",
      "For max_depth:10,n_estimators:125,learning_rate:0.1\n",
      "            train accuracy:2.3629661018502186 validation accuracy:7.364861588102104\n",
      "For max_depth:10,n_estimators:125,learning_rate:1\n",
      "            train accuracy:1.3562677054897838 validation accuracy:19.972989287330773\n",
      "For max_depth:15,n_estimators:5,learning_rate:0.01\n",
      "            train accuracy:35.65530966564313 validation accuracy:32.32649561678775\n",
      "For max_depth:15,n_estimators:5,learning_rate:0.1\n",
      "            train accuracy:15.751363431590997 validation accuracy:16.833901432358655\n",
      "For max_depth:15,n_estimators:5,learning_rate:1\n",
      "            train accuracy:1.9696626749386055 validation accuracy:14.387090434794775\n",
      "For max_depth:15,n_estimators:10,learning_rate:0.01\n",
      "            train accuracy:32.5686946443256 validation accuracy:29.84556892017337\n",
      "For max_depth:15,n_estimators:10,learning_rate:0.1\n",
      "            train accuracy:7.425658620341197 validation accuracy:10.965624682938115\n",
      "For max_depth:15,n_estimators:10,learning_rate:1\n",
      "            train accuracy:1.5016873484333335 validation accuracy:15.001124090567702\n",
      "For max_depth:15,n_estimators:15,learning_rate:0.01\n",
      "            train accuracy:29.77537852290882 validation accuracy:27.62739244731817\n",
      "For max_depth:15,n_estimators:15,learning_rate:0.1\n",
      "            train accuracy:4.29257483208135 validation accuracy:9.403374206924179\n",
      "For max_depth:15,n_estimators:15,learning_rate:1\n",
      "            train accuracy:1.306122093290732 validation accuracy:15.121629427509529\n",
      "For max_depth:15,n_estimators:25,learning_rate:0.01\n",
      "            train accuracy:24.958764106178837 validation accuracy:23.83298620877539\n",
      "For max_depth:15,n_estimators:25,learning_rate:0.1\n",
      "            train accuracy:2.46667709881476 validation accuracy:9.036058819350494\n",
      "For max_depth:15,n_estimators:25,learning_rate:1\n",
      "            train accuracy:1.0723095889110863 validation accuracy:15.214860941778843\n",
      "For max_depth:15,n_estimators:50,learning_rate:0.01\n",
      "            train accuracy:16.36830199360857 validation accuracy:17.215340446795267\n",
      "For max_depth:15,n_estimators:50,learning_rate:0.1\n",
      "            train accuracy:1.653750220371944 validation accuracy:9.22377954026732\n",
      "For max_depth:15,n_estimators:50,learning_rate:1\n",
      "            train accuracy:0.9115847419232835 validation accuracy:15.39571791177363\n",
      "For max_depth:15,n_estimators:60,learning_rate:0.01\n",
      "            train accuracy:13.95570552820302 validation accuracy:15.438191658799024\n",
      "For max_depth:15,n_estimators:60,learning_rate:0.1\n",
      "            train accuracy:1.5264533824585682 validation accuracy:9.235037547074887\n",
      "For max_depth:15,n_estimators:60,learning_rate:1\n",
      "            train accuracy:0.8929490284064552 validation accuracy:15.361022638823899\n",
      "For max_depth:15,n_estimators:75,learning_rate:0.01\n",
      "            train accuracy:11.123762246624086 validation accuracy:13.406784457752495\n",
      "For max_depth:15,n_estimators:75,learning_rate:0.1\n",
      "            train accuracy:1.4164138377003797 validation accuracy:9.311554363459413\n",
      "For max_depth:15,n_estimators:75,learning_rate:1\n",
      "            train accuracy:0.8804544825983696 validation accuracy:15.3828646630242\n",
      "For max_depth:15,n_estimators:100,learning_rate:0.01\n",
      "            train accuracy:7.8723849176751015 validation accuracy:11.248252925887263\n",
      "For max_depth:15,n_estimators:100,learning_rate:0.1\n",
      "            train accuracy:1.2885045999502864 validation accuracy:9.415657664435825\n",
      "For max_depth:15,n_estimators:100,learning_rate:1\n",
      "            train accuracy:0.8706498393385745 validation accuracy:15.37481485354752\n",
      "For max_depth:15,n_estimators:125,learning_rate:0.01\n",
      "            train accuracy:5.845387022317873 validation accuracy:10.169614715135635\n",
      "For max_depth:15,n_estimators:125,learning_rate:0.1\n",
      "            train accuracy:1.1969287982395267 validation accuracy:9.467258648374576\n",
      "For max_depth:15,n_estimators:125,learning_rate:1\n",
      "            train accuracy:0.8670354951085573 validation accuracy:15.377097933508566\n"
     ]
    }
   ],
   "source": [
    "list1=[]\n",
    "depth = [5,7,8,9,10,15]\n",
    "features= [5,10,15,25,50,60,75,100,125]\n",
    "min_samples_s = [0.01,0.1,1]\n",
    "for j in depth:\n",
    "    for k in features:\n",
    "        for l in min_samples_s:\n",
    "            xgb = XGBRegressor(n_estimators=k, learning_rate= l , max_depth=j, random_state=32)\n",
    "            xgb.fit(x_train, y_train)\n",
    "            y_train_pred = xgb.predict(x_train)\n",
    "            train_accuracy = mean_squared_error(y_train, y_train_pred)\n",
    "            y_val_pred = xgb.predict(x_val)\n",
    "            val_accuracy = mean_squared_error(y_val, y_val_pred)\n",
    "            list1.append((j,k,l,train_accuracy,val_accuracy))\n",
    "            print(f'''For max_depth:{j},n_estimators:{k},learning_rate:{l}\n",
    "            train accuracy:{train_accuracy} validation accuracy:{val_accuracy}''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[36.15103485361481, 19.08711207312206, 6.7528844586755765, 33.51188379734885, 11.808232135630869, 6.12296730091129, 31.125087565360914, 9.047493361833174, 5.81366467706509, 27.00991267963088, 7.341527812118083, 5.1392859192451725, 19.614326405050956, 6.319994548698917, 4.45855607563335, 17.52399536106809, 6.181793723503085, 4.272197715258773, 15.058040578042396, 5.9362929386697365, 4.042309146235322, 12.217414619367837, 5.709591701862106, 3.7807760467020124, 10.423156882160708, 5.483335321597568, 3.5261281255592496, 36.04160364698999, 18.292551198688123, 5.672889895078722, 33.3024799493666, 10.716862190683532, 4.757636300101311, 30.821987746843636, 7.785822453678407, 4.340432563231448, 26.543587192743512, 5.937873419865919, 3.8114468991491206, 18.838144843876393, 4.854271418183686, 3.0839187628013263, 16.656153314928872, 4.696837516621953, 2.9143673100798018, 14.071792759112338, 4.439674321648379, 2.768367839152065, 11.115551244356642, 4.1694743627552375, 2.572161584805344, 9.239353186955622, 3.970112378329399, 2.4189676171420635, 35.98444274519823, 17.912585989826425, 4.983428147333555, 33.1905037822383, 10.206407590092718, 4.105992200287374, 30.65920759972236, 7.2255315136588685, 3.6352475857344904, 26.298282920480617, 5.280322967222079, 3.1102171473781848, 18.45584375516076, 4.222801078096403, 2.5618287387407412, 16.23670510252124, 3.9931362765494027, 2.424880382729877, 13.61231572152787, 3.801752930026063, 2.2871953307877475, 10.573043616689352, 3.5241883986518503, 2.11676129011383, 8.648560806418907, 3.306812213851343, 1.9761561597176396, 35.92642197793301, 17.558822764985052, 4.097064936425996, 33.08311772073608, 9.685627573216465, 3.3959612436096207, 30.508557181037656, 6.637307901347358, 2.988904753241394, 26.06363946242815, 4.709406541714363, 2.5964069003020787, 18.11734920664966, 3.603470408027309, 2.162022269264123, 15.859987095274967, 3.410309434730039, 2.0585638564457573, 13.190437623330897, 3.2221078572436976, 1.9114245144513249, 10.094074527101029, 2.9724953667732894, 1.7648442209327186, 8.14207588195185, 2.766165722417948, 1.6408572499466672, 35.87327759649704, 17.197723118796496, 3.8357959178361427, 32.98041760955899, 9.182616151426794, 2.945644647195927, 30.363987909142832, 6.112430666264628, 2.5685363122684355, 25.84428278255864, 4.170203780463453, 2.2385545310187043, 17.762953922556186, 3.088371245533737, 1.8165896162646031, 15.473820698305515, 2.91894262456308, 1.7286992903434408, 12.77494902047996, 2.762624905032678, 1.600929755475066, 9.626811761574723, 2.539571799822059, 1.4535877057203694, 7.640384569403416, 2.3629661018502186, 1.3562677054897838, 35.65530966564313, 15.751363431590997, 1.9696626749386055, 32.5686946443256, 7.425658620341197, 1.5016873484333335, 29.77537852290882, 4.29257483208135, 1.306122093290732, 24.958764106178837, 2.46667709881476, 1.0723095889110863, 16.36830199360857, 1.653750220371944, 0.9115847419232835, 13.95570552820302, 1.5264533824585682, 0.8929490284064552, 11.123762246624086, 1.4164138377003797, 0.8804544825983696, 7.8723849176751015, 1.2885045999502864, 0.8706498393385745, 5.845387022317873, 1.1969287982395267, 0.8670354951085573]\n",
      "[32.40595076367675, 16.653298966043064, 10.637303294432842, 29.951519474768308, 10.251799316210134, 10.612837626682524, 27.75289071754342, 8.160551660282728, 13.185082241887327, 23.955900334579017, 7.06324660253249, 16.462142247888963, 17.21538306200086, 7.114264055583997, 26.54799188437628, 15.340273671762036, 7.259161033841803, 28.029628095008082, 13.162844985264456, 7.434358209863655, 27.46052451069879, 10.687277363526096, 7.525059674650443, 25.568687037018442, 9.216951288855967, 7.677269950315682, 26.86333268316202, 32.31119733033948, 16.80588581732834, 10.236626185185234, 29.810437908323916, 10.631069912798882, 21.758971825382957, 27.60082256088984, 8.285892546546958, 23.648770402881542, 23.838800202016543, 7.01444878242439, 21.863601474573233, 17.426392300851955, 7.023940190922021, 22.72464724635803, 15.660177725865879, 7.1994764371945, 23.28222568790734, 13.576600703453872, 7.346564446405063, 25.72547858131716, 11.167447478401044, 7.535352295887553, 26.887057571695962, 9.642833825737108, 7.738631330741004, 27.21646769092659, 32.26261418773923, 16.831885194074076, 9.753215387395644, 29.716855991697788, 10.920052341385672, 11.583677364485709, 27.465692442102704, 8.596500069529537, 12.542363004197723, 23.677945077592007, 7.398071225340328, 14.088039513017092, 17.08505232864678, 7.318192755413482, 15.306742128346192, 15.353649503970518, 7.4263084259631755, 15.542280617280463, 13.347166051917474, 7.631169495480355, 15.91418889448171, 11.02109099732476, 7.792925888024522, 16.251551795324232, 9.552994152773856, 7.931169237097267, 16.684084681234637, 32.29748024410378, 16.653975804431273, 12.528920292872352, 29.789689473935773, 10.599956247511171, 14.04590685147264, 27.54296021552352, 8.411726500694813, 15.876466535444646, 23.677861828320328, 7.185434074135138, 19.11603796001281, 17.0517907940335, 7.166018629375619, 20.59846912411666, 15.231811451930646, 6.8825533821929, 20.819760918497387, 13.101788178945307, 6.949967079503761, 19.503982014258778, 10.832698281526316, 7.222963998035073, 19.73059600114042, 9.482063144257022, 7.355748470805075, 19.838108513258877, 32.31666133390657, 16.564309075840967, 12.374310224367967, 29.795740056054868, 10.588099807380186, 13.958366312986065, 27.554063202044166, 8.518578617232212, 15.42743001899748, 23.74058939641473, 7.457371709452159, 16.487516432343707, 17.093239050947528, 7.2679557288794285, 17.239585813401295, 15.274503478382753, 7.224595727402475, 17.357023335607437, 13.225775864384147, 7.338539290432109, 18.543162592190175, 11.063829646147378, 7.3753026918194164, 19.26497332427314, 9.791810849740868, 7.364861588102104, 19.972989287330773, 32.32649561678775, 16.833901432358655, 14.387090434794775, 29.84556892017337, 10.965624682938115, 15.001124090567702, 27.62739244731817, 9.403374206924179, 15.121629427509529, 23.83298620877539, 9.036058819350494, 15.214860941778843, 17.215340446795267, 9.22377954026732, 15.39571791177363, 15.438191658799024, 9.235037547074887, 15.361022638823899, 13.406784457752495, 9.311554363459413, 15.3828646630242, 11.248252925887263, 9.415657664435825, 15.37481485354752, 10.169614715135635, 9.467258648374576, 15.377097933508566]\n"
     ]
    }
   ],
   "source": [
    "all_train_acc=[list1[i][3] for i in range(len(list1))]\n",
    "all_val_acc=[list1[i][4] for i in range(len(list1))]\n",
    "print(all_train_acc)\n",
    "print(all_val_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[6.8825533821929,\n",
       " 6.949967079503761,\n",
       " 7.01444878242439,\n",
       " 7.023940190922021,\n",
       " 7.06324660253249,\n",
       " 7.114264055583997,\n",
       " 7.166018629375619,\n",
       " 7.185434074135138,\n",
       " 7.1994764371945,\n",
       " 7.222963998035073]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import heapq\n",
    "max_5_val_acc = heapq.nsmallest(10, all_val_acc)\n",
    "max_5_val_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9, 60, 0.1, 3.410309434730039, 6.8825533821929)\n",
      "(9, 75, 0.1, 3.2221078572436976, 6.949967079503761)\n",
      "(7, 25, 0.1, 5.937873419865919, 7.01444878242439)\n",
      "(7, 50, 0.1, 4.854271418183686, 7.023940190922021)\n",
      "(5, 25, 0.1, 7.341527812118083, 7.06324660253249)\n",
      "(5, 50, 0.1, 6.319994548698917, 7.114264055583997)\n",
      "(9, 50, 0.1, 3.603470408027309, 7.166018629375619)\n",
      "(9, 25, 0.1, 4.709406541714363, 7.185434074135138)\n",
      "(7, 60, 0.1, 4.696837516621953, 7.1994764371945)\n",
      "(9, 100, 0.1, 2.9724953667732894, 7.222963998035073)\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(max_5_val_acc)):\n",
    "    print(list1[all_val_acc.index(max_5_val_acc[i])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error (MSE) on training data: 3.410309434730039\n",
      "Mean Squared Error (MSE) on test data: 6.8825533821929\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBRegressor\n",
    "xgb = XGBRegressor(n_estimators=60, learning_rate=0.1, max_depth=9, random_state=0)\n",
    "xgb.fit(x_train, y_train)\n",
    "y_train_pred = xgb.predict(x_train)\n",
    "mse = mean_squared_error(y_train, y_train_pred)\n",
    "print(f\"Mean Squared Error (MSE) on training data: {mse}\")\n",
    "y_val_pred = xgb.predict(x_val)\n",
    "mse1 = mean_squared_error(y_val, y_val_pred)\n",
    "print(f\"Mean Squared Error (MSE) on test data: {mse1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred = xgb.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df = pd.DataFrame({\n",
    "    'position': y_test_pred,\n",
    "    'result_driver_standing': test_data[\"result_driver_standing\"]\n",
    "})\n",
    "result_df.to_csv('submission_file_xgb.csv', index=False, header=['position', 'result_driver_standing'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Catboost Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from catboost import CatBoostRegressor\n",
    "estim = [100,200,250,300,350,400,450,500]\n",
    "train_result=[]\n",
    "val_result=[]\n",
    "for i in estim:\n",
    "    catboost = CatBoostRegressor(iterations= i, learning_rate=0.1, depth=3, random_state=0, silent=True)\n",
    "    catboost.fit(x_train, y_train)\n",
    "    y_train_pred = catboost.predict(x_train)\n",
    "    train_result.append(mean_squared_error(y_train, y_train_pred))\n",
    "    y_val_pred = catboost.predict(x_val)\n",
    "    val_result.append(mean_squared_error(y_val, y_val_pred))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "plt.plot(estim,train_result, marker='o', linestyle='-')\n",
    "plt.plot(estim,val_result, marker='o', linestyle='-')\n",
    "plt.xlabel(\"iterations\")\n",
    "plt.ylabel('MSE')\n",
    "plt.title('Number Of Iterations')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[7.634794630684779,\n",
       " 7.505249844436526,\n",
       " 7.443169174301169,\n",
       " 7.385842990294807,\n",
       " 7.383805518699819,\n",
       " 7.371177759969147,\n",
       " 7.354565321368992,\n",
       " 7.428599897824319]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "5\n",
      "9\n",
      "10\n",
      "15\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "estim = [2,5,9,10,15]\n",
    "train_result=[]\n",
    "val_result=[]\n",
    "for i in estim:\n",
    "    print(i)\n",
    "    catboost = CatBoostRegressor(iterations= 450, learning_rate=0.1, depth= i, random_state=0, silent=True)\n",
    "    catboost.fit(x_train, y_train)\n",
    "    y_train_pred = catboost.predict(x_train)\n",
    "    train_result.append(mean_squared_error(y_train, y_train_pred))\n",
    "    y_val_pred = catboost.predict(x_val)\n",
    "    val_result.append(mean_squared_error(y_val, y_val_pred))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "plt.plot(estim,train_result, marker='o', linestyle='-')\n",
    "plt.plot(estim,val_result, marker='o', linestyle='-')\n",
    "plt.xlabel(\"depth\")\n",
    "plt.ylabel('MSE')\n",
    "plt.title('Depth')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.01\n",
      "0.1\n",
      "1\n",
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "learning rate is greater than 1. You probably need to decrease learning rate.\n",
      "learning rate is greater than 1. You probably need to decrease learning rate.\n",
      "learning rate is greater than 1. You probably need to decrease learning rate.\n",
      "learning rate is greater than 1. You probably need to decrease learning rate.\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "estim = [0.01,0.1,1,2]\n",
    "train_result=[]\n",
    "val_result=[]\n",
    "for i in estim:\n",
    "    print(i)\n",
    "    catboost = CatBoostRegressor(iterations= 450, learning_rate= i, depth= 9, random_state=0, silent=True)\n",
    "    catboost.fit(x_train, y_train)\n",
    "    y_train_pred = catboost.predict(x_train)\n",
    "    train_result.append(mean_squared_error(y_train, y_train_pred))\n",
    "    y_val_pred = catboost.predict(x_val)\n",
    "    val_result.append(mean_squared_error(y_val, y_val_pred))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "plt.plot(estim,train_result, marker='o', linestyle='-')\n",
    "plt.plot(estim,val_result, marker='o', linestyle='-')\n",
    "plt.xlabel(\"depth\")\n",
    "plt.ylabel('MSE')\n",
    "plt.title('Depth')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For depth:5,iterations:400,learning_rate:0.01\n",
      "            train accuracy:7.908393303969475 validation accuracy:7.447204930735394\n",
      "For depth:5,iterations:400,learning_rate:0.1\n",
      "            train accuracy:5.4087958095041655 validation accuracy:7.271310469815163\n",
      "For depth:5,iterations:425,learning_rate:0.01\n",
      "            train accuracy:7.835820508264683 validation accuracy:7.40706059520954\n",
      "For depth:5,iterations:425,learning_rate:0.1\n",
      "            train accuracy:5.347731590942943 validation accuracy:7.335644829720593\n",
      "For depth:5,iterations:450,learning_rate:0.01\n",
      "            train accuracy:7.771857097557855 validation accuracy:7.36952828918554\n",
      "For depth:5,iterations:450,learning_rate:0.1\n",
      "            train accuracy:5.290308010379564 validation accuracy:7.3134326292825875\n",
      "For depth:7,iterations:400,learning_rate:0.01\n",
      "            train accuracy:7.130662046210351 validation accuracy:7.331975204264542\n",
      "For depth:7,iterations:400,learning_rate:0.1\n",
      "            train accuracy:4.4481459156611 validation accuracy:7.204658075392891\n",
      "For depth:7,iterations:425,learning_rate:0.01\n",
      "            train accuracy:7.05955254136426 validation accuracy:7.2735075765936354\n",
      "For depth:7,iterations:425,learning_rate:0.1\n",
      "            train accuracy:4.379376333286357 validation accuracy:7.266870142530666\n",
      "For depth:7,iterations:450,learning_rate:0.01\n",
      "            train accuracy:6.992444077829767 validation accuracy:7.251898673859386\n",
      "For depth:7,iterations:450,learning_rate:0.1\n",
      "            train accuracy:4.311796087238251 validation accuracy:7.271726567603457\n",
      "For depth:9,iterations:400,learning_rate:0.01\n",
      "            train accuracy:6.367381672857858 validation accuracy:7.402796954993391\n",
      "For depth:9,iterations:400,learning_rate:0.1\n",
      "            train accuracy:3.6958579202126867 validation accuracy:6.973085911288308\n",
      "For depth:9,iterations:425,learning_rate:0.01\n",
      "            train accuracy:6.2876011750020515 validation accuracy:7.35224106983164\n",
      "For depth:9,iterations:425,learning_rate:0.1\n",
      "            train accuracy:3.6311194535024622 validation accuracy:6.974839102035771\n",
      "For depth:9,iterations:450,learning_rate:0.01\n",
      "            train accuracy:6.224892848041772 validation accuracy:7.307977018198062\n",
      "For depth:9,iterations:450,learning_rate:0.1\n",
      "            train accuracy:3.5714049348735406 validation accuracy:6.941226250481769\n",
      "For depth:10,iterations:400,learning_rate:0.01\n",
      "            train accuracy:5.983752214510711 validation accuracy:7.557780874434322\n",
      "For depth:10,iterations:400,learning_rate:0.1\n",
      "            train accuracy:3.388694398680739 validation accuracy:7.3139517224348785\n",
      "For depth:10,iterations:425,learning_rate:0.01\n",
      "            train accuracy:5.90913236021751 validation accuracy:7.5312801695338845\n",
      "For depth:10,iterations:425,learning_rate:0.1\n",
      "            train accuracy:3.3221176518762343 validation accuracy:7.309538964121992\n",
      "For depth:10,iterations:450,learning_rate:0.01\n",
      "            train accuracy:5.842233655236882 validation accuracy:7.500466965341588\n",
      "For depth:10,iterations:450,learning_rate:0.1\n",
      "            train accuracy:3.2671295187861316 validation accuracy:7.3472407358592955\n"
     ]
    }
   ],
   "source": [
    "list1=[]\n",
    "depth = [5,7,9,10]\n",
    "features= [400,425,450]\n",
    "min_samples_s = [0.01,0.1]\n",
    "for j in depth:\n",
    "    for k in features:\n",
    "        for l in min_samples_s:\n",
    "            catboost = CatBoostRegressor(iterations=k, learning_rate= l , depth=j, random_state=32, silent=True)\n",
    "            catboost.fit(x_train, y_train)\n",
    "            y_train_pred = catboost.predict(x_train)\n",
    "            train_accuracy = mean_squared_error(y_train, y_train_pred)\n",
    "            y_val_pred = catboost.predict(x_val)\n",
    "            val_accuracy = mean_squared_error(y_val, y_val_pred)\n",
    "            list1.append((j,k,l,train_accuracy,val_accuracy))\n",
    "            print(f'''For depth:{j},iterations:{k},learning_rate:{l}\n",
    "            train accuracy:{train_accuracy} validation accuracy:{val_accuracy}''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7.908393303969475, 5.4087958095041655, 7.835820508264683, 5.347731590942943, 7.771857097557855, 5.290308010379564, 7.130662046210351, 4.4481459156611, 7.05955254136426, 4.379376333286357, 6.992444077829767, 4.311796087238251, 6.367381672857858, 3.6958579202126867, 6.2876011750020515, 3.6311194535024622, 6.224892848041772, 3.5714049348735406, 5.983752214510711, 3.388694398680739, 5.90913236021751, 3.3221176518762343, 5.842233655236882, 3.2671295187861316]\n",
      "[7.447204930735394, 7.271310469815163, 7.40706059520954, 7.335644829720593, 7.36952828918554, 7.3134326292825875, 7.331975204264542, 7.204658075392891, 7.2735075765936354, 7.266870142530666, 7.251898673859386, 7.271726567603457, 7.402796954993391, 6.973085911288308, 7.35224106983164, 6.974839102035771, 7.307977018198062, 6.941226250481769, 7.557780874434322, 7.3139517224348785, 7.5312801695338845, 7.309538964121992, 7.500466965341588, 7.3472407358592955]\n"
     ]
    }
   ],
   "source": [
    "all_train_acc=[list1[i][3] for i in range(len(list1))]\n",
    "all_val_acc=[list1[i][4] for i in range(len(list1))]\n",
    "print(all_train_acc)\n",
    "print(all_val_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[6.941226250481769,\n",
       " 6.973085911288308,\n",
       " 6.974839102035771,\n",
       " 7.204658075392891,\n",
       " 7.251898673859386,\n",
       " 7.266870142530666,\n",
       " 7.271310469815163,\n",
       " 7.271726567603457,\n",
       " 7.2735075765936354,\n",
       " 7.307977018198062]"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import heapq\n",
    "max_5_val_acc = heapq.nsmallest(10, all_val_acc)\n",
    "max_5_val_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9, 450, 0.1, 3.5714049348735406, 6.941226250481769)\n",
      "(9, 400, 0.1, 3.6958579202126867, 6.973085911288308)\n",
      "(9, 425, 0.1, 3.6311194535024622, 6.974839102035771)\n",
      "(7, 400, 0.1, 4.4481459156611, 7.204658075392891)\n",
      "(7, 450, 0.01, 6.992444077829767, 7.251898673859386)\n",
      "(7, 425, 0.1, 4.379376333286357, 7.266870142530666)\n",
      "(5, 400, 0.1, 5.4087958095041655, 7.271310469815163)\n",
      "(7, 450, 0.1, 4.311796087238251, 7.271726567603457)\n",
      "(7, 425, 0.01, 7.05955254136426, 7.2735075765936354)\n",
      "(9, 450, 0.01, 6.224892848041772, 7.307977018198062)\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(max_5_val_acc)):\n",
    "    print(list1[all_val_acc.index(max_5_val_acc[i])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error (MSE) on training data: 3.573125921036362\n",
      "Mean Squared Error (MSE) on training data: 7.035413198648431\n"
     ]
    }
   ],
   "source": [
    "from catboost import CatBoostRegressor\n",
    "catboost = CatBoostRegressor(iterations=450, learning_rate=0.1, depth=9, random_state=0, silent=True)\n",
    "catboost.fit(x_train, y_train)\n",
    "y_train_pred = catboost.predict(x_train)\n",
    "mse = mean_squared_error(y_train, y_train_pred)\n",
    "print(f\"Mean Squared Error (MSE) on training data: {mse}\")\n",
    "y_val_pred = catboost.predict(x_val)\n",
    "mse1 = mean_squared_error(y_val, y_val_pred)\n",
    "print(f\"Mean Squared Error (MSE) on training data: {mse1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred = catboost.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df = pd.DataFrame({\n",
    "    'position': y_test_pred,\n",
    "    'result_driver_standing': test_data[\"result_driver_standing\"]\n",
    "})\n",
    "result_df.to_csv('submission_file_cat.csv', index=False, header=['position', 'result_driver_standing'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>position</th>\n",
       "      <th>result_driver_standing</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.035360</td>\n",
       "      <td>298739826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.336553</td>\n",
       "      <td>299218806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.336553</td>\n",
       "      <td>299697786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6.516010</td>\n",
       "      <td>300176766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6.516010</td>\n",
       "      <td>300655746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>352923</th>\n",
       "      <td>13.875174</td>\n",
       "      <td>1880337225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>352924</th>\n",
       "      <td>13.875174</td>\n",
       "      <td>1881380625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>352925</th>\n",
       "      <td>12.198771</td>\n",
       "      <td>1881902325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>352926</th>\n",
       "      <td>11.496779</td>\n",
       "      <td>1882424025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>352927</th>\n",
       "      <td>11.241560</td>\n",
       "      <td>1882971810</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>352928 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         position  result_driver_standing\n",
       "0        8.035360               298739826\n",
       "1        7.336553               299218806\n",
       "2        7.336553               299697786\n",
       "3        6.516010               300176766\n",
       "4        6.516010               300655746\n",
       "...           ...                     ...\n",
       "352923  13.875174              1880337225\n",
       "352924  13.875174              1881380625\n",
       "352925  12.198771              1881902325\n",
       "352926  11.496779              1882424025\n",
       "352927  11.241560              1882971810\n",
       "\n",
       "[352928 rows x 2 columns]"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
